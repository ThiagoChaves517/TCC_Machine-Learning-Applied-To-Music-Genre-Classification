{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils  # Do seu utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados carregados para 8000 faixas 'small'.\n",
      "Gêneros: ['Electronic' 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental'\n",
      " 'International' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_3s_25overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_3s_25overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 3\n",
    "OVERLAP_PERCENT = 0.25\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição (lógica do v2)\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando espectrogramas cacheados de ../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy...\n",
      "Arquivos carregados.\n",
      "Shape de X (amostras, n_mels, frames): (99278, 128, 130)\n",
      "Shape de y (labels): (99278,)\n",
      "Shape de groups (track_ids): (99278,)\n"
     ]
    }
   ],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados. Iniciando extração (2 passagens)...\")\n",
    "    \n",
    "    # --- PASSAGEM 1: Contar o número total de janelas ---\n",
    "    \n",
    "    def get_window_count(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT):\n",
    "        # Esta função é mais leve, apenas carrega o áudio e conta os frames\n",
    "        try:\n",
    "            y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "            samples_per_window = window_size_sec * sr\n",
    "            if len(y) < samples_per_window: return 0\n",
    "            hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "            y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "            return y_frames.shape[0] # Retorna o número de janelas\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        if not os.path.exists(file_path): continue\n",
    "            \n",
    "        n_janelas = get_window_count(file_path)\n",
    "        if n_janelas > 0:\n",
    "            total_janelas += n_janelas\n",
    "            all_track_ids_para_contagem.append((track_id, row, n_janelas))\n",
    "\n",
    "    print(f\"\\nContagem concluída. Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- PASSAGEM 2: Extrair e Salvar em Arrays (memmap) ---\n",
    "    \n",
    "    # Usa o SPEC_SHAPE definido na Célula 3 (ex: (128, 130))\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    \n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita_atual = 0\n",
    "    \n",
    "    for track_id, row, n_janelas in tqdm(all_track_ids_para_contagem):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "        \n",
    "        for i, spec in enumerate(window_specs):\n",
    "            if i >= n_janelas: break \n",
    "            \n",
    "            X_np_memmap[idx_escrita_atual] = spec\n",
    "            y_encoded_np_temp[idx_escrita_atual] = row['genre_encoded']\n",
    "            groups_np_temp[idx_escrita_atual] = track_id\n",
    "            idx_escrita_atual += 1\n",
    "    \n",
    "    # 1. Salva o X (lendo do memmap e salvando como .npy)\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap)\n",
    "    \n",
    "    # 2. Fecha e deleta o arquivo memmap temporário\n",
    "    del X_np_memmap\n",
    "    os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    # 3. Salva os outros arrays\n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    print(f\"Extração concluída. Arquivos salvos.\")\n",
    "    \n",
    "    # 4. Agora, carregamos as variáveis (do .npy recém-criado)\n",
    "    print(f\"Carregando arquivos recém-criados do cache...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r') # <-- Esta linha agora funcionará\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 00:33:29.170500: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-24 00:33:29.279499: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-24 00:33:30.746556: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Growth habilitado para: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X para CNN (amostras, altura, largura, canais): (99278, 128, 130, 1)\n",
      "Shape de y (one-hot): (99278, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, \n",
    "                                     BatchNormalization, Dropout, \n",
    "                                     GlobalAveragePooling2D, Dense, Activation, \n",
    "                                     ReLU, Add)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763958811.510301  101346 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"ResNet_Audio\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"ResNet_Audio\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ activation_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │ activation_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ activation_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ activation_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │ activation_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ activation_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ activation_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │                   │            │ activation_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ activation_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │      \u001b[38;5;34m3,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ activation[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_3        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │     \u001b[38;5;34m36,928\u001b[0m │ activation_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │ activation_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_4        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m33\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │     \u001b[38;5;34m73,856\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_5        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │      \u001b[38;5;34m8,320\u001b[0m │ activation_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │    \u001b[38;5;34m147,584\u001b[0m │ activation_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │        \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │ activation_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m17\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ activation_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ activation_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_11       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ activation_11[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │                   │            │ activation_10[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ activation_12       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mActivation\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ activation_12[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m2,056\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,785,288</span> (10.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,785,288\u001b[0m (10.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,780,808</span> (10.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,780,808\u001b[0m (10.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,480</span> (17.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,480\u001b[0m (17.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_resnet_cnn(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    ResNet-18 style adaptada para Espectrogramas e 6GB VRAM.\n",
    "    \"\"\"\n",
    "    weight_decay = 0.0005\n",
    "    \n",
    "    def residual_block(x, filters, stride=1):\n",
    "        shortcut = x\n",
    "        \n",
    "        # Primeira convolução\n",
    "        x = Conv2D(filters, (3, 3), strides=stride, padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        \n",
    "        # Segunda convolução\n",
    "        x = Conv2D(filters, (3, 3), padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Ajuste do atalho se as dimensões mudarem\n",
    "        if stride > 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = Conv2D(filters, (1, 1), strides=stride, padding='same', kernel_regularizer=l2(weight_decay))(shortcut)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "            \n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    # Camada inicial\n",
    "    x = Conv2D(64, (7, 7), strides=2, padding='same', kernel_regularizer=l2(weight_decay))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "    \n",
    "    # Blocos Residuais\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    \n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = residual_block(x, 128)\n",
    "    \n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    # Não vamos até 512 filtros para economizar VRAM na 3060\n",
    "    \n",
    "    # Head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
    "    \n",
    "    return tf.keras.Model(inputs, outputs, name=\"ResNet_Audio\")\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_resnet_cnn(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Precision ativado: mixed_float16\n",
      "\n",
      "=== Iniciando Fold 1/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-24 00:33:58.237434: I external/local_xla/xla/service/service.cc:163] XLA service 0x72ac3c0032d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-24 00:33:58.237727: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-11-24 00:33:58.516299: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-24 00:33:59.641343: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
      "I0000 00:00:1763958847.067801  101462 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 29ms/step - accuracy: 0.4305 - loss: 1.9679 - val_accuracy: 0.3887 - val_loss: 1.8602 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27ms/step - accuracy: 0.4963 - loss: 1.6172 - val_accuracy: 0.5024 - val_loss: 1.6475 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 27ms/step - accuracy: 0.5184 - loss: 1.5463 - val_accuracy: 0.4750 - val_loss: 1.8020 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.5387 - loss: 1.4816 - val_accuracy: 0.4993 - val_loss: 1.5761 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.5502 - loss: 1.4367 - val_accuracy: 0.5007 - val_loss: 1.5633 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.5649 - loss: 1.3991 - val_accuracy: 0.5290 - val_loss: 1.4963 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.5717 - loss: 1.3732 - val_accuracy: 0.5055 - val_loss: 1.6441 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.5815 - loss: 1.3517 - val_accuracy: 0.5474 - val_loss: 1.4376 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.5892 - loss: 1.3334 - val_accuracy: 0.5198 - val_loss: 1.6675 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.5921 - loss: 1.3252 - val_accuracy: 0.4691 - val_loss: 1.7837 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5965 - loss: 1.3059\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 25ms/step - accuracy: 0.5967 - loss: 1.3109 - val_accuracy: 0.5534 - val_loss: 1.5185 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6285 - loss: 1.2101 - val_accuracy: 0.5643 - val_loss: 1.4189 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6403 - loss: 1.1714 - val_accuracy: 0.5561 - val_loss: 1.4564 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6468 - loss: 1.1497 - val_accuracy: 0.5590 - val_loss: 1.4628 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6558 - loss: 1.1300\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6544 - loss: 1.1337 - val_accuracy: 0.5689 - val_loss: 1.4774 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6829 - loss: 1.0477 - val_accuracy: 0.5741 - val_loss: 1.4879 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6945 - loss: 1.0094 - val_accuracy: 0.5628 - val_loss: 1.5500 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7030 - loss: 0.9857\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.7009 - loss: 0.9889 - val_accuracy: 0.5740 - val_loss: 1.4870 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 25ms/step - accuracy: 0.7228 - loss: 0.9258 - val_accuracy: 0.5776 - val_loss: 1.5559 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.7303 - loss: 0.8983 - val_accuracy: 0.5761 - val_loss: 1.5651 - learning_rate: 1.2500e-04\n",
      "Fold 1: Acc Janela=0.5643 | Acc Faixa=0.6075\n",
      "\n",
      "=== Iniciando Fold 2/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 27ms/step - accuracy: 0.4289 - loss: 1.9654 - val_accuracy: 0.4478 - val_loss: 1.8017 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 26ms/step - accuracy: 0.4916 - loss: 1.6183 - val_accuracy: 0.4697 - val_loss: 1.6718 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 27ms/step - accuracy: 0.5154 - loss: 1.5506 - val_accuracy: 0.4732 - val_loss: 1.6529 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5313 - loss: 1.4920 - val_accuracy: 0.4639 - val_loss: 1.6761 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5474 - loss: 1.4428 - val_accuracy: 0.4924 - val_loss: 1.6745 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5580 - loss: 1.4119 - val_accuracy: 0.5512 - val_loss: 1.4709 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5665 - loss: 1.3870 - val_accuracy: 0.5405 - val_loss: 1.4794 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5748 - loss: 1.3675 - val_accuracy: 0.5153 - val_loss: 1.5978 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5856 - loss: 1.3429\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.5821 - loss: 1.3527 - val_accuracy: 0.5370 - val_loss: 1.4786 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6127 - loss: 1.2464 - val_accuracy: 0.5678 - val_loss: 1.4261 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6264 - loss: 1.2103 - val_accuracy: 0.5846 - val_loss: 1.3947 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6339 - loss: 1.1843 - val_accuracy: 0.5576 - val_loss: 1.4599 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6424 - loss: 1.1685 - val_accuracy: 0.5760 - val_loss: 1.4441 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2789/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6516 - loss: 1.1466\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 25ms/step - accuracy: 0.6490 - loss: 1.1515 - val_accuracy: 0.5693 - val_loss: 1.4614 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6811 - loss: 1.0616 - val_accuracy: 0.5728 - val_loss: 1.5123 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6928 - loss: 1.0185 - val_accuracy: 0.5908 - val_loss: 1.4463 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7017 - loss: 0.9881\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6978 - loss: 0.9998 - val_accuracy: 0.5756 - val_loss: 1.4823 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.7225 - loss: 0.9282 - val_accuracy: 0.5828 - val_loss: 1.5207 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.7323 - loss: 0.9020 - val_accuracy: 0.5763 - val_loss: 1.5361 - learning_rate: 1.2500e-04\n",
      "Fold 2: Acc Janela=0.5846 | Acc Faixa=0.6312\n",
      "\n",
      "=== Iniciando Fold 3/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 27ms/step - accuracy: 0.4258 - loss: 1.9774 - val_accuracy: 0.4212 - val_loss: 1.8140 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 26ms/step - accuracy: 0.4892 - loss: 1.6141 - val_accuracy: 0.5181 - val_loss: 1.6418 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5131 - loss: 1.5436 - val_accuracy: 0.4282 - val_loss: 1.7289 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5330 - loss: 1.4827 - val_accuracy: 0.3181 - val_loss: 2.1417 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5474 - loss: 1.4363 - val_accuracy: 0.5645 - val_loss: 1.4333 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5615 - loss: 1.3988 - val_accuracy: 0.5334 - val_loss: 1.5282 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 27ms/step - accuracy: 0.5699 - loss: 1.3668 - val_accuracy: 0.5696 - val_loss: 1.4145 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5805 - loss: 1.3436 - val_accuracy: 0.5421 - val_loss: 1.5090 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5850 - loss: 1.3331 - val_accuracy: 0.5548 - val_loss: 1.4763 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2789/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5928 - loss: 1.3214\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5934 - loss: 1.3203 - val_accuracy: 0.5575 - val_loss: 1.5379 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6243 - loss: 1.2212 - val_accuracy: 0.5837 - val_loss: 1.4135 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6360 - loss: 1.1792 - val_accuracy: 0.5734 - val_loss: 1.4283 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6435 - loss: 1.1562 - val_accuracy: 0.5867 - val_loss: 1.4062 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6519 - loss: 1.1403 - val_accuracy: 0.5754 - val_loss: 1.4533 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 26ms/step - accuracy: 0.6556 - loss: 1.1216 - val_accuracy: 0.5750 - val_loss: 1.4917 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6624 - loss: 1.1126\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6603 - loss: 1.1178 - val_accuracy: 0.5908 - val_loss: 1.4866 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6894 - loss: 1.0285 - val_accuracy: 0.5903 - val_loss: 1.4591 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.7001 - loss: 0.9928 - val_accuracy: 0.5819 - val_loss: 1.5521 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7118 - loss: 0.9606\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7068 - loss: 0.9740 - val_accuracy: 0.5837 - val_loss: 1.4867 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7286 - loss: 0.9116 - val_accuracy: 0.5897 - val_loss: 1.5071 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7355 - loss: 0.8898 - val_accuracy: 0.5925 - val_loss: 1.5512 - learning_rate: 1.2500e-04\n",
      "Fold 3: Acc Janela=0.5867 | Acc Faixa=0.6400\n",
      "\n",
      "=== Iniciando Fold 4/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 27ms/step - accuracy: 0.4286 - loss: 1.9596 - val_accuracy: 0.2572 - val_loss: 3.0740 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 26ms/step - accuracy: 0.4936 - loss: 1.6055 - val_accuracy: 0.3985 - val_loss: 1.8230 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5166 - loss: 1.5401 - val_accuracy: 0.4801 - val_loss: 1.6984 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5387 - loss: 1.4730 - val_accuracy: 0.5237 - val_loss: 1.5095 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5555 - loss: 1.4178 - val_accuracy: 0.5169 - val_loss: 1.5638 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 27ms/step - accuracy: 0.5670 - loss: 1.3834 - val_accuracy: 0.5525 - val_loss: 1.4616 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5793 - loss: 1.3536 - val_accuracy: 0.5555 - val_loss: 1.4624 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5866 - loss: 1.3350 - val_accuracy: 0.5354 - val_loss: 1.5241 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5942 - loss: 1.3180\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5949 - loss: 1.3194 - val_accuracy: 0.5436 - val_loss: 1.5090 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6277 - loss: 1.2162 - val_accuracy: 0.5387 - val_loss: 1.5708 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6372 - loss: 1.1789 - val_accuracy: 0.5682 - val_loss: 1.4743 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6461 - loss: 1.1545\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6489 - loss: 1.1518 - val_accuracy: 0.5523 - val_loss: 1.5906 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6779 - loss: 1.0620 - val_accuracy: 0.5872 - val_loss: 1.4499 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6894 - loss: 1.0213 - val_accuracy: 0.5839 - val_loss: 1.5285 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6975 - loss: 0.9996 - val_accuracy: 0.5834 - val_loss: 1.4826 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7065 - loss: 0.9693\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7029 - loss: 0.9785 - val_accuracy: 0.5889 - val_loss: 1.5012 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.7260 - loss: 0.9092 - val_accuracy: 0.5815 - val_loss: 1.5885 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7348 - loss: 0.8853 - val_accuracy: 0.5792 - val_loss: 1.5594 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7386 - loss: 0.8679\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7382 - loss: 0.8717 - val_accuracy: 0.5829 - val_loss: 1.5896 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7536 - loss: 0.8315 - val_accuracy: 0.5859 - val_loss: 1.6208 - learning_rate: 6.2500e-05\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7598 - loss: 0.8101 - val_accuracy: 0.5880 - val_loss: 1.6357 - learning_rate: 6.2500e-05\n",
      "Fold 4: Acc Janela=0.5872 | Acc Faixa=0.6350\n",
      "\n",
      "=== Iniciando Fold 5/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 27ms/step - accuracy: 0.4226 - loss: 1.9651 - val_accuracy: 0.4421 - val_loss: 1.7285 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 26ms/step - accuracy: 0.4900 - loss: 1.6272 - val_accuracy: 0.4766 - val_loss: 1.6614 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 27ms/step - accuracy: 0.5141 - loss: 1.5448 - val_accuracy: 0.5122 - val_loss: 1.5411 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5375 - loss: 1.4772 - val_accuracy: 0.5022 - val_loss: 1.5744 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5525 - loss: 1.4322 - val_accuracy: 0.4611 - val_loss: 1.8513 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5637 - loss: 1.3973 - val_accuracy: 0.5567 - val_loss: 1.4385 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5730 - loss: 1.3716 - val_accuracy: 0.5217 - val_loss: 1.5577 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5828 - loss: 1.3477 - val_accuracy: 0.5152 - val_loss: 1.6410 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5906 - loss: 1.3261\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.5898 - loss: 1.3273 - val_accuracy: 0.5360 - val_loss: 1.5030 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6222 - loss: 1.2237 - val_accuracy: 0.5444 - val_loss: 1.5141 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6362 - loss: 1.1820 - val_accuracy: 0.5807 - val_loss: 1.3990 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6438 - loss: 1.1557 - val_accuracy: 0.5932 - val_loss: 1.4461 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6519 - loss: 1.1381 - val_accuracy: 0.5898 - val_loss: 1.4050 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6637 - loss: 1.1122\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6600 - loss: 1.1207 - val_accuracy: 0.5623 - val_loss: 1.5189 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.6934 - loss: 1.0274 - val_accuracy: 0.5871 - val_loss: 1.4351 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 26ms/step - accuracy: 0.7036 - loss: 0.9920 - val_accuracy: 0.5859 - val_loss: 1.5098 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7133 - loss: 0.9577\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7120 - loss: 0.9655 - val_accuracy: 0.5780 - val_loss: 1.5449 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7364 - loss: 0.8961 - val_accuracy: 0.5856 - val_loss: 1.5224 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7452 - loss: 0.8705 - val_accuracy: 0.5880 - val_loss: 1.5593 - learning_rate: 1.2500e-04\n",
      "Fold 5: Acc Janela=0.5807 | Acc Faixa=0.6270\n",
      "\n",
      "=== Iniciando Fold 6/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 27ms/step - accuracy: 0.4344 - loss: 1.9627 - val_accuracy: 0.3976 - val_loss: 1.7971 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 26ms/step - accuracy: 0.4957 - loss: 1.6192 - val_accuracy: 0.4784 - val_loss: 1.7229 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5189 - loss: 1.5459 - val_accuracy: 0.4963 - val_loss: 1.5948 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5346 - loss: 1.4874 - val_accuracy: 0.5433 - val_loss: 1.4561 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5501 - loss: 1.4463 - val_accuracy: 0.5396 - val_loss: 1.4535 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5600 - loss: 1.4137 - val_accuracy: 0.5285 - val_loss: 1.4909 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5683 - loss: 1.3868 - val_accuracy: 0.5225 - val_loss: 1.4905 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5756 - loss: 1.3616\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5760 - loss: 1.3614 - val_accuracy: 0.5329 - val_loss: 1.5447 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6063 - loss: 1.2637 - val_accuracy: 0.5583 - val_loss: 1.4274 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6217 - loss: 1.2185 - val_accuracy: 0.5593 - val_loss: 1.4305 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6298 - loss: 1.1948 - val_accuracy: 0.5624 - val_loss: 1.4170 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6368 - loss: 1.1766 - val_accuracy: 0.5781 - val_loss: 1.4049 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6467 - loss: 1.1573 - val_accuracy: 0.5514 - val_loss: 1.5164 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6510 - loss: 1.1456 - val_accuracy: 0.5545 - val_loss: 1.5243 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6611 - loss: 1.1298\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6606 - loss: 1.1310 - val_accuracy: 0.5612 - val_loss: 1.5716 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6931 - loss: 1.0345 - val_accuracy: 0.5754 - val_loss: 1.4821 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7048 - loss: 0.9919 - val_accuracy: 0.5755 - val_loss: 1.5002 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7148 - loss: 0.9706\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7129 - loss: 0.9721 - val_accuracy: 0.5633 - val_loss: 1.5890 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7382 - loss: 0.8949 - val_accuracy: 0.5791 - val_loss: 1.5818 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7457 - loss: 0.8682 - val_accuracy: 0.5725 - val_loss: 1.5742 - learning_rate: 1.2500e-04\n",
      "Fold 6: Acc Janela=0.5781 | Acc Faixa=0.6358\n",
      "\n",
      "=== Iniciando Fold 7/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 28ms/step - accuracy: 0.4292 - loss: 1.9529 - val_accuracy: 0.4695 - val_loss: 1.7090 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.4932 - loss: 1.6090 - val_accuracy: 0.4981 - val_loss: 1.6458 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.5187 - loss: 1.5341 - val_accuracy: 0.4474 - val_loss: 1.8520 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.5364 - loss: 1.4682 - val_accuracy: 0.5189 - val_loss: 1.5793 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5522 - loss: 1.4221 - val_accuracy: 0.5578 - val_loss: 1.4520 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5629 - loss: 1.3903 - val_accuracy: 0.5331 - val_loss: 1.5092 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5737 - loss: 1.3639 - val_accuracy: 0.5400 - val_loss: 1.4608 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5794 - loss: 1.3447\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5794 - loss: 1.3429 - val_accuracy: 0.5192 - val_loss: 1.5868 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6135 - loss: 1.2430 - val_accuracy: 0.5724 - val_loss: 1.4513 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.6249 - loss: 1.2034 - val_accuracy: 0.5847 - val_loss: 1.4064 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6364 - loss: 1.1765 - val_accuracy: 0.5663 - val_loss: 1.5333 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6418 - loss: 1.1570 - val_accuracy: 0.5879 - val_loss: 1.3962 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6495 - loss: 1.1403 - val_accuracy: 0.5780 - val_loss: 1.4781 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6534 - loss: 1.1335 - val_accuracy: 0.5821 - val_loss: 1.4943 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6621 - loss: 1.1096\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6591 - loss: 1.1191 - val_accuracy: 0.5456 - val_loss: 1.5635 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6905 - loss: 1.0238 - val_accuracy: 0.5956 - val_loss: 1.4928 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7031 - loss: 0.9874 - val_accuracy: 0.5750 - val_loss: 1.5360 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7121 - loss: 0.9631\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7116 - loss: 0.9666 - val_accuracy: 0.5869 - val_loss: 1.5155 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7321 - loss: 0.8987 - val_accuracy: 0.5851 - val_loss: 1.6115 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7369 - loss: 0.8797 - val_accuracy: 0.5958 - val_loss: 1.5663 - learning_rate: 1.2500e-04\n",
      "Fold 7: Acc Janela=0.5879 | Acc Faixa=0.6233\n",
      "\n",
      "=== Iniciando Fold 8/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 28ms/step - accuracy: 0.4287 - loss: 1.9565 - val_accuracy: 0.3057 - val_loss: 2.8644 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 27ms/step - accuracy: 0.4952 - loss: 1.6101 - val_accuracy: 0.4596 - val_loss: 1.6944 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5207 - loss: 1.5367 - val_accuracy: 0.4286 - val_loss: 1.9020 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5371 - loss: 1.4764 - val_accuracy: 0.5112 - val_loss: 1.5270 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5515 - loss: 1.4318 - val_accuracy: 0.5181 - val_loss: 1.5441 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5607 - loss: 1.4008 - val_accuracy: 0.5091 - val_loss: 1.5724 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5719 - loss: 1.3731 - val_accuracy: 0.5303 - val_loss: 1.5006 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5824 - loss: 1.3461 - val_accuracy: 0.5194 - val_loss: 1.6030 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5865 - loss: 1.3332 - val_accuracy: 0.5063 - val_loss: 1.6452 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2790/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5941 - loss: 1.3166\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5931 - loss: 1.3204 - val_accuracy: 0.5235 - val_loss: 1.5566 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6243 - loss: 1.2218 - val_accuracy: 0.5535 - val_loss: 1.4916 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6361 - loss: 1.1774 - val_accuracy: 0.5634 - val_loss: 1.4536 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6455 - loss: 1.1544 - val_accuracy: 0.5540 - val_loss: 1.5141 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6517 - loss: 1.1365 - val_accuracy: 0.5491 - val_loss: 1.5352 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6597 - loss: 1.1130\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6577 - loss: 1.1231 - val_accuracy: 0.5513 - val_loss: 1.5401 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6894 - loss: 1.0310 - val_accuracy: 0.5680 - val_loss: 1.5587 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6973 - loss: 1.0004 - val_accuracy: 0.5679 - val_loss: 1.5397 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7048 - loss: 0.9779\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7025 - loss: 0.9810 - val_accuracy: 0.5559 - val_loss: 1.5802 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7279 - loss: 0.9122 - val_accuracy: 0.5723 - val_loss: 1.6065 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7347 - loss: 0.8887 - val_accuracy: 0.5724 - val_loss: 1.5824 - learning_rate: 1.2500e-04\n",
      "Fold 8: Acc Janela=0.5634 | Acc Faixa=0.6170\n",
      "\n",
      "=== Iniciando Fold 9/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 28ms/step - accuracy: 0.4244 - loss: 1.9620 - val_accuracy: 0.4274 - val_loss: 1.7769 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 27ms/step - accuracy: 0.4916 - loss: 1.6132 - val_accuracy: 0.4683 - val_loss: 1.6451 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 27ms/step - accuracy: 0.5159 - loss: 1.5433 - val_accuracy: 0.4614 - val_loss: 1.7467 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5334 - loss: 1.4823 - val_accuracy: 0.4222 - val_loss: 1.9649 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5487 - loss: 1.4334 - val_accuracy: 0.5362 - val_loss: 1.4796 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5619 - loss: 1.4003 - val_accuracy: 0.4880 - val_loss: 1.6629 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5688 - loss: 1.3764 - val_accuracy: 0.5308 - val_loss: 1.5306 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5795 - loss: 1.3454\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.5779 - loss: 1.3496 - val_accuracy: 0.5375 - val_loss: 1.5567 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6116 - loss: 1.2502 - val_accuracy: 0.5574 - val_loss: 1.4833 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6248 - loss: 1.2087 - val_accuracy: 0.5588 - val_loss: 1.4577 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6331 - loss: 1.1831 - val_accuracy: 0.5511 - val_loss: 1.5202 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6427 - loss: 1.1624 - val_accuracy: 0.5581 - val_loss: 1.4465 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6480 - loss: 1.1483 - val_accuracy: 0.5560 - val_loss: 1.5141 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6556 - loss: 1.1340 - val_accuracy: 0.5416 - val_loss: 1.5758 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6575 - loss: 1.1249\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6602 - loss: 1.1213 - val_accuracy: 0.5632 - val_loss: 1.4936 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6932 - loss: 1.0280 - val_accuracy: 0.5822 - val_loss: 1.4799 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7074 - loss: 0.9872 - val_accuracy: 0.5694 - val_loss: 1.5140 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7188 - loss: 0.9524\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7143 - loss: 0.9639 - val_accuracy: 0.5569 - val_loss: 1.6046 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7373 - loss: 0.8941 - val_accuracy: 0.5746 - val_loss: 1.5776 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7450 - loss: 0.8693 - val_accuracy: 0.5789 - val_loss: 1.5982 - learning_rate: 1.2500e-04\n",
      "Fold 9: Acc Janela=0.5581 | Acc Faixa=0.6195\n",
      "\n",
      "=== Iniciando Fold 10/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 28ms/step - accuracy: 0.4306 - loss: 1.9654 - val_accuracy: 0.4750 - val_loss: 1.6715 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 27ms/step - accuracy: 0.4938 - loss: 1.6152 - val_accuracy: 0.4961 - val_loss: 1.5606 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5170 - loss: 1.5420 - val_accuracy: 0.4844 - val_loss: 1.5739 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5369 - loss: 1.4783 - val_accuracy: 0.5082 - val_loss: 1.6093 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5466 - loss: 1.4420\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5506 - loss: 1.4342 - val_accuracy: 0.4907 - val_loss: 1.6020 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.5867 - loss: 1.3170 - val_accuracy: 0.5504 - val_loss: 1.4355 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.6034 - loss: 1.2684 - val_accuracy: 0.5513 - val_loss: 1.4023 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6152 - loss: 1.2366 - val_accuracy: 0.5748 - val_loss: 1.3864 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6253 - loss: 1.2111 - val_accuracy: 0.5672 - val_loss: 1.4229 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6371 - loss: 1.1875 - val_accuracy: 0.5861 - val_loss: 1.4071 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6458 - loss: 1.1673\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.6478 - loss: 1.1657 - val_accuracy: 0.5657 - val_loss: 1.4651 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 26ms/step - accuracy: 0.6848 - loss: 1.0583 - val_accuracy: 0.5788 - val_loss: 1.5017 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7012 - loss: 1.0090 - val_accuracy: 0.5824 - val_loss: 1.4713 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7131 - loss: 0.9755\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7121 - loss: 0.9770 - val_accuracy: 0.5721 - val_loss: 1.5392 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7446 - loss: 0.8875 - val_accuracy: 0.5763 - val_loss: 1.5733 - learning_rate: 1.2500e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 26ms/step - accuracy: 0.7563 - loss: 0.8491 - val_accuracy: 0.5831 - val_loss: 1.5999 - learning_rate: 1.2500e-04\n",
      "Fold 10: Acc Janela=0.5748 | Acc Faixa=0.6333\n",
      "\n",
      "--- CV Concluído ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 32 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "def apply_spec_augment(spectrogram, time_mask_param=20, freq_mask_param=15, num_masks=1):\n",
    "    \"\"\"\n",
    "    Aplica mascaramento de tempo e frequência no espectrograma.\n",
    "    Entrada: (128, 130, 1) ou (128, 130)\n",
    "    \"\"\"\n",
    "    # Garante que é uma cópia para não alterar o original\n",
    "    aug_spec = spectrogram.copy()\n",
    "    \n",
    "    # Se tiver canal (H, W, C), remove para processar\n",
    "    if aug_spec.ndim == 3:\n",
    "        aug_spec = aug_spec[:, :, 0]\n",
    "        \n",
    "    n_mels, n_steps = aug_spec.shape\n",
    "    \n",
    "    # Mascaramento de Frequência\n",
    "    for _ in range(num_masks):\n",
    "        f = np.random.randint(0, freq_mask_param)\n",
    "        f0 = np.random.randint(0, n_mels - f)\n",
    "        aug_spec[f0:f0+f, :] = 0\n",
    "        \n",
    "    # Mascaramento de Tempo\n",
    "    for _ in range(num_masks):\n",
    "        t = np.random.randint(0, time_mask_param)\n",
    "        t0 = np.random.randint(0, n_steps - t)\n",
    "        aug_spec[:, t0:t0+t] = 0\n",
    "        \n",
    "    # Retorna dimensão do canal\n",
    "    return aug_spec[..., np.newaxis]\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size, augment=False):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            original_shape = X_batch.shape\n",
    "            X_b_flat = X_batch.reshape(original_shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(original_shape)\n",
    "            \n",
    "            # Aplica Augmentation apenas no Treino\n",
    "            if augment:\n",
    "                X_b_final = np.array([apply_spec_augment(x) for x in X_b_scaled])\n",
    "            else:\n",
    "                X_b_final = X_b_scaled\n",
    "            \n",
    "            yield X_b_final, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"\\n=== Iniciando Fold {fold+1}/{n_splits} ===\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_resnet_cnn(input_shape, N_CLASSES)\n",
    "\n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=0.004)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino com SpecAugmentation\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE, augment=True)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\n",
      "Acurácia Média (10-Fold CV): 0.6270 +/- 0.0096\n",
      "\n",
      "--- Relatório de Classificação (Nível Faixa) ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.61      0.69      0.65       999\n",
      " Experimental       0.56      0.50      0.53       999\n",
      "         Folk       0.62      0.69      0.65      1000\n",
      "      Hip-Hop       0.77      0.78      0.77       997\n",
      " Instrumental       0.60      0.63      0.61      1000\n",
      "International       0.67      0.76      0.71      1000\n",
      "          Pop       0.45      0.28      0.34      1000\n",
      "         Rock       0.65      0.70      0.67       999\n",
      "\n",
      "     accuracy                           0.63      7994\n",
      "    macro avg       0.62      0.63      0.62      7994\n",
      " weighted avg       0.62      0.63      0.62      7994\n",
      "\n",
      "\n",
      "--- Matriz de Confusão (Nível Faixa) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
