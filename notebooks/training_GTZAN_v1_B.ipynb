{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e53e1b",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b321bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuração de Ambiente e Hardware ---\n",
    "import os\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "# Bibliotecas RAPIDS (GPU)\n",
    "import cupy as cp\n",
    "from cuml.pipeline import Pipeline as cumlPipeline\n",
    "from cuml.preprocessing import StandardScaler as cumlStandardScaler\n",
    "from cuml.neighbors import KNeighborsClassifier as cumlKNN\n",
    "from cuml.svm import SVC as cumlSVC\n",
    "from cuml.ensemble import RandomForestClassifier as cumlRF\n",
    "import xgboost as xgb\n",
    "from cuml.metrics import accuracy_score\n",
    "\n",
    "# Bibliotecas Scikit-learn (CPU & Utilities)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, confusion_matrix\n",
    "from sklearn.base import clone \n",
    "\n",
    "# Bibliotecas de Processamento de Áudio e Dados\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "import io\n",
    "from joblib import Parallel, delayed\n",
    "import psutil\n",
    "import gc\n",
    "\n",
    "# Bibliotecas TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Configuração de GPU para TF (evitar alocar toda VRAM)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "print(\"Ambiente configurado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c14ddc",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats(features_matrix):\n",
    "    \"\"\"Calcula Mean, Std, Skew, Kurtosis para a matriz de features.\"\"\"\n",
    "    if features_matrix.size == 0:\n",
    "        return None \n",
    "    result = []\n",
    "    result.extend(np.mean(features_matrix, axis=1))\n",
    "    result.extend(np.std(features_matrix, axis=1))\n",
    "    result.extend(stats.skew(features_matrix, axis=1))\n",
    "    result.extend(stats.kurtosis(features_matrix, axis=1))\n",
    "    return np.array(result)\n",
    "\n",
    "def extract_features_windowed(file_path, window_size=3.0, overlap=0.5, sr=22050):\n",
    "    \"\"\"\n",
    "    Extrai features de janelas de áudio.\n",
    "    \"\"\"\n",
    "    all_window_features = []\n",
    "    \n",
    "    # Parâmetros DSP\n",
    "    N_FFT = 2048\n",
    "    HOP_LENGTH = 512\n",
    "    N_MFCC = 20\n",
    "    N_CHROMA = 12\n",
    "    N_CONTRAST = 7\n",
    "    \n",
    "    try:\n",
    "        # Carregar áudio (GTZAN é .wav, librosa nativo é rápido)\n",
    "        y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "        \n",
    "        # Janelamento\n",
    "        samples_per_window = int(window_size * sr)\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            return None\n",
    "\n",
    "        # Cria frames [n_windows, samples_per_window]\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Bases: STFT e CQT\n",
    "            stft = np.abs(librosa.stft(y_window, n_fft=N_FFT, hop_length=HOP_LENGTH))\n",
    "            cqt = np.abs(librosa.cqt(y_window, sr=sr, hop_length=HOP_LENGTH))\n",
    "            \n",
    "            window_vector = []\n",
    "            \n",
    "            # 1. Spectral Centroid, Bandwidth, Rolloff, Flatness, RMS, ZCR\n",
    "            f_list = [\n",
    "                librosa.feature.spectral_centroid(S=stft),\n",
    "                librosa.feature.spectral_bandwidth(S=stft),\n",
    "                librosa.feature.spectral_rolloff(S=stft),\n",
    "                librosa.feature.rms(S=stft),\n",
    "                librosa.feature.zero_crossing_rate(y_window, frame_length=N_FFT, hop_length=HOP_LENGTH)\n",
    "            ]\n",
    "            \n",
    "            for feat in f_list:\n",
    "                stats_f = calculate_stats(feat)\n",
    "                if stats_f is not None: window_vector.extend(stats_f)\n",
    "\n",
    "            # 2. Spectral Contrast\n",
    "            f = librosa.feature.spectral_contrast(S=stft, n_bands=N_CONTRAST - 1)\n",
    "            window_vector.extend(calculate_stats(f))\n",
    "\n",
    "            # 3. Chroma (CQT, CENS, STFT)\n",
    "            f_chroma = [\n",
    "                librosa.feature.chroma_cqt(C=cqt, n_chroma=N_CHROMA),\n",
    "                librosa.feature.chroma_cens(C=cqt, n_chroma=N_CHROMA),\n",
    "                librosa.feature.chroma_stft(S=stft**2, n_chroma=N_CHROMA)\n",
    "            ]\n",
    "            for feat in f_chroma:\n",
    "                window_vector.extend(calculate_stats(feat))\n",
    "\n",
    "            # 4. MFCC + Deltas\n",
    "            mel = librosa.feature.melspectrogram(S=stft**2, sr=sr)\n",
    "            mfcc = librosa.feature.mfcc(S=librosa.power_to_db(mel), n_mfcc=N_MFCC)\n",
    "            mfcc_delta = librosa.feature.delta(mfcc)\n",
    "            mfcc_delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "            \n",
    "            window_vector.extend(calculate_stats(mfcc))\n",
    "            window_vector.extend(calculate_stats(mfcc_delta))\n",
    "            window_vector.extend(calculate_stats(mfcc_delta2))\n",
    "\n",
    "            # 5. Tonnetz\n",
    "            # Recalcula chroma_cqt se necessário ou reutiliza\n",
    "            f = librosa.feature.tonnetz(y=librosa.effects.harmonic(y_window), sr=sr, chroma=f_chroma[0])\n",
    "            window_vector.extend(calculate_stats(f))\n",
    "            \n",
    "            all_window_features.append(window_vector)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro em {file_path}: {e}\")\n",
    "        return None\n",
    "        \n",
    "    return all_window_features\n",
    "\n",
    "def process_gtzan_file(genre, filename, dataset_path, params):\n",
    "    \"\"\"Worker para processamento paralelo.\"\"\"\n",
    "    file_path = os.path.join(dataset_path, genre, filename)\n",
    "    \n",
    "    # Nome da faixa (sem extensão) servirá como Group ID\n",
    "    track_id = filename.split('.')[0] + \"_\" + genre \n",
    "    \n",
    "    features = extract_features_windowed(\n",
    "        file_path, \n",
    "        window_size=params['window_size'], \n",
    "        overlap=params['overlap'], \n",
    "        sr=params['sr']\n",
    "    )\n",
    "    \n",
    "    if features is None or len(features) == 0:\n",
    "        return None\n",
    "        \n",
    "    # Retorna: (Features, Label, GroupID)\n",
    "    # Replicamos o label e o ID para cada janela extraída\n",
    "    labels = [genre] * len(features)\n",
    "    groups = [track_id] * len(features)\n",
    "    \n",
    "    return features, labels, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4475b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Parâmetros e Execução ---\n",
    "GTZAN_DIR = '../gtzan_dataset/genres_original' # Ajuste para o seu caminho\n",
    "OUTPUT_FILE_X = '../preprocessed_features/gtzan_X_3s_50overlap.npy'\n",
    "OUTPUT_FILE_y = '../preprocessed_features/gtzan_y_3s_50overlap.npy'\n",
    "OUTPUT_FILE_groups = '../preprocessed_features/gtzan_groups_3s_50overlap.npy'\n",
    "\n",
    "# Parâmetros: 3s de janela, 50% de overlap (gera mais dados que os 25% do FMA)\n",
    "extraction_params = {'window_size': 3.0, 'overlap': 0.5, 'sr': 22050}\n",
    "\n",
    "if not os.path.exists(OUTPUT_FILE_X):\n",
    "    print(\"Iniciando extração de features do GTZAN...\")\n",
    "    \n",
    "    # Listar arquivos\n",
    "    genres = [d for d in os.listdir(GTZAN_DIR) if os.path.isdir(os.path.join(GTZAN_DIR, d))]\n",
    "    tasks = []\n",
    "    for genre in genres:\n",
    "        genre_dir = os.path.join(GTZAN_DIR, genre)\n",
    "        files = [f for f in os.listdir(genre_dir) if f.endswith('.wav')]\n",
    "        for f in files:\n",
    "            tasks.append((genre, f))\n",
    "            \n",
    "    print(f\"Total de arquivos encontrados: {len(tasks)}\")\n",
    "    \n",
    "    # Paralelismo\n",
    "    n_cores = max(1, psutil.cpu_count(logical=False) - 1)\n",
    "    print(f\"Usando {n_cores} núcleos.\")\n",
    "    \n",
    "    results = Parallel(n_jobs=n_cores, verbose=0)(\n",
    "        delayed(process_gtzan_file)(\n",
    "            g, f, GTZAN_DIR, extraction_params\n",
    "        ) for g, f in tqdm(tasks, desc=\"Extraindo\")\n",
    "    )\n",
    "    \n",
    "    # Consolidar\n",
    "    X_list, y_list, groups_list = [], [], []\n",
    "    for res in results:\n",
    "        if res:\n",
    "            feat, lbl, grp = res\n",
    "            X_list.extend(feat)\n",
    "            y_list.extend(lbl)\n",
    "            groups_list.extend(grp)\n",
    "            \n",
    "    X_np = np.array(X_list, dtype=np.float32)\n",
    "    # Encoding Labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_list).astype(np.int32)\n",
    "    groups_np = np.array(groups_list) # Strings são ok para Groups\n",
    "    \n",
    "    # Limpeza NaNs\n",
    "    X_np = np.nan_to_num(X_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Salvar\n",
    "    os.makedirs(os.path.dirname(OUTPUT_FILE_X), exist_ok=True)\n",
    "    np.save(OUTPUT_FILE_X, X_np)\n",
    "    np.save(OUTPUT_FILE_y, y_encoded)\n",
    "    np.save(OUTPUT_FILE_groups, groups_np)\n",
    "    \n",
    "    # Salvar classes para referência\n",
    "    np.save('../preprocessed_features/gtzan_classes.npy', le.classes_)\n",
    "    \n",
    "    print(f\"Extração concluída. Shape X: {X_np.shape}\")\n",
    "\n",
    "else:\n",
    "    print(\"Carregando arquivos pré-processados...\")\n",
    "    X_np = np.load(OUTPUT_FILE_X)\n",
    "    y_encoded = np.load(OUTPUT_FILE_y)\n",
    "    groups_np = np.load(OUTPUT_FILE_groups)\n",
    "    class_names = np.load('../preprocessed_features/gtzan_classes.npy', allow_pickle=True)\n",
    "    print(f\"Dados carregados. Shape X: {X_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2be225",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição dos Pipelines\n",
    "pipe_knn = cumlPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('knn', cumlKNN(n_neighbors=10)) \n",
    "])\n",
    "\n",
    "pipe_svm = cumlPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', cumlSVC(kernel='rbf', C=0.75, gamma='scale')) \n",
    "])\n",
    "\n",
    "# Random Forest: n_estimators mantido, max_depth reduzido levemente\n",
    "pipe_rf = cumlPipeline([\n",
    "    ('rf', cumlRF(n_estimators=300, \n",
    "                                  max_depth=7,\n",
    "                                  min_samples_leaf=5,\n",
    "                                  max_features=0.6))\n",
    "])\n",
    "\n",
    "# XGBoost: Ajustado para dataset menor\n",
    "model_xgb = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.03,\n",
    "    gamma=5.0,             # AUMENTADO: poda agressiva de árvores\n",
    "    reg_alpha=1.0,\n",
    "    reg_lambda=1.0,        # AUMENTADO: regularização L2\n",
    "    subsample=0.7,         # Usa apenas 70% dos dados por árvore\n",
    "    colsample_bytree=0.7,  # Usa apenas 70% das features por árvore\n",
    "    tree_method='hist',\n",
    "    device=\"cuda\",\n",
    "    random_state=42,\n",
    "    objective='multi:softmax',\n",
    "    num_class=len(np.unique(y_encoded))\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"KNN (GPU)\": pipe_knn,\n",
    "    \"SVM (GPU)\": pipe_svm,\n",
    "    \"Random Forest (GPU)\": pipe_rf,\n",
    "    \"XGBoost (GPU)\": model_xgb,\n",
    "    \"MLP (Keras)\": \"keras_placeholder\"\n",
    "}\n",
    "\n",
    "def build_mlp(input_dim, num_classes):\n",
    "    # Regularização um pouco mais forte pois o dataset é pequeno\n",
    "    l2_reg = 0.02\n",
    "    dropout_rate = 0.6\n",
    "    \n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(input_dim,)),\n",
    "        \n",
    "        # Camada 1\n",
    "        layers.Dense(128, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ELU(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "\n",
    "        # Camada 2\n",
    "        layers.Dense(64, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ELU(),\n",
    "        layers.Dropout(dropout_rate),\n",
    "        \n",
    "        # Camada 3\n",
    "        layers.Dense(32, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(l2_reg)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ELU(),\n",
    "        \n",
    "        # Saída\n",
    "        layers.Dense(num_classes, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005) \n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Validação Cruzada com GroupKFold (CRUCIAL para evitar vazamento de dados entre janelas)\n",
    "gkf = GroupKFold(n_splits=10) # 10 folds padrão para GTZAN\n",
    "results_track_level = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTreinando {name}...\")\n",
    "    fold_accs = []\n",
    "    \n",
    "    # Clonar modelo se não for Keras\n",
    "    if name != \"MLP (Keras)\":\n",
    "        current_model = clone(model)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np, y_encoded, groups=groups_np)):\n",
    "        X_train, y_train = X_np[train_idx], y_encoded[train_idx]\n",
    "        X_test, y_test = X_np[test_idx], y_encoded[test_idx]\n",
    "        \n",
    "        # Track IDs para agregação (votação)\n",
    "        groups_test = groups_np[test_idx]\n",
    "        \n",
    "        # Treino\n",
    "        if name == \"MLP (Keras)\":\n",
    "            # Scaling manual para Keras\n",
    "            scl = StandardScaler()\n",
    "            X_train_s = scl.fit_transform(X_train)\n",
    "            X_test_s = scl.transform(X_test)\n",
    "            \n",
    "            keras_m = build_mlp(X_train.shape[1], len(np.unique(y_encoded)))\n",
    "            cb = [EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss')]\n",
    "            keras_m.fit(X_train_s, y_train, epochs=100, batch_size=64, validation_split=0.1, callbacks=cb, verbose=0)\n",
    "            \n",
    "            # Predição (Probabilidades -> Classes)\n",
    "            preds_window = np.argmax(keras_m.predict(X_test_s, verbose=0), axis=1)\n",
    "            tf.keras.backend.clear_session()\n",
    "            \n",
    "        elif \"GPU\" in name:\n",
    "            # Converter para CuPy se necessário e treinar\n",
    "            # Nota: cuML pipelines aceitam numpy, mas convertem internamente\n",
    "            current_model.fit(X_train, y_train)\n",
    "            preds_window = current_model.predict(X_test)\n",
    "            # Se retornar cupy array, converter para numpy\n",
    "            if hasattr(preds_window, 'get'): preds_window = preds_window.get()\n",
    "        \n",
    "        # --- Votação Majoritária por Faixa (Track Level Accuracy) ---\n",
    "        df_pred = pd.DataFrame({'group': groups_test, 'pred': preds_window, 'true': y_test})\n",
    "        \n",
    "        # Agrupar por música e pegar a moda das predições das janelas\n",
    "        track_preds = df_pred.groupby('group')['pred'].apply(lambda x: stats.mode(x)[0][0])\n",
    "        track_true = df_pred.groupby('group')['true'].first()\n",
    "        \n",
    "        acc = accuracy_score(track_true, track_preds)\n",
    "        fold_accs.append(acc)\n",
    "        \n",
    "    results_track_level[name] = fold_accs\n",
    "    print(f\"Média Acurácia (Track-Level): {np.mean(fold_accs):.4f}\")\n",
    "\n",
    "# Exibir Resultados Finais\n",
    "print(\"\\n=== Resultados Finais (10-Fold Group CV) ===\")\n",
    "for model, accs in results_track_level.items():\n",
    "    print(f\"{model}: {np.mean(accs)*100:.2f}% (+/- {np.std(accs)*100:.2f}%)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-fma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
