{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados carregados para 8000 faixas 'small'.\n",
      "Gêneros: ['Electronic' 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental'\n",
      " 'International' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_3s_25overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_3s_25overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28aa0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Função de Carregamento Robusto (Trazida do V2 e melhorada) ---\n",
    "def load_audio_ffmpeg(file_path, sr):\n",
    "    \"\"\"\n",
    "    Decodifica áudio para WAV em memória usando FFmpeg.\n",
    "    Muito mais robusto a arquivos MP3 corrompidos do FMA.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Comando para decodificar MP3 para WAV (PCM 16-bit) e jogar no STDOUT (pipe)\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', file_path,\n",
    "            '-f', 'wav',            # Formato de contêiner WAV\n",
    "            '-ac', '1',             # 1 Canal (Mono)\n",
    "            '-ar', str(sr),         # Taxa de Amostragem\n",
    "            '-vn',                  # Ignorar vídeo (se houver capa de álbum embutida)\n",
    "            '-y',                   # Sobrescrever (para pipe não importa, mas boa prática)\n",
    "            '-loglevel', 'quiet',   # Silenciar logs do ffmpeg\n",
    "            '-'                     # Saída para Pipe (STDOUT)\n",
    "        ]\n",
    "        \n",
    "        # Executa e captura os bytes\n",
    "        out = subprocess.check_output(command)\n",
    "        \n",
    "        # Carrega do buffer de memória\n",
    "        # librosa.load consegue ler de um objeto file-like (BytesIO)\n",
    "        y, _ = librosa.load(io.BytesIO(out), sr=sr)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback: Se o FFmpeg falhar (raro), tenta o librosa padrão ou retorna erro\n",
    "        # print(f\"Erro FFmpeg em {file_path}: {e}\")\n",
    "        try:\n",
    "            y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "            return y\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 3\n",
    "OVERLAP_PERCENT = 0.25\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y = load_audio_ffmpeg(file_path, sr=sr)\n",
    "\n",
    "        # Verificação de segurança caso o ffmpeg falhe e retorne None\n",
    "        if y is None:\n",
    "            return []\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de núcleos a usar (deixa 1 ou 2 livres para o sistema/OS não travar)\n",
    "N_JOBS = max(1, multiprocessing.cpu_count() - 2)\n",
    "\n",
    "# Funções Auxiliares para o Paralelismo (devem ser definidas antes da chamada Parallel)\n",
    "def worker_count_windows(args):\n",
    "    \"\"\"Função worker para contar janelas de uma faixa em paralelo\"\"\"\n",
    "    track_id, row, audio_dir = args\n",
    "    genre_top = row['genre_top']\n",
    "    file_path = f\"{audio_dir}/{genre_top}/{track_id:06d}.mp3\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    \n",
    "    # Reutiliza a lógica de contagem (copiada para dentro para garantir escopo no worker)\n",
    "    try:\n",
    "        y = load_audio_ffmpeg(file_path, sr=SR)\n",
    "        \n",
    "        if y is None: \n",
    "            return None\n",
    "    \n",
    "        samples_per_window = WINDOW_SIZE_SEC * SR\n",
    "        if len(y) < samples_per_window: \n",
    "            return None\n",
    "        \n",
    "        hop_size = int(samples_per_window * (1.0 - OVERLAP_PERCENT))\n",
    "        n_windows = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0).shape[0]\n",
    "\n",
    "        return (track_id, row, n_windows)\n",
    "    \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def worker_extract_features(args):\n",
    "    \"\"\"Função worker para extrair mel-specs de uma faixa em paralelo\"\"\"\n",
    "    track_id, row, n_janelas_esperadas, audio_dir = args\n",
    "    genre_top = row['genre_top']\n",
    "    file_path = f\"{audio_dir}/{genre_top}/{track_id:06d}.mp3\"\n",
    "    \n",
    "    window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "    \n",
    "    # Prepara os dados para retorno\n",
    "    track_data = []\n",
    "    for i, spec in enumerate(window_specs):\n",
    "        if i >= n_janelas_esperadas: break\n",
    "        # Retorna tupla: (Espectrograma, Label Codificado, Track ID)\n",
    "        track_data.append((spec, row['genre_encoded'], track_id))\n",
    "        \n",
    "    return track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando espectrogramas cacheados de ../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy...\n",
      "Arquivos carregados.\n",
      "Shape de X (amostras, n_mels, frames): (99278, 128, 130)\n",
      "Shape de y (labels): (99278,)\n",
      "Shape de groups (track_ids): (99278,)\n"
     ]
    }
   ],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados na cache. Iniciando extração (são 2 passagens)...\")\n",
    "    print(f\"Extração paralela usando {N_JOBS} núcleos...\")\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "\n",
    "    # --- 2 - Contagem Paralela ---\n",
    "    # Prepara argumentos para o worker\n",
    "    tasks_p1 = [(tid, row, AUDIO_DIR_GENRES) for tid, row in track_metadata.iterrows()]\n",
    "    \n",
    "    # Executa em paralelo\n",
    "    results_p1 = Parallel(n_jobs=N_JOBS, verbose=5, batch_size='auto')(\n",
    "        delayed(worker_count_windows)(t) for t in tqdm(tasks_p1, desc=\"Passagem 1/2: Contando Janelas\")\n",
    "    )\n",
    "\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for res in results_p1:\n",
    "        if res is not None:\n",
    "            track_id, row, n = res\n",
    "            if n > 0:\n",
    "                total_janelas += n\n",
    "                all_track_ids_para_contagem.append((track_id, row, n))\n",
    "                \n",
    "    print(f\"Contagem completa! Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- 2 - Extração Paralela ---\n",
    "    tasks_p2 = [(t[0], t[1], t[2], AUDIO_DIR_GENRES) for t in all_track_ids_para_contagem]\n",
    "    \n",
    "    # Executa extração (Isso vai consumir RAM, mas com 32GB é tranquilo para ~7GB de dados)\n",
    "    results_p2_lists = Parallel(n_jobs=N_JOBS, batch_size='auto')(\n",
    "        delayed(worker_extract_features)(t) for t in tqdm(tasks_p2, desc=\"Passagem 2/2: Extraindo Features\")\n",
    "    )\n",
    "    \n",
    "    # --- 3 - Escrita no Memmap ---\n",
    "    # Agora escrevemos tudo no disco sequencialmente (muito rápido pois já está na RAM)\n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    print(f\"\\nEscrevendo dados no disco para {MEMMAP_TEMP_FILE} shape={final_shape}...\")\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita = 0\n",
    "    # Itera sobre os resultados das faixas\n",
    "    for track_data in tqdm(results_p2_lists, desc=\"Salvando no disco...\"):\n",
    "        for spec, label, tid in track_data:\n",
    "            X_np_memmap[idx_escrita] = spec\n",
    "            y_encoded_np_temp[idx_escrita] = label\n",
    "            groups_np_temp[idx_escrita] = tid\n",
    "            idx_escrita += 1\n",
    "    \n",
    "    # Finalização (Salvar e Carregar)\n",
    "    print(f\"\\nConsolidando arquivos...\")\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap) # Converte memmap para npy final\n",
    "    del X_np_memmap\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE): os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    \n",
    "    print(\"Carregando arquivos gerados...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 01:51:50.374593: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-02 01:51:50.411901: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-02 01:51:51.329222: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Growth habilitado para: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X para CNN (amostras, altura, largura, canais): (99278, 128, 130, 1)\n",
      "Shape de y (one-hot): (99278, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, \n",
    "                                     BatchNormalization, Dropout, \n",
    "                                     GlobalAveragePooling2D, Dense, Activation)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1764654711.711713    3540 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,243,368</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,243,368\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,241,448</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,241,448\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Arquitetura inspirada na VGG, otimizada para Mel-Espectrogramas.\n",
    "    Usa GlobalAveragePooling para reduzir parâmetros na camada densa.\n",
    "    \"\"\"\n",
    "    weight_decay = 0.0005  # Regularização L2 para evitar overfitting\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=input_shape))\n",
    "\n",
    "    # --- Bloco 1 (Recursos de Baixo Nível / Timbre) ---\n",
    "    # 32 Filtros\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # --- Bloco 2 ---\n",
    "    # 64 Filtros\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 3 ---\n",
    "    # 128 Filtros\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 4 (Recursos de Alto Nível / Estrutura) ---\n",
    "    # 256 Filtros - Aprofundando, mas parando aqui para economizar VRAM\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    # --- Classificador (Head) ---\n",
    "    # Global Average Pooling \n",
    "    # Transforma (H, W, 256) -> vetor de (256)\n",
    "    model.add(GlobalAveragePooling2D()) \n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax', dtype='float32'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Precision ativado: mixed_float16\n",
      "\n",
      "=== Iniciando Fold 1/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 01:52:06.883533: I external/local_xla/xla/service/service.cc:163] XLA service 0x28b39e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-12-02 01:52:06.883580: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-12-02 01:52:06.982865: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-12-02 01:52:07.608577: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
      "2025-12-02 01:52:07.967254: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-12-02 01:52:09.061714: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5747', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-12-02 01:52:09.344360: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5747', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "I0000 00:00:1764654740.357762    3790 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 44ms/step - accuracy: 0.4142 - loss: 1.8278 - val_accuracy: 0.3853 - val_loss: 1.8563 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 42ms/step - accuracy: 0.4892 - loss: 1.6097 - val_accuracy: 0.3942 - val_loss: 2.0668 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5131 - loss: 1.5473 - val_accuracy: 0.3595 - val_loss: 2.2635 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5268 - loss: 1.5105\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.5318 - loss: 1.4978 - val_accuracy: 0.4060 - val_loss: 2.0490 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.5665 - loss: 1.3881 - val_accuracy: 0.5337 - val_loss: 1.4816 - learning_rate: 5.0000e-04\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5772 - loss: 1.3462 - val_accuracy: 0.5533 - val_loss: 1.4267 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5872 - loss: 1.3249 - val_accuracy: 0.5341 - val_loss: 1.4966 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5939 - loss: 1.3078 - val_accuracy: 0.5655 - val_loss: 1.3936 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 42ms/step - accuracy: 0.6003 - loss: 1.2912 - val_accuracy: 0.5188 - val_loss: 1.5218 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6076 - loss: 1.2758 - val_accuracy: 0.5365 - val_loss: 1.6136 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6165 - loss: 1.2547\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6139 - loss: 1.2621 - val_accuracy: 0.5432 - val_loss: 1.4757 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6381 - loss: 1.1955 - val_accuracy: 0.5775 - val_loss: 1.3643 - learning_rate: 2.5000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6470 - loss: 1.1645 - val_accuracy: 0.5775 - val_loss: 1.4211 - learning_rate: 2.5000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6529 - loss: 1.1473 - val_accuracy: 0.5177 - val_loss: 1.7329 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6566 - loss: 1.1349\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6563 - loss: 1.1333 - val_accuracy: 0.5708 - val_loss: 1.3989 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6772 - loss: 1.0787 - val_accuracy: 0.5828 - val_loss: 1.4066 - learning_rate: 1.2500e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6825 - loss: 1.0578 - val_accuracy: 0.5806 - val_loss: 1.4276 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6883 - loss: 1.0428 - val_accuracy: 0.5962 - val_loss: 1.3572 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6915 - loss: 1.0302 - val_accuracy: 0.5994 - val_loss: 1.3638 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6936 - loss: 1.0238 - val_accuracy: 0.5997 - val_loss: 1.4081 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6969 - loss: 1.0065\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6962 - loss: 1.0108 - val_accuracy: 0.5989 - val_loss: 1.4085 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.7094 - loss: 0.9747 - val_accuracy: 0.5961 - val_loss: 1.3929 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7153 - loss: 0.9590 - val_accuracy: 0.6045 - val_loss: 1.3687 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7166 - loss: 0.9557\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.7171 - loss: 0.9530 - val_accuracy: 0.5698 - val_loss: 1.5656 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.7244 - loss: 0.9306 - val_accuracy: 0.6004 - val_loss: 1.4226 - learning_rate: 3.1250e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7269 - loss: 0.9217 - val_accuracy: 0.6003 - val_loss: 1.4272 - learning_rate: 3.1250e-05\n",
      "Fold 1: Acc Janela=0.5962 | Acc Faixa=0.6400\n",
      "\n",
      "=== Iniciando Fold 2/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 43ms/step - accuracy: 0.4181 - loss: 1.8244 - val_accuracy: 0.3005 - val_loss: 2.8551 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4875 - loss: 1.6154 - val_accuracy: 0.3712 - val_loss: 2.1929 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5136 - loss: 1.5433 - val_accuracy: 0.4669 - val_loss: 1.6733 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.5327 - loss: 1.4959 - val_accuracy: 0.5464 - val_loss: 1.4501 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5457 - loss: 1.4531 - val_accuracy: 0.4296 - val_loss: 1.8475 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5540 - loss: 1.4294 - val_accuracy: 0.4886 - val_loss: 1.6679 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5582 - loss: 1.4154\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.5599 - loss: 1.4105 - val_accuracy: 0.5421 - val_loss: 1.5370 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5888 - loss: 1.3262 - val_accuracy: 0.5656 - val_loss: 1.3972 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5953 - loss: 1.2924 - val_accuracy: 0.5632 - val_loss: 1.5036 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6035 - loss: 1.2721 - val_accuracy: 0.5718 - val_loss: 1.3926 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6064 - loss: 1.2637 - val_accuracy: 0.5866 - val_loss: 1.3373 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6136 - loss: 1.2480 - val_accuracy: 0.5586 - val_loss: 1.4692 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6169 - loss: 1.2421 - val_accuracy: 0.5531 - val_loss: 1.4818 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6246 - loss: 1.2258\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6223 - loss: 1.2321 - val_accuracy: 0.5608 - val_loss: 1.5142 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6410 - loss: 1.1730 - val_accuracy: 0.5974 - val_loss: 1.3389 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6491 - loss: 1.1487 - val_accuracy: 0.6050 - val_loss: 1.3618 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6531 - loss: 1.1343\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6528 - loss: 1.1370 - val_accuracy: 0.5758 - val_loss: 1.5098 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6673 - loss: 1.0917 - val_accuracy: 0.6165 - val_loss: 1.3320 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6706 - loss: 1.0754 - val_accuracy: 0.6028 - val_loss: 1.4138 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6753 - loss: 1.0646 - val_accuracy: 0.6137 - val_loss: 1.3733 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6799 - loss: 1.0509\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6769 - loss: 1.0562 - val_accuracy: 0.5983 - val_loss: 1.4151 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6866 - loss: 1.0267 - val_accuracy: 0.6093 - val_loss: 1.3874 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6892 - loss: 1.0182 - val_accuracy: 0.6096 - val_loss: 1.3456 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6916 - loss: 1.0138 - val_accuracy: 0.6190 - val_loss: 1.3240 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6932 - loss: 1.0049 - val_accuracy: 0.6139 - val_loss: 1.3463 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6933 - loss: 1.0028 - val_accuracy: 0.6123 - val_loss: 1.3603 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6944 - loss: 0.9973\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6967 - loss: 0.9968 - val_accuracy: 0.6072 - val_loss: 1.3968 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.7009 - loss: 0.9780 - val_accuracy: 0.6163 - val_loss: 1.3615 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.7026 - loss: 0.9776 - val_accuracy: 0.6127 - val_loss: 1.3884 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7026 - loss: 0.9719\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7040 - loss: 0.9695 - val_accuracy: 0.6113 - val_loss: 1.3723 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.7055 - loss: 0.9641 - val_accuracy: 0.6171 - val_loss: 1.3663 - learning_rate: 1.5625e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.7093 - loss: 0.9596 - val_accuracy: 0.6161 - val_loss: 1.3696 - learning_rate: 1.5625e-05\n",
      "Fold 2: Acc Janela=0.6190 | Acc Faixa=0.6587\n",
      "\n",
      "=== Iniciando Fold 3/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4157 - loss: 1.8334 - val_accuracy: 0.4091 - val_loss: 1.8741 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 42ms/step - accuracy: 0.4818 - loss: 1.6260 - val_accuracy: 0.4649 - val_loss: 1.6457 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5095 - loss: 1.5540 - val_accuracy: 0.4550 - val_loss: 1.6705 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5281 - loss: 1.5051 - val_accuracy: 0.4927 - val_loss: 1.6318 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5399 - loss: 1.4655 - val_accuracy: 0.5198 - val_loss: 1.5886 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5474 - loss: 1.4404 - val_accuracy: 0.5183 - val_loss: 1.5643 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5582 - loss: 1.4188 - val_accuracy: 0.4864 - val_loss: 1.6322 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5632 - loss: 1.4044 - val_accuracy: 0.5403 - val_loss: 1.5034 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5693 - loss: 1.3913 - val_accuracy: 0.5243 - val_loss: 1.4799 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5742 - loss: 1.3802 - val_accuracy: 0.5136 - val_loss: 1.6738 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5747 - loss: 1.3764 - val_accuracy: 0.5731 - val_loss: 1.4259 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5800 - loss: 1.3674 - val_accuracy: 0.5265 - val_loss: 1.5603 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5836 - loss: 1.3615 - val_accuracy: 0.5848 - val_loss: 1.3525 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5849 - loss: 1.3533 - val_accuracy: 0.5774 - val_loss: 1.4032 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5858 - loss: 1.3511 - val_accuracy: 0.5716 - val_loss: 1.3874 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5878 - loss: 1.3493\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5893 - loss: 1.3461 - val_accuracy: 0.5713 - val_loss: 1.4787 - learning_rate: 0.0010\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6129 - loss: 1.2741 - val_accuracy: 0.5815 - val_loss: 1.3912 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6221 - loss: 1.2443 - val_accuracy: 0.5998 - val_loss: 1.3397 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6242 - loss: 1.2340 - val_accuracy: 0.5557 - val_loss: 1.4402 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6261 - loss: 1.2251 - val_accuracy: 0.5735 - val_loss: 1.4294 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6296 - loss: 1.2117\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6281 - loss: 1.2162 - val_accuracy: 0.5851 - val_loss: 1.4143 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6465 - loss: 1.1600 - val_accuracy: 0.6004 - val_loss: 1.3433 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6530 - loss: 1.1422 - val_accuracy: 0.6168 - val_loss: 1.2838 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6565 - loss: 1.1296 - val_accuracy: 0.6155 - val_loss: 1.2765 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6582 - loss: 1.1210 - val_accuracy: 0.5877 - val_loss: 1.3998 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6605 - loss: 1.1128 - val_accuracy: 0.5702 - val_loss: 1.5794 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6674 - loss: 1.0957\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6639 - loss: 1.1032 - val_accuracy: 0.6056 - val_loss: 1.3379 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6764 - loss: 1.0672 - val_accuracy: 0.5970 - val_loss: 1.4088 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6803 - loss: 1.0551 - val_accuracy: 0.6095 - val_loss: 1.3444 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6835 - loss: 1.0446\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6824 - loss: 1.0467 - val_accuracy: 0.6229 - val_loss: 1.2924 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6913 - loss: 1.0187 - val_accuracy: 0.6260 - val_loss: 1.2808 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6935 - loss: 1.0133 - val_accuracy: 0.6188 - val_loss: 1.2959 - learning_rate: 6.2500e-05\n",
      "Fold 3: Acc Janela=0.6155 | Acc Faixa=0.6500\n",
      "\n",
      "=== Iniciando Fold 4/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 43ms/step - accuracy: 0.4207 - loss: 1.8336 - val_accuracy: 0.3169 - val_loss: 2.0851 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 42ms/step - accuracy: 0.4925 - loss: 1.6116 - val_accuracy: 0.4691 - val_loss: 1.6169 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5158 - loss: 1.5452 - val_accuracy: 0.5322 - val_loss: 1.5083 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5337 - loss: 1.4914 - val_accuracy: 0.4759 - val_loss: 1.7701 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5478 - loss: 1.4547 - val_accuracy: 0.3363 - val_loss: 2.9267 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5549 - loss: 1.4311 - val_accuracy: 0.5398 - val_loss: 1.4968 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5664 - loss: 1.4032 - val_accuracy: 0.4972 - val_loss: 1.6152 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5706 - loss: 1.3906 - val_accuracy: 0.4784 - val_loss: 1.7451 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5745 - loss: 1.3790 - val_accuracy: 0.5437 - val_loss: 1.4714 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5772 - loss: 1.3731 - val_accuracy: 0.5372 - val_loss: 1.5314 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5808 - loss: 1.3651 - val_accuracy: 0.5466 - val_loss: 1.5321 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5830 - loss: 1.3603\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5841 - loss: 1.3580 - val_accuracy: 0.4262 - val_loss: 1.9227 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6092 - loss: 1.2804 - val_accuracy: 0.5437 - val_loss: 1.4623 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6146 - loss: 1.2576 - val_accuracy: 0.5676 - val_loss: 1.4604 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6186 - loss: 1.2428 - val_accuracy: 0.5742 - val_loss: 1.4300 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6207 - loss: 1.2342 - val_accuracy: 0.5642 - val_loss: 1.4367 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6236 - loss: 1.2257 - val_accuracy: 0.5644 - val_loss: 1.4979 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6243 - loss: 1.2207 - val_accuracy: 0.6026 - val_loss: 1.3046 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6280 - loss: 1.2150 - val_accuracy: 0.5767 - val_loss: 1.3923 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6301 - loss: 1.2102 - val_accuracy: 0.5666 - val_loss: 1.4651 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6298 - loss: 1.2093\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6315 - loss: 1.2082 - val_accuracy: 0.6019 - val_loss: 1.3426 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6511 - loss: 1.1475 - val_accuracy: 0.6086 - val_loss: 1.3156 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6568 - loss: 1.1270 - val_accuracy: 0.5997 - val_loss: 1.3771 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6642 - loss: 1.1150\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6610 - loss: 1.1168 - val_accuracy: 0.6050 - val_loss: 1.3538 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6725 - loss: 1.0742 - val_accuracy: 0.5975 - val_loss: 1.3935 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6768 - loss: 1.0621 - val_accuracy: 0.6141 - val_loss: 1.3299 - learning_rate: 1.2500e-04\n",
      "Fold 4: Acc Janela=0.6026 | Acc Faixa=0.6450\n",
      "\n",
      "=== Iniciando Fold 5/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 43ms/step - accuracy: 0.4223 - loss: 1.8225 - val_accuracy: 0.4219 - val_loss: 1.7085 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 42ms/step - accuracy: 0.4919 - loss: 1.6090 - val_accuracy: 0.4656 - val_loss: 1.7230 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5162 - loss: 1.5437 - val_accuracy: 0.5006 - val_loss: 1.5634 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5319 - loss: 1.4964 - val_accuracy: 0.5197 - val_loss: 1.5490 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5466 - loss: 1.4595 - val_accuracy: 0.5180 - val_loss: 1.5135 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5523 - loss: 1.4363 - val_accuracy: 0.4875 - val_loss: 1.6711 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5620 - loss: 1.4126 - val_accuracy: 0.5399 - val_loss: 1.4783 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5699 - loss: 1.3964 - val_accuracy: 0.5353 - val_loss: 1.5042 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5721 - loss: 1.3888 - val_accuracy: 0.5539 - val_loss: 1.4434 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5766 - loss: 1.3739 - val_accuracy: 0.5597 - val_loss: 1.4558 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5797 - loss: 1.3678 - val_accuracy: 0.5552 - val_loss: 1.4616 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5807 - loss: 1.3654\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5825 - loss: 1.3622 - val_accuracy: 0.5380 - val_loss: 1.4555 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6055 - loss: 1.2871 - val_accuracy: 0.5867 - val_loss: 1.3638 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6144 - loss: 1.2568 - val_accuracy: 0.5640 - val_loss: 1.4630 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6158 - loss: 1.2449 - val_accuracy: 0.6093 - val_loss: 1.2812 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6207 - loss: 1.2354 - val_accuracy: 0.5924 - val_loss: 1.3139 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6245 - loss: 1.2259 - val_accuracy: 0.5818 - val_loss: 1.3866 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6235 - loss: 1.2244\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6261 - loss: 1.2222 - val_accuracy: 0.5827 - val_loss: 1.4025 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6456 - loss: 1.1635 - val_accuracy: 0.6129 - val_loss: 1.3161 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6505 - loss: 1.1470 - val_accuracy: 0.6042 - val_loss: 1.3217 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6532 - loss: 1.1375\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6544 - loss: 1.1336 - val_accuracy: 0.6086 - val_loss: 1.3216 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6657 - loss: 1.0954 - val_accuracy: 0.6340 - val_loss: 1.2481 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6722 - loss: 1.0790 - val_accuracy: 0.6187 - val_loss: 1.2956 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6734 - loss: 1.0727 - val_accuracy: 0.6144 - val_loss: 1.3621 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6784 - loss: 1.0606\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6764 - loss: 1.0645 - val_accuracy: 0.6248 - val_loss: 1.2568 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6835 - loss: 1.0427 - val_accuracy: 0.6345 - val_loss: 1.2637 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6863 - loss: 1.0311 - val_accuracy: 0.6203 - val_loss: 1.3105 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6882 - loss: 1.0197\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6869 - loss: 1.0227 - val_accuracy: 0.6312 - val_loss: 1.2612 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6930 - loss: 1.0092 - val_accuracy: 0.6215 - val_loss: 1.2985 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6923 - loss: 1.0106 - val_accuracy: 0.6246 - val_loss: 1.2939 - learning_rate: 3.1250e-05\n",
      "Fold 5: Acc Janela=0.6340 | Acc Faixa=0.6721\n",
      "\n",
      "=== Iniciando Fold 6/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 43ms/step - accuracy: 0.4114 - loss: 1.8351 - val_accuracy: 0.3479 - val_loss: 2.3408 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4887 - loss: 1.6142 - val_accuracy: 0.4381 - val_loss: 1.7329 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5161 - loss: 1.5449 - val_accuracy: 0.3984 - val_loss: 2.0714 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 44ms/step - accuracy: 0.5325 - loss: 1.4965 - val_accuracy: 0.5271 - val_loss: 1.5219 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5448 - loss: 1.4624 - val_accuracy: 0.4523 - val_loss: 1.9014 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5532 - loss: 1.4329 - val_accuracy: 0.5205 - val_loss: 1.5140 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5594 - loss: 1.4165 - val_accuracy: 0.5421 - val_loss: 1.5354 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5659 - loss: 1.3999 - val_accuracy: 0.5392 - val_loss: 1.4990 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5698 - loss: 1.3902 - val_accuracy: 0.4795 - val_loss: 1.6398 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5759 - loss: 1.3797 - val_accuracy: 0.5240 - val_loss: 1.5006 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5778 - loss: 1.3682\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5774 - loss: 1.3716 - val_accuracy: 0.4011 - val_loss: 2.2596 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6027 - loss: 1.2928 - val_accuracy: 0.5782 - val_loss: 1.3590 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6099 - loss: 1.2661 - val_accuracy: 0.5490 - val_loss: 1.4864 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6130 - loss: 1.2491 - val_accuracy: 0.6107 - val_loss: 1.2997 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6173 - loss: 1.2421 - val_accuracy: 0.5653 - val_loss: 1.4312 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6228 - loss: 1.2290 - val_accuracy: 0.5933 - val_loss: 1.3617 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6257 - loss: 1.2222\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6259 - loss: 1.2249 - val_accuracy: 0.5691 - val_loss: 1.4668 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6456 - loss: 1.1655 - val_accuracy: 0.6167 - val_loss: 1.2788 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6522 - loss: 1.1395 - val_accuracy: 0.5915 - val_loss: 1.4402 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6569 - loss: 1.1267 - val_accuracy: 0.6203 - val_loss: 1.2955 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6581 - loss: 1.1207\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6572 - loss: 1.1223 - val_accuracy: 0.6150 - val_loss: 1.2934 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6745 - loss: 1.0765 - val_accuracy: 0.6179 - val_loss: 1.3122 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6767 - loss: 1.0671 - val_accuracy: 0.6129 - val_loss: 1.3144 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6843 - loss: 1.0467\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6789 - loss: 1.0553 - val_accuracy: 0.6172 - val_loss: 1.2972 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6880 - loss: 1.0285 - val_accuracy: 0.6184 - val_loss: 1.2964 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6908 - loss: 1.0192 - val_accuracy: 0.6210 - val_loss: 1.2955 - learning_rate: 6.2500e-05\n",
      "Fold 6: Acc Janela=0.6167 | Acc Faixa=0.6646\n",
      "\n",
      "=== Iniciando Fold 7/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.3952 - loss: 1.8510 - val_accuracy: 0.4187 - val_loss: 1.8112 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4843 - loss: 1.6131 - val_accuracy: 0.4780 - val_loss: 1.6451 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5129 - loss: 1.5451 - val_accuracy: 0.4822 - val_loss: 1.6712 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5297 - loss: 1.4959 - val_accuracy: 0.4952 - val_loss: 1.6127 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5425 - loss: 1.4576 - val_accuracy: 0.4973 - val_loss: 1.6317 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5534 - loss: 1.4299 - val_accuracy: 0.4922 - val_loss: 1.6285 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5607 - loss: 1.4129 - val_accuracy: 0.5391 - val_loss: 1.4754 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5645 - loss: 1.3973 - val_accuracy: 0.5364 - val_loss: 1.5666 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5735 - loss: 1.3818 - val_accuracy: 0.5627 - val_loss: 1.4414 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5755 - loss: 1.3756 - val_accuracy: 0.5663 - val_loss: 1.4748 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5751 - loss: 1.3685 - val_accuracy: 0.5550 - val_loss: 1.4443 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5815 - loss: 1.3585\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5812 - loss: 1.3602 - val_accuracy: 0.5503 - val_loss: 1.5287 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6047 - loss: 1.2866 - val_accuracy: 0.5679 - val_loss: 1.4561 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6100 - loss: 1.2605 - val_accuracy: 0.5948 - val_loss: 1.3341 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6136 - loss: 1.2510 - val_accuracy: 0.5642 - val_loss: 1.4511 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6176 - loss: 1.2422 - val_accuracy: 0.5752 - val_loss: 1.4579 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6190 - loss: 1.2347\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6182 - loss: 1.2353 - val_accuracy: 0.5667 - val_loss: 1.4488 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6388 - loss: 1.1809 - val_accuracy: 0.5670 - val_loss: 1.5210 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6435 - loss: 1.1611 - val_accuracy: 0.5463 - val_loss: 1.6437 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6467 - loss: 1.1461\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6457 - loss: 1.1498 - val_accuracy: 0.5870 - val_loss: 1.4094 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6583 - loss: 1.1126 - val_accuracy: 0.6168 - val_loss: 1.3328 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6636 - loss: 1.0964 - val_accuracy: 0.5911 - val_loss: 1.4338 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6654 - loss: 1.0851 - val_accuracy: 0.5906 - val_loss: 1.4290 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6717 - loss: 1.0755\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6679 - loss: 1.0810 - val_accuracy: 0.6023 - val_loss: 1.3465 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6754 - loss: 1.0572 - val_accuracy: 0.6134 - val_loss: 1.3295 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6764 - loss: 1.0513 - val_accuracy: 0.6153 - val_loss: 1.3148 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6789 - loss: 1.0445 - val_accuracy: 0.6180 - val_loss: 1.3061 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6777 - loss: 1.0443 - val_accuracy: 0.6086 - val_loss: 1.3456 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6808 - loss: 1.0335 - val_accuracy: 0.6154 - val_loss: 1.3403 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m2779/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6856 - loss: 1.0260\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6831 - loss: 1.0325 - val_accuracy: 0.6122 - val_loss: 1.3251 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6891 - loss: 1.0176 - val_accuracy: 0.6162 - val_loss: 1.3176 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6886 - loss: 1.0169 - val_accuracy: 0.6180 - val_loss: 1.3310 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6878 - loss: 1.0143\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6886 - loss: 1.0126 - val_accuracy: 0.6134 - val_loss: 1.3472 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6920 - loss: 1.0007 - val_accuracy: 0.6153 - val_loss: 1.3416 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6937 - loss: 0.9996 - val_accuracy: 0.6200 - val_loss: 1.3350 - learning_rate: 1.5625e-05\n",
      "Fold 7: Acc Janela=0.6180 | Acc Faixa=0.6558\n",
      "\n",
      "=== Iniciando Fold 8/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4079 - loss: 1.8393 - val_accuracy: 0.3781 - val_loss: 1.8755 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4846 - loss: 1.6186 - val_accuracy: 0.3919 - val_loss: 1.7968 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5128 - loss: 1.5422 - val_accuracy: 0.3672 - val_loss: 1.9905 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5366 - loss: 1.4846 - val_accuracy: 0.5086 - val_loss: 1.5098 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5481 - loss: 1.4510 - val_accuracy: 0.4973 - val_loss: 1.6094 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5585 - loss: 1.4235 - val_accuracy: 0.5361 - val_loss: 1.4370 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5652 - loss: 1.4029 - val_accuracy: 0.4775 - val_loss: 1.6785 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5707 - loss: 1.3917 - val_accuracy: 0.5383 - val_loss: 1.4449 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5743 - loss: 1.3815\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5747 - loss: 1.3797 - val_accuracy: 0.4991 - val_loss: 1.6200 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6006 - loss: 1.3003 - val_accuracy: 0.5315 - val_loss: 1.5225 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6091 - loss: 1.2722 - val_accuracy: 0.5724 - val_loss: 1.3644 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6155 - loss: 1.2522 - val_accuracy: 0.5522 - val_loss: 1.4460 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6187 - loss: 1.2427 - val_accuracy: 0.5540 - val_loss: 1.4502 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6223 - loss: 1.2322\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6233 - loss: 1.2327 - val_accuracy: 0.5662 - val_loss: 1.4056 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6439 - loss: 1.1705 - val_accuracy: 0.5743 - val_loss: 1.4465 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6482 - loss: 1.1519 - val_accuracy: 0.5845 - val_loss: 1.3861 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6533 - loss: 1.1396\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6532 - loss: 1.1368 - val_accuracy: 0.5749 - val_loss: 1.3810 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6676 - loss: 1.0946 - val_accuracy: 0.5975 - val_loss: 1.3409 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6724 - loss: 1.0787 - val_accuracy: 0.5945 - val_loss: 1.3585 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6779 - loss: 1.0626 - val_accuracy: 0.5997 - val_loss: 1.3470 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6780 - loss: 1.0603\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6790 - loss: 1.0594 - val_accuracy: 0.5761 - val_loss: 1.5031 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6861 - loss: 1.0310 - val_accuracy: 0.5874 - val_loss: 1.3966 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6889 - loss: 1.0218 - val_accuracy: 0.6023 - val_loss: 1.3440 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6917 - loss: 1.0181\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6906 - loss: 1.0160 - val_accuracy: 0.5981 - val_loss: 1.3496 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6967 - loss: 1.0021 - val_accuracy: 0.6023 - val_loss: 1.3463 - learning_rate: 3.1250e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6969 - loss: 0.9965 - val_accuracy: 0.6026 - val_loss: 1.3573 - learning_rate: 3.1250e-05\n",
      "Fold 8: Acc Janela=0.5975 | Acc Faixa=0.6446\n",
      "\n",
      "=== Iniciando Fold 9/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4163 - loss: 1.8286 - val_accuracy: 0.3009 - val_loss: 2.0002 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4964 - loss: 1.6029 - val_accuracy: 0.4698 - val_loss: 1.6695 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5227 - loss: 1.5307 - val_accuracy: 0.4774 - val_loss: 1.6179 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5343 - loss: 1.4898 - val_accuracy: 0.4387 - val_loss: 1.8465 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5464 - loss: 1.4563 - val_accuracy: 0.5421 - val_loss: 1.4693 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5556 - loss: 1.4285 - val_accuracy: 0.5412 - val_loss: 1.5498 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5604 - loss: 1.4109 - val_accuracy: 0.5085 - val_loss: 1.5720 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5618 - loss: 1.4057\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5661 - loss: 1.3962 - val_accuracy: 0.5051 - val_loss: 1.5836 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5950 - loss: 1.3089 - val_accuracy: 0.4785 - val_loss: 1.7426 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6032 - loss: 1.2779 - val_accuracy: 0.5953 - val_loss: 1.3133 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6111 - loss: 1.2602 - val_accuracy: 0.5631 - val_loss: 1.4394 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6133 - loss: 1.2496 - val_accuracy: 0.5611 - val_loss: 1.4362 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6153 - loss: 1.2443\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6197 - loss: 1.2414 - val_accuracy: 0.5676 - val_loss: 1.4128 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6393 - loss: 1.1812 - val_accuracy: 0.6065 - val_loss: 1.3416 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6451 - loss: 1.1556 - val_accuracy: 0.5860 - val_loss: 1.3601 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6524 - loss: 1.1327\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6484 - loss: 1.1414 - val_accuracy: 0.6093 - val_loss: 1.3192 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6660 - loss: 1.0967 - val_accuracy: 0.5988 - val_loss: 1.3475 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6694 - loss: 1.0774 - val_accuracy: 0.6031 - val_loss: 1.3602 - learning_rate: 1.2500e-04\n",
      "Fold 9: Acc Janela=0.5953 | Acc Faixa=0.6421\n",
      "\n",
      "=== Iniciando Fold 10/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 43ms/step - accuracy: 0.4076 - loss: 1.8423 - val_accuracy: 0.3832 - val_loss: 1.8269 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4822 - loss: 1.6280 - val_accuracy: 0.4786 - val_loss: 1.6466 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.5130 - loss: 1.5499 - val_accuracy: 0.3694 - val_loss: 1.9236 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5303 - loss: 1.5002 - val_accuracy: 0.5372 - val_loss: 1.4498 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5416 - loss: 1.4638 - val_accuracy: 0.4755 - val_loss: 1.6720 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5527 - loss: 1.4368 - val_accuracy: 0.4782 - val_loss: 1.6038 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5561 - loss: 1.4214\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5582 - loss: 1.4167 - val_accuracy: 0.5666 - val_loss: 1.4722 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5858 - loss: 1.3336 - val_accuracy: 0.5424 - val_loss: 1.4592 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5945 - loss: 1.3027 - val_accuracy: 0.5691 - val_loss: 1.4567 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6011 - loss: 1.2825 - val_accuracy: 0.5852 - val_loss: 1.3389 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.6060 - loss: 1.2721 - val_accuracy: 0.5134 - val_loss: 1.6692 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6108 - loss: 1.2625 - val_accuracy: 0.5077 - val_loss: 1.5886 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6138 - loss: 1.2521\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6154 - loss: 1.2509 - val_accuracy: 0.5521 - val_loss: 1.4483 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6357 - loss: 1.1889 - val_accuracy: 0.6170 - val_loss: 1.2696 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6423 - loss: 1.1636 - val_accuracy: 0.6184 - val_loss: 1.2571 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6484 - loss: 1.1467 - val_accuracy: 0.6063 - val_loss: 1.3023 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6520 - loss: 1.1377 - val_accuracy: 0.6007 - val_loss: 1.3514 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6566 - loss: 1.1229\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6558 - loss: 1.1256 - val_accuracy: 0.6154 - val_loss: 1.3044 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6694 - loss: 1.0851 - val_accuracy: 0.6083 - val_loss: 1.3116 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6768 - loss: 1.0653 - val_accuracy: 0.6209 - val_loss: 1.2783 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6796 - loss: 1.0474\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6779 - loss: 1.0528 - val_accuracy: 0.6037 - val_loss: 1.3971 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6893 - loss: 1.0230 - val_accuracy: 0.6282 - val_loss: 1.2529 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6927 - loss: 1.0128 - val_accuracy: 0.6271 - val_loss: 1.2546 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6930 - loss: 1.0093 - val_accuracy: 0.6137 - val_loss: 1.3202 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6972 - loss: 0.9955\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6958 - loss: 1.0005 - val_accuracy: 0.6239 - val_loss: 1.2688 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7026 - loss: 0.9815 - val_accuracy: 0.6306 - val_loss: 1.2717 - learning_rate: 3.1250e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7030 - loss: 0.9753 - val_accuracy: 0.6284 - val_loss: 1.2680 - learning_rate: 3.1250e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7066 - loss: 0.9694\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.7057 - loss: 0.9719 - val_accuracy: 0.6294 - val_loss: 1.2859 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7087 - loss: 0.9629 - val_accuracy: 0.6273 - val_loss: 1.2903 - learning_rate: 1.5625e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7073 - loss: 0.9637 - val_accuracy: 0.6280 - val_loss: 1.2910 - learning_rate: 1.5625e-05\n",
      "Fold 10: Acc Janela=0.6282 | Acc Faixa=0.6721\n",
      "\n",
      "--- CV Concluído ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 32 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "def apply_spec_augment(spectrogram, time_mask_param=20, freq_mask_param=15, num_masks=1):\n",
    "    \"\"\"\n",
    "    Aplica mascaramento de tempo e frequência no espectrograma.\n",
    "    Entrada: (128, 130, 1) ou (128, 130)\n",
    "    \"\"\"\n",
    "    # Garante que é uma cópia para não alterar o original\n",
    "    aug_spec = spectrogram.copy()\n",
    "    \n",
    "    # Se tiver canal (H, W, C), remove para processar\n",
    "    if aug_spec.ndim == 3:\n",
    "        aug_spec = aug_spec[:, :, 0]\n",
    "        \n",
    "    n_mels, n_steps = aug_spec.shape\n",
    "    \n",
    "    # Mascaramento de Frequência\n",
    "    for _ in range(num_masks):\n",
    "        f = np.random.randint(0, freq_mask_param)\n",
    "        f0 = np.random.randint(0, n_mels - f)\n",
    "        aug_spec[f0:f0+f, :] = 0\n",
    "        \n",
    "    # Mascaramento de Tempo\n",
    "    for _ in range(num_masks):\n",
    "        t = np.random.randint(0, time_mask_param)\n",
    "        t0 = np.random.randint(0, n_steps - t)\n",
    "        aug_spec[:, t0:t0+t] = 0\n",
    "        \n",
    "    # Retorna dimensão do canal\n",
    "    return aug_spec[..., np.newaxis]\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size, augment=False):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            original_shape = X_batch.shape\n",
    "            X_b_flat = X_batch.reshape(original_shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(original_shape)\n",
    "            \n",
    "            # Aplica Augmentation apenas no Treino\n",
    "            if augment:\n",
    "                X_b_final = np.array([apply_spec_augment(x) for x in X_b_scaled])\n",
    "            else:\n",
    "                X_b_final = X_b_scaled\n",
    "            \n",
    "            yield X_b_final, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"\\n=== Iniciando Fold {fold+1}/{n_splits} ===\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "\n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=0.004)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino com SpecAugmentation\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE, augment=True)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\n",
      "Acurácia Média (10-Fold CV): 0.6545 +/- 0.0115\n",
      "\n",
      "--- Relatório de Classificação (Nível Faixa) ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.66      0.72      0.69       999\n",
      " Experimental       0.62      0.47      0.53       999\n",
      "         Folk       0.63      0.75      0.68      1000\n",
      "      Hip-Hop       0.78      0.82      0.80       997\n",
      " Instrumental       0.61      0.63      0.62      1000\n",
      "International       0.75      0.78      0.76      1000\n",
      "          Pop       0.47      0.35      0.40      1000\n",
      "         Rock       0.65      0.73      0.69       999\n",
      "\n",
      "     accuracy                           0.65      7994\n",
      "    macro avg       0.65      0.65      0.65      7994\n",
      " weighted avg       0.65      0.65      0.65      7994\n",
      "\n",
      "\n",
      "--- Matriz de Confusão (Nível Faixa) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
