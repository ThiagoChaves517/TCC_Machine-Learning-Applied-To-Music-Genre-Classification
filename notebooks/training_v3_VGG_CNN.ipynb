{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils  # Do seu utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados carregados para 8000 faixas 'small'.\n",
      "Gêneros: ['Electronic' 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental'\n",
      " 'International' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_3s_25overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_3s_25overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 3\n",
    "OVERLAP_PERCENT = 0.25\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição (lógica do v2)\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando espectrogramas cacheados de ../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy...\n",
      "Arquivos carregados.\n",
      "Shape de X (amostras, n_mels, frames): (99278, 128, 130)\n",
      "Shape de y (labels): (99278,)\n",
      "Shape de groups (track_ids): (99278,)\n"
     ]
    }
   ],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados. Iniciando extração (2 passagens)...\")\n",
    "    \n",
    "    # --- PASSAGEM 1: Contar o número total de janelas ---\n",
    "    \n",
    "    def get_window_count(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT):\n",
    "        # Esta função é mais leve, apenas carrega o áudio e conta os frames\n",
    "        try:\n",
    "            y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "            samples_per_window = window_size_sec * sr\n",
    "            if len(y) < samples_per_window: return 0\n",
    "            hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "            y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "            return y_frames.shape[0] # Retorna o número de janelas\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        if not os.path.exists(file_path): continue\n",
    "            \n",
    "        n_janelas = get_window_count(file_path)\n",
    "        if n_janelas > 0:\n",
    "            total_janelas += n_janelas\n",
    "            all_track_ids_para_contagem.append((track_id, row, n_janelas))\n",
    "\n",
    "    print(f\"\\nContagem concluída. Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- PASSAGEM 2: Extrair e Salvar em Arrays (memmap) ---\n",
    "    \n",
    "    # Usa o SPEC_SHAPE definido na Célula 3 (ex: (128, 130))\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    \n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita_atual = 0\n",
    "    \n",
    "    for track_id, row, n_janelas in tqdm(all_track_ids_para_contagem):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "        \n",
    "        for i, spec in enumerate(window_specs):\n",
    "            if i >= n_janelas: break \n",
    "            \n",
    "            X_np_memmap[idx_escrita_atual] = spec\n",
    "            y_encoded_np_temp[idx_escrita_atual] = row['genre_encoded']\n",
    "            groups_np_temp[idx_escrita_atual] = track_id\n",
    "            idx_escrita_atual += 1\n",
    "    \n",
    "    # 1. Salva o X (lendo do memmap e salvando como .npy)\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap)\n",
    "    \n",
    "    # 2. Fecha e deleta o arquivo memmap temporário\n",
    "    del X_np_memmap\n",
    "    os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    # 3. Salva os outros arrays\n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    print(f\"Extração concluída. Arquivos salvos.\")\n",
    "    \n",
    "    # 4. Agora, carregamos as variáveis (do .npy recém-criado)\n",
    "    print(f\"Carregando arquivos recém-criados do cache...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r') # <-- Esta linha agora funcionará\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:11:00.047478: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 16:11:00.476598: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-23 16:11:02.146409: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Growth habilitado para: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X para CNN (amostras, altura, largura, canais): (99278, 128, 130, 1)\n",
      "Shape de y (one-hot): (99278, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, \n",
    "                                     BatchNormalization, Dropout, \n",
    "                                     GlobalAveragePooling2D, Dense, Activation)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763928663.092560    5888 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,243,368</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,243,368\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,241,448</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,241,448\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Arquitetura inspirada na VGG, otimizada para Mel-Espectrogramas.\n",
    "    Usa GlobalAveragePooling para reduzir parâmetros na camada densa.\n",
    "    \"\"\"\n",
    "    weight_decay = 0.0005  # Regularização L2 para evitar overfitting\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=input_shape))\n",
    "\n",
    "    # --- Bloco 1 (Recursos de Baixo Nível / Timbre) ---\n",
    "    # 32 Filtros\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # --- Bloco 2 ---\n",
    "    # 64 Filtros\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 3 ---\n",
    "    # 128 Filtros\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 4 (Recursos de Alto Nível / Estrutura) ---\n",
    "    # 256 Filtros - Aprofundando, mas parando aqui para economizar VRAM\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    # --- Classificador (Head) ---\n",
    "    # Global Average Pooling \n",
    "    # Transforma (H, W, 256) -> vetor de (256)\n",
    "    model.add(GlobalAveragePooling2D()) \n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax', dtype='float32'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Precision ativado: mixed_float16\n",
      "\n",
      "=== Iniciando Fold 1/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 16:11:30.949538: I external/local_xla/xla/service/service.cc:163] XLA service 0x7cae04009ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-23 16:11:30.949570: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-11-23 16:11:31.076630: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-23 16:11:31.684242: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
      "2025-11-23 16:11:32.084466: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-11-23 16:11:32.811663: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5747', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-11-23 16:11:33.250198: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_5747', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "I0000 00:00:1763928706.463115    6009 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 44ms/step - accuracy: 0.4207 - loss: 1.8272 - val_accuracy: 0.3412 - val_loss: 2.2892 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 43ms/step - accuracy: 0.4911 - loss: 1.6089 - val_accuracy: 0.2667 - val_loss: 2.9220 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5136 - loss: 1.5471 - val_accuracy: 0.4803 - val_loss: 1.7763 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5307 - loss: 1.4978 - val_accuracy: 0.5101 - val_loss: 1.5789 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5448 - loss: 1.4581 - val_accuracy: 0.4797 - val_loss: 1.6902 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5554 - loss: 1.4334 - val_accuracy: 0.5174 - val_loss: 1.5115 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.5627 - loss: 1.4081 - val_accuracy: 0.4621 - val_loss: 1.6830 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5681 - loss: 1.3950 - val_accuracy: 0.4943 - val_loss: 1.5918 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5736 - loss: 1.3841\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.5744 - loss: 1.3806 - val_accuracy: 0.4896 - val_loss: 1.7477 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6006 - loss: 1.2970 - val_accuracy: 0.5245 - val_loss: 1.5643 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6096 - loss: 1.2670 - val_accuracy: 0.5698 - val_loss: 1.4073 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6136 - loss: 1.2538 - val_accuracy: 0.5823 - val_loss: 1.3184 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6158 - loss: 1.2438 - val_accuracy: 0.5654 - val_loss: 1.3840 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6182 - loss: 1.2373 - val_accuracy: 0.5706 - val_loss: 1.4445 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6257 - loss: 1.2222\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6235 - loss: 1.2269 - val_accuracy: 0.5554 - val_loss: 1.4876 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6430 - loss: 1.1725 - val_accuracy: 0.5991 - val_loss: 1.3329 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6486 - loss: 1.1511 - val_accuracy: 0.5717 - val_loss: 1.3980 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6516 - loss: 1.1368\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6512 - loss: 1.1384 - val_accuracy: 0.5931 - val_loss: 1.3963 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6663 - loss: 1.0954 - val_accuracy: 0.5823 - val_loss: 1.4769 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6721 - loss: 1.0784 - val_accuracy: 0.6030 - val_loss: 1.3576 - learning_rate: 1.2500e-04\n",
      "Fold 1: Acc Janela=0.5823 | Acc Faixa=0.6100\n",
      "\n",
      "=== Iniciando Fold 2/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 44ms/step - accuracy: 0.4198 - loss: 1.8274 - val_accuracy: 0.3809 - val_loss: 2.1858 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 43ms/step - accuracy: 0.4895 - loss: 1.6104 - val_accuracy: 0.5090 - val_loss: 1.5432 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 44ms/step - accuracy: 0.5153 - loss: 1.5401 - val_accuracy: 0.4660 - val_loss: 1.7408 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5368 - loss: 1.4880 - val_accuracy: 0.4391 - val_loss: 1.9375 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5478 - loss: 1.4568\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5487 - loss: 1.4532 - val_accuracy: 0.5162 - val_loss: 1.5554 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.5781 - loss: 1.3548 - val_accuracy: 0.5601 - val_loss: 1.4280 - learning_rate: 5.0000e-04\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5868 - loss: 1.3181 - val_accuracy: 0.5397 - val_loss: 1.5602 - learning_rate: 5.0000e-04\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5952 - loss: 1.2973 - val_accuracy: 0.5660 - val_loss: 1.3945 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5978 - loss: 1.2854 - val_accuracy: 0.5613 - val_loss: 1.4530 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6042 - loss: 1.2729 - val_accuracy: 0.5880 - val_loss: 1.3640 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6100 - loss: 1.2611 - val_accuracy: 0.5423 - val_loss: 1.4963 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6154 - loss: 1.2523 - val_accuracy: 0.5466 - val_loss: 1.4874 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6182 - loss: 1.2488\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6178 - loss: 1.2501 - val_accuracy: 0.5669 - val_loss: 1.4298 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6406 - loss: 1.1790 - val_accuracy: 0.5752 - val_loss: 1.4210 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6499 - loss: 1.1483 - val_accuracy: 0.5877 - val_loss: 1.4160 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6525 - loss: 1.1395\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6536 - loss: 1.1373 - val_accuracy: 0.5828 - val_loss: 1.4332 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6718 - loss: 1.0863 - val_accuracy: 0.6058 - val_loss: 1.3304 - learning_rate: 1.2500e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6769 - loss: 1.0678 - val_accuracy: 0.6000 - val_loss: 1.3764 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6811 - loss: 1.0569 - val_accuracy: 0.6010 - val_loss: 1.3870 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6842 - loss: 1.0445\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6850 - loss: 1.0415 - val_accuracy: 0.5984 - val_loss: 1.3820 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6943 - loss: 1.0107 - val_accuracy: 0.6042 - val_loss: 1.4063 - learning_rate: 6.2500e-05\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6982 - loss: 0.9991 - val_accuracy: 0.6059 - val_loss: 1.3832 - learning_rate: 6.2500e-05\n",
      "Epoch 23/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6956 - loss: 1.0000\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6976 - loss: 0.9968 - val_accuracy: 0.5903 - val_loss: 1.4549 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.7056 - loss: 0.9764 - val_accuracy: 0.6070 - val_loss: 1.3814 - learning_rate: 3.1250e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.7087 - loss: 0.9678 - val_accuracy: 0.6040 - val_loss: 1.3922 - learning_rate: 3.1250e-05\n",
      "Fold 2: Acc Janela=0.6058 | Acc Faixa=0.6450\n",
      "\n",
      "=== Iniciando Fold 3/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 46ms/step - accuracy: 0.3988 - loss: 1.8517 - val_accuracy: 0.4284 - val_loss: 1.7889 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 45ms/step - accuracy: 0.4818 - loss: 1.6170 - val_accuracy: 0.3733 - val_loss: 2.4070 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5078 - loss: 1.5466 - val_accuracy: 0.4839 - val_loss: 1.6671 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 44ms/step - accuracy: 0.5249 - loss: 1.5015 - val_accuracy: 0.4926 - val_loss: 1.7203 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5363 - loss: 1.4643 - val_accuracy: 0.5184 - val_loss: 1.5654 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5470 - loss: 1.4398 - val_accuracy: 0.4751 - val_loss: 1.6416 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5536 - loss: 1.4242 - val_accuracy: 0.5296 - val_loss: 1.5383 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5613 - loss: 1.4059 - val_accuracy: 0.5357 - val_loss: 1.5004 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.5667 - loss: 1.3916 - val_accuracy: 0.5332 - val_loss: 1.4975 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5690 - loss: 1.3820 - val_accuracy: 0.5672 - val_loss: 1.3839 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5769 - loss: 1.3720 - val_accuracy: 0.5840 - val_loss: 1.3771 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5792 - loss: 1.3675 - val_accuracy: 0.5867 - val_loss: 1.3618 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5817 - loss: 1.3636 - val_accuracy: 0.5732 - val_loss: 1.4182 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5818 - loss: 1.3559 - val_accuracy: 0.5480 - val_loss: 1.4535 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5839 - loss: 1.3538\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5827 - loss: 1.3523 - val_accuracy: 0.5471 - val_loss: 1.5639 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6073 - loss: 1.2814 - val_accuracy: 0.6105 - val_loss: 1.3097 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6162 - loss: 1.2511 - val_accuracy: 0.5733 - val_loss: 1.4118 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6188 - loss: 1.2403 - val_accuracy: 0.5606 - val_loss: 1.4918 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6226 - loss: 1.2303 - val_accuracy: 0.6066 - val_loss: 1.3017 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6246 - loss: 1.2221 - val_accuracy: 0.5956 - val_loss: 1.3295 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6262 - loss: 1.2179 - val_accuracy: 0.5764 - val_loss: 1.4030 - learning_rate: 5.0000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6322 - loss: 1.2045\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6291 - loss: 1.2120 - val_accuracy: 0.5787 - val_loss: 1.3882 - learning_rate: 5.0000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6481 - loss: 1.1570 - val_accuracy: 0.6232 - val_loss: 1.2649 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6537 - loss: 1.1373 - val_accuracy: 0.6141 - val_loss: 1.3320 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6570 - loss: 1.1252 - val_accuracy: 0.6165 - val_loss: 1.3002 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6555 - loss: 1.1214\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6562 - loss: 1.1207 - val_accuracy: 0.6203 - val_loss: 1.2871 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6739 - loss: 1.0772 - val_accuracy: 0.6191 - val_loss: 1.3063 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6741 - loss: 1.0656 - val_accuracy: 0.6267 - val_loss: 1.2730 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6760 - loss: 1.0572\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6771 - loss: 1.0581 - val_accuracy: 0.6252 - val_loss: 1.3075 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6827 - loss: 1.0369 - val_accuracy: 0.6364 - val_loss: 1.2650 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6872 - loss: 1.0281 - val_accuracy: 0.6292 - val_loss: 1.2883 - learning_rate: 6.2500e-05\n",
      "Fold 3: Acc Janela=0.6232 | Acc Faixa=0.6575\n",
      "\n",
      "=== Iniciando Fold 4/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 42ms/step - accuracy: 0.4242 - loss: 1.8167 - val_accuracy: 0.2966 - val_loss: 2.2162 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 43ms/step - accuracy: 0.4882 - loss: 1.6156 - val_accuracy: 0.4376 - val_loss: 1.6913 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5173 - loss: 1.5416 - val_accuracy: 0.4214 - val_loss: 1.9098 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5314 - loss: 1.4935 - val_accuracy: 0.4304 - val_loss: 1.9072 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5471 - loss: 1.4558 - val_accuracy: 0.5527 - val_loss: 1.4621 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5557 - loss: 1.4297 - val_accuracy: 0.5100 - val_loss: 1.5730 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5624 - loss: 1.4100 - val_accuracy: 0.5123 - val_loss: 1.5712 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5686 - loss: 1.3931 - val_accuracy: 0.5571 - val_loss: 1.3767 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5714 - loss: 1.3866 - val_accuracy: 0.5094 - val_loss: 1.5279 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5752 - loss: 1.3799 - val_accuracy: 0.5472 - val_loss: 1.4359 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5823 - loss: 1.3639\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5811 - loss: 1.3662 - val_accuracy: 0.4979 - val_loss: 1.6848 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6046 - loss: 1.2923 - val_accuracy: 0.5844 - val_loss: 1.3674 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6115 - loss: 1.2648 - val_accuracy: 0.5601 - val_loss: 1.3900 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6154 - loss: 1.2497 - val_accuracy: 0.5589 - val_loss: 1.4785 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6186 - loss: 1.2383\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6166 - loss: 1.2410 - val_accuracy: 0.5873 - val_loss: 1.3923 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6390 - loss: 1.1805 - val_accuracy: 0.5795 - val_loss: 1.3634 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6424 - loss: 1.1633 - val_accuracy: 0.5874 - val_loss: 1.3918 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6474 - loss: 1.1493 - val_accuracy: 0.5900 - val_loss: 1.3694 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6496 - loss: 1.1349 - val_accuracy: 0.6038 - val_loss: 1.3618 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6540 - loss: 1.1277 - val_accuracy: 0.5983 - val_loss: 1.3709 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6551 - loss: 1.1228 - val_accuracy: 0.5613 - val_loss: 1.5152 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6570 - loss: 1.1123\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6562 - loss: 1.1141 - val_accuracy: 0.5928 - val_loss: 1.4316 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6725 - loss: 1.0727 - val_accuracy: 0.6103 - val_loss: 1.3812 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6760 - loss: 1.0584 - val_accuracy: 0.6111 - val_loss: 1.3693 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6816 - loss: 1.0448\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6797 - loss: 1.0481 - val_accuracy: 0.6048 - val_loss: 1.3831 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6877 - loss: 1.0234 - val_accuracy: 0.6073 - val_loss: 1.4236 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6902 - loss: 1.0145 - val_accuracy: 0.6114 - val_loss: 1.3254 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6924 - loss: 1.0091 - val_accuracy: 0.6141 - val_loss: 1.3489 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6939 - loss: 1.0047 - val_accuracy: 0.6085 - val_loss: 1.3547 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m2790/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6939 - loss: 0.9999\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6938 - loss: 0.9996 - val_accuracy: 0.6094 - val_loss: 1.3490 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6971 - loss: 0.9886 - val_accuracy: 0.6106 - val_loss: 1.3441 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.7017 - loss: 0.9796 - val_accuracy: 0.6111 - val_loss: 1.3685 - learning_rate: 3.1250e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7057 - loss: 0.9723\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.7029 - loss: 0.9776 - val_accuracy: 0.6136 - val_loss: 1.3354 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.7051 - loss: 0.9682 - val_accuracy: 0.6124 - val_loss: 1.3533 - learning_rate: 1.5625e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m2791/2791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.7048 - loss: 0.9698 - val_accuracy: 0.6135 - val_loss: 1.3389 - learning_rate: 1.5625e-05\n",
      "Fold 4: Acc Janela=0.6114 | Acc Faixa=0.6625\n",
      "\n",
      "=== Iniciando Fold 5/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4112 - loss: 1.8328 - val_accuracy: 0.3733 - val_loss: 1.8752 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 41ms/step - accuracy: 0.4842 - loss: 1.6191 - val_accuracy: 0.4059 - val_loss: 1.8310 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5087 - loss: 1.5499 - val_accuracy: 0.4584 - val_loss: 1.7270 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5263 - loss: 1.5021 - val_accuracy: 0.4566 - val_loss: 1.7039 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5400 - loss: 1.4665 - val_accuracy: 0.4874 - val_loss: 1.5959 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5483 - loss: 1.4437 - val_accuracy: 0.4346 - val_loss: 1.8877 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5573 - loss: 1.4218 - val_accuracy: 0.5212 - val_loss: 1.4573 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5625 - loss: 1.4017 - val_accuracy: 0.5520 - val_loss: 1.4171 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5685 - loss: 1.3927 - val_accuracy: 0.5406 - val_loss: 1.4769 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5722 - loss: 1.3823 - val_accuracy: 0.5365 - val_loss: 1.4732 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5778 - loss: 1.3714\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5768 - loss: 1.3735 - val_accuracy: 0.5279 - val_loss: 1.4770 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5998 - loss: 1.2992 - val_accuracy: 0.5221 - val_loss: 1.6337 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6095 - loss: 1.2683 - val_accuracy: 0.5595 - val_loss: 1.3981 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6111 - loss: 1.2594 - val_accuracy: 0.5411 - val_loss: 1.4860 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6156 - loss: 1.2458 - val_accuracy: 0.5837 - val_loss: 1.3675 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6192 - loss: 1.2382 - val_accuracy: 0.5928 - val_loss: 1.3563 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6222 - loss: 1.2344 - val_accuracy: 0.5828 - val_loss: 1.4412 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6248 - loss: 1.2278 - val_accuracy: 0.5614 - val_loss: 1.4480 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6249 - loss: 1.2277\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6269 - loss: 1.2251 - val_accuracy: 0.5701 - val_loss: 1.4528 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6452 - loss: 1.1655 - val_accuracy: 0.5871 - val_loss: 1.3628 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6514 - loss: 1.1453 - val_accuracy: 0.5903 - val_loss: 1.3757 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6575 - loss: 1.1326 - val_accuracy: 0.6148 - val_loss: 1.2634 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6592 - loss: 1.1228 - val_accuracy: 0.6140 - val_loss: 1.2954 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6599 - loss: 1.1189 - val_accuracy: 0.6142 - val_loss: 1.2586 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6627 - loss: 1.1092 - val_accuracy: 0.5885 - val_loss: 1.3931 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6633 - loss: 1.1052 - val_accuracy: 0.6040 - val_loss: 1.3437 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6660 - loss: 1.0992\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6641 - loss: 1.1035 - val_accuracy: 0.6060 - val_loss: 1.3049 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6798 - loss: 1.0585 - val_accuracy: 0.6085 - val_loss: 1.3502 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6825 - loss: 1.0466 - val_accuracy: 0.6098 - val_loss: 1.3187 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6883 - loss: 1.0322\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6861 - loss: 1.0380 - val_accuracy: 0.6166 - val_loss: 1.3119 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6932 - loss: 1.0159 - val_accuracy: 0.6179 - val_loss: 1.3100 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6943 - loss: 1.0066 - val_accuracy: 0.6170 - val_loss: 1.3251 - learning_rate: 6.2500e-05\n",
      "Fold 5: Acc Janela=0.6142 | Acc Faixa=0.6633\n",
      "\n",
      "=== Iniciando Fold 6/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 42ms/step - accuracy: 0.4127 - loss: 1.8328 - val_accuracy: 0.4254 - val_loss: 1.7489 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4877 - loss: 1.6169 - val_accuracy: 0.4715 - val_loss: 1.6842 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5161 - loss: 1.5468 - val_accuracy: 0.4203 - val_loss: 1.9785 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5327 - loss: 1.4987 - val_accuracy: 0.5172 - val_loss: 1.5234 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5429 - loss: 1.4644 - val_accuracy: 0.3645 - val_loss: 2.0963 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5509 - loss: 1.4393 - val_accuracy: 0.5179 - val_loss: 1.5559 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5558 - loss: 1.4289\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5589 - loss: 1.4193 - val_accuracy: 0.4522 - val_loss: 1.9148 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5858 - loss: 1.3377 - val_accuracy: 0.4665 - val_loss: 1.8818 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5939 - loss: 1.3067 - val_accuracy: 0.5265 - val_loss: 1.4655 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5999 - loss: 1.2905 - val_accuracy: 0.4791 - val_loss: 1.6992 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6055 - loss: 1.2778 - val_accuracy: 0.5684 - val_loss: 1.4280 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6103 - loss: 1.2689 - val_accuracy: 0.5718 - val_loss: 1.3904 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6127 - loss: 1.2571 - val_accuracy: 0.5980 - val_loss: 1.3214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6157 - loss: 1.2528 - val_accuracy: 0.5874 - val_loss: 1.3634 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6199 - loss: 1.2452 - val_accuracy: 0.5509 - val_loss: 1.5175 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6228 - loss: 1.2399 - val_accuracy: 0.6047 - val_loss: 1.3054 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6262 - loss: 1.2345 - val_accuracy: 0.5832 - val_loss: 1.3599 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6287 - loss: 1.2288 - val_accuracy: 0.5889 - val_loss: 1.3924 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6324 - loss: 1.2209\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6303 - loss: 1.2260 - val_accuracy: 0.5997 - val_loss: 1.3822 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6506 - loss: 1.1629 - val_accuracy: 0.5970 - val_loss: 1.4324 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6618 - loss: 1.1309 - val_accuracy: 0.6041 - val_loss: 1.3640 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6634 - loss: 1.1259\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6634 - loss: 1.1255 - val_accuracy: 0.5864 - val_loss: 1.4141 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6790 - loss: 1.0775 - val_accuracy: 0.6198 - val_loss: 1.3296 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6826 - loss: 1.0613 - val_accuracy: 0.6132 - val_loss: 1.3096 - learning_rate: 1.2500e-04\n",
      "Fold 6: Acc Janela=0.6047 | Acc Faixa=0.6483\n",
      "\n",
      "=== Iniciando Fold 7/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 43ms/step - accuracy: 0.4090 - loss: 1.8412 - val_accuracy: 0.3857 - val_loss: 1.8388 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 42ms/step - accuracy: 0.4884 - loss: 1.6139 - val_accuracy: 0.4794 - val_loss: 1.6595 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5145 - loss: 1.5431 - val_accuracy: 0.5147 - val_loss: 1.5957 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5311 - loss: 1.4923 - val_accuracy: 0.4623 - val_loss: 1.6937 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5450 - loss: 1.4579 - val_accuracy: 0.5106 - val_loss: 1.7221 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5540 - loss: 1.4333 - val_accuracy: 0.5408 - val_loss: 1.4557 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5583 - loss: 1.4171 - val_accuracy: 0.4894 - val_loss: 1.6681 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5660 - loss: 1.3994 - val_accuracy: 0.4620 - val_loss: 1.8717 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5690 - loss: 1.3915\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5716 - loss: 1.3859 - val_accuracy: 0.4838 - val_loss: 1.7827 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5987 - loss: 1.3039 - val_accuracy: 0.5769 - val_loss: 1.3817 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6043 - loss: 1.2716 - val_accuracy: 0.5943 - val_loss: 1.3252 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6116 - loss: 1.2589 - val_accuracy: 0.5600 - val_loss: 1.4994 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6141 - loss: 1.2469 - val_accuracy: 0.5716 - val_loss: 1.4830 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6202 - loss: 1.2343\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6181 - loss: 1.2370 - val_accuracy: 0.5786 - val_loss: 1.3672 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6392 - loss: 1.1775 - val_accuracy: 0.6074 - val_loss: 1.3729 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6453 - loss: 1.1564 - val_accuracy: 0.6119 - val_loss: 1.3324 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6510 - loss: 1.1405\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.6495 - loss: 1.1418 - val_accuracy: 0.6088 - val_loss: 1.3698 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6636 - loss: 1.0990 - val_accuracy: 0.5998 - val_loss: 1.3614 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6706 - loss: 1.0789 - val_accuracy: 0.6038 - val_loss: 1.3572 - learning_rate: 1.2500e-04\n",
      "Fold 7: Acc Janela=0.5943 | Acc Faixa=0.6283\n",
      "\n",
      "=== Iniciando Fold 8/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4024 - loss: 1.8480 - val_accuracy: 0.3994 - val_loss: 1.7335 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 42ms/step - accuracy: 0.4833 - loss: 1.6118 - val_accuracy: 0.3857 - val_loss: 1.9146 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5132 - loss: 1.5466 - val_accuracy: 0.4820 - val_loss: 1.5920 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.5291 - loss: 1.5003 - val_accuracy: 0.4478 - val_loss: 1.7670 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5409 - loss: 1.4657 - val_accuracy: 0.4778 - val_loss: 1.5908 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5527 - loss: 1.4339 - val_accuracy: 0.5125 - val_loss: 1.5119 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5572 - loss: 1.4134 - val_accuracy: 0.5508 - val_loss: 1.4156 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5658 - loss: 1.4032 - val_accuracy: 0.4994 - val_loss: 1.5303 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5730 - loss: 1.3847 - val_accuracy: 0.5595 - val_loss: 1.3748 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5756 - loss: 1.3741 - val_accuracy: 0.5123 - val_loss: 1.4894 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5799 - loss: 1.3707 - val_accuracy: 0.4422 - val_loss: 1.7200 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5828 - loss: 1.3639\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5825 - loss: 1.3613 - val_accuracy: 0.5477 - val_loss: 1.4522 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6051 - loss: 1.2885 - val_accuracy: 0.5515 - val_loss: 1.4577 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6127 - loss: 1.2595 - val_accuracy: 0.5689 - val_loss: 1.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6208 - loss: 1.2410\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.6183 - loss: 1.2455 - val_accuracy: 0.5570 - val_loss: 1.4514 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6352 - loss: 1.1937 - val_accuracy: 0.5588 - val_loss: 1.3880 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6400 - loss: 1.1684 - val_accuracy: 0.5691 - val_loss: 1.4115 - learning_rate: 2.5000e-04\n",
      "Fold 8: Acc Janela=0.5595 | Acc Faixa=0.6058\n",
      "\n",
      "=== Iniciando Fold 9/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 43ms/step - accuracy: 0.4069 - loss: 1.8452 - val_accuracy: 0.3865 - val_loss: 2.1697 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 42ms/step - accuracy: 0.4901 - loss: 1.6145 - val_accuracy: 0.4054 - val_loss: 1.9445 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5178 - loss: 1.5373 - val_accuracy: 0.4926 - val_loss: 1.6124 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5319 - loss: 1.4931 - val_accuracy: 0.5064 - val_loss: 1.5655 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5411 - loss: 1.4597 - val_accuracy: 0.4902 - val_loss: 1.6140 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5538 - loss: 1.4325 - val_accuracy: 0.5185 - val_loss: 1.6791 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5585 - loss: 1.4106\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5590 - loss: 1.4147 - val_accuracy: 0.5092 - val_loss: 1.7048 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5857 - loss: 1.3318 - val_accuracy: 0.5732 - val_loss: 1.3816 - learning_rate: 5.0000e-04\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.5927 - loss: 1.3034 - val_accuracy: 0.5294 - val_loss: 1.5170 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.5975 - loss: 1.2861 - val_accuracy: 0.5869 - val_loss: 1.3553 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6027 - loss: 1.2718 - val_accuracy: 0.5349 - val_loss: 1.5928 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6076 - loss: 1.2642 - val_accuracy: 0.5928 - val_loss: 1.3265 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6131 - loss: 1.2553 - val_accuracy: 0.5837 - val_loss: 1.4495 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6158 - loss: 1.2502 - val_accuracy: 0.5706 - val_loss: 1.3952 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6201 - loss: 1.2401\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6190 - loss: 1.2413 - val_accuracy: 0.5623 - val_loss: 1.4628 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6379 - loss: 1.1787 - val_accuracy: 0.6061 - val_loss: 1.3009 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6461 - loss: 1.1546 - val_accuracy: 0.5887 - val_loss: 1.4068 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6493 - loss: 1.1443 - val_accuracy: 0.6023 - val_loss: 1.3083 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6558 - loss: 1.1230\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6539 - loss: 1.1286 - val_accuracy: 0.6003 - val_loss: 1.3456 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6682 - loss: 1.0854 - val_accuracy: 0.6175 - val_loss: 1.3116 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.6741 - loss: 1.0675 - val_accuracy: 0.6049 - val_loss: 1.3311 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6784 - loss: 1.0557\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6784 - loss: 1.0573 - val_accuracy: 0.6072 - val_loss: 1.3189 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6859 - loss: 1.0304 - val_accuracy: 0.6087 - val_loss: 1.3677 - learning_rate: 6.2500e-05\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 44ms/step - accuracy: 0.6909 - loss: 1.0156 - val_accuracy: 0.6133 - val_loss: 1.3200 - learning_rate: 6.2500e-05\n",
      "Fold 9: Acc Janela=0.6061 | Acc Faixa=0.6458\n",
      "\n",
      "=== Iniciando Fold 10/10 ===\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 32...\n",
      "Epoch 1/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 45ms/step - accuracy: 0.4132 - loss: 1.8346 - val_accuracy: 0.4523 - val_loss: 1.6400 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 44ms/step - accuracy: 0.4884 - loss: 1.6159 - val_accuracy: 0.3633 - val_loss: 1.8457 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 45ms/step - accuracy: 0.5110 - loss: 1.5543 - val_accuracy: 0.4544 - val_loss: 1.8484 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5319 - loss: 1.4990 - val_accuracy: 0.4839 - val_loss: 1.6137 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 44ms/step - accuracy: 0.5448 - loss: 1.4644 - val_accuracy: 0.5232 - val_loss: 1.5128 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 41ms/step - accuracy: 0.5522 - loss: 1.4395 - val_accuracy: 0.5348 - val_loss: 1.5739 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5610 - loss: 1.4178 - val_accuracy: 0.4927 - val_loss: 1.7402 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 42ms/step - accuracy: 0.5660 - loss: 1.4040 - val_accuracy: 0.5255 - val_loss: 1.4835 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5745 - loss: 1.3868 - val_accuracy: 0.5277 - val_loss: 1.4649 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5758 - loss: 1.3777 - val_accuracy: 0.5416 - val_loss: 1.5003 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 42ms/step - accuracy: 0.5785 - loss: 1.3720 - val_accuracy: 0.5415 - val_loss: 1.4481 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5811 - loss: 1.3667 - val_accuracy: 0.5570 - val_loss: 1.4054 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5819 - loss: 1.3656 - val_accuracy: 0.5546 - val_loss: 1.4246 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.5837 - loss: 1.3617 - val_accuracy: 0.5552 - val_loss: 1.4343 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m2791/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5870 - loss: 1.3512\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.5878 - loss: 1.3545 - val_accuracy: 0.5441 - val_loss: 1.4707 - learning_rate: 0.0010\n",
      "Epoch 16/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6089 - loss: 1.2832 - val_accuracy: 0.5920 - val_loss: 1.3297 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6160 - loss: 1.2544 - val_accuracy: 0.6135 - val_loss: 1.2703 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 43ms/step - accuracy: 0.6213 - loss: 1.2402 - val_accuracy: 0.5999 - val_loss: 1.3064 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 43ms/step - accuracy: 0.6234 - loss: 1.2309 - val_accuracy: 0.5421 - val_loss: 1.5520 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6253 - loss: 1.2271\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6263 - loss: 1.2245 - val_accuracy: 0.5905 - val_loss: 1.3503 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 42ms/step - accuracy: 0.6443 - loss: 1.1688 - val_accuracy: 0.5982 - val_loss: 1.3354 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6490 - loss: 1.1493 - val_accuracy: 0.5841 - val_loss: 1.3914 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6526 - loss: 1.1389\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 41ms/step - accuracy: 0.6524 - loss: 1.1392 - val_accuracy: 0.6152 - val_loss: 1.2825 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 41ms/step - accuracy: 0.6645 - loss: 1.1001 - val_accuracy: 0.6147 - val_loss: 1.2975 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m2792/2792\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 43ms/step - accuracy: 0.6690 - loss: 1.0880 - val_accuracy: 0.6038 - val_loss: 1.3363 - learning_rate: 1.2500e-04\n",
      "Fold 10: Acc Janela=0.6135 | Acc Faixa=0.6521\n",
      "\n",
      "--- CV Concluído ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 32 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "def apply_spec_augment(spectrogram, time_mask_param=20, freq_mask_param=15, num_masks=1):\n",
    "    \"\"\"\n",
    "    Aplica mascaramento de tempo e frequência no espectrograma.\n",
    "    Entrada: (128, 130, 1) ou (128, 130)\n",
    "    \"\"\"\n",
    "    # Garante que é uma cópia para não alterar o original\n",
    "    aug_spec = spectrogram.copy()\n",
    "    \n",
    "    # Se tiver canal (H, W, C), remove para processar\n",
    "    if aug_spec.ndim == 3:\n",
    "        aug_spec = aug_spec[:, :, 0]\n",
    "        \n",
    "    n_mels, n_steps = aug_spec.shape\n",
    "    \n",
    "    # Mascaramento de Frequência\n",
    "    for _ in range(num_masks):\n",
    "        f = np.random.randint(0, freq_mask_param)\n",
    "        f0 = np.random.randint(0, n_mels - f)\n",
    "        aug_spec[f0:f0+f, :] = 0\n",
    "        \n",
    "    # Mascaramento de Tempo\n",
    "    for _ in range(num_masks):\n",
    "        t = np.random.randint(0, time_mask_param)\n",
    "        t0 = np.random.randint(0, n_steps - t)\n",
    "        aug_spec[:, t0:t0+t] = 0\n",
    "        \n",
    "    # Retorna dimensão do canal\n",
    "    return aug_spec[..., np.newaxis]\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size, augment=False):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            original_shape = X_batch.shape\n",
    "            X_b_flat = X_batch.reshape(original_shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(original_shape)\n",
    "            \n",
    "            # Aplica Augmentation apenas no Treino\n",
    "            if augment:\n",
    "                X_b_final = np.array([apply_spec_augment(x) for x in X_b_scaled])\n",
    "            else:\n",
    "                X_b_final = X_b_scaled\n",
    "            \n",
    "            yield X_b_final, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"\\n=== Iniciando Fold {fold+1}/{n_splits} ===\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "\n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=0.004)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino com SpecAugmentation\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE, augment=True)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\n",
      "Acurácia Média (10-Fold CV): 0.6419 +/- 0.0195\n",
      "\n",
      "--- Relatório de Classificação (Nível Faixa) ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.63      0.71      0.67       999\n",
      " Experimental       0.58      0.53      0.55       999\n",
      "         Folk       0.62      0.71      0.67      1000\n",
      "      Hip-Hop       0.79      0.80      0.79       997\n",
      " Instrumental       0.60      0.64      0.62      1000\n",
      "International       0.71      0.76      0.73      1000\n",
      "          Pop       0.48      0.25      0.33      1000\n",
      "         Rock       0.64      0.73      0.69       999\n",
      "\n",
      "     accuracy                           0.64      7994\n",
      "    macro avg       0.63      0.64      0.63      7994\n",
      " weighted avg       0.63      0.64      0.63      7994\n",
      "\n",
      "\n",
      "--- Matriz de Confusão (Nível Faixa) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
