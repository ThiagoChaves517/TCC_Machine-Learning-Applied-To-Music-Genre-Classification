{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_5s_50overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_5s_50overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_5s_50overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa0d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Função de Carregamento Robusto ---\n",
    "def load_audio_ffmpeg(file_path, sr):\n",
    "    \"\"\"\n",
    "    Decodifica áudio para WAV em memória usando FFmpeg.\n",
    "    Muito mais robusto a arquivos MP3 corrompidos do FMA.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Comando para decodificar MP3 para WAV (PCM 16-bit) e jogar no STDOUT (pipe)\n",
    "        command = [\n",
    "            'ffmpeg',\n",
    "            '-i', file_path,\n",
    "            '-f', 'wav',            # Formato de contêiner WAV\n",
    "            '-ac', '1',             # 1 Canal (Mono)\n",
    "            '-ar', str(sr),         # Taxa de Amostragem\n",
    "            '-vn',                  # Ignorar vídeo (se houver capa de álbum embutida)\n",
    "            '-y',                   # Sobrescrever (para pipe não importa, mas boa prática)\n",
    "            '-loglevel', 'quiet',   # Silenciar logs do ffmpeg\n",
    "            '-'                     # Saída para Pipe (STDOUT)\n",
    "        ]\n",
    "        \n",
    "        # Executa e captura os bytes\n",
    "        out = subprocess.check_output(command)\n",
    "        \n",
    "        # Carrega do buffer de memória\n",
    "        # librosa.load consegue ler de um objeto file-like (BytesIO)\n",
    "        y, _ = librosa.load(io.BytesIO(out), sr=sr)\n",
    "        \n",
    "        return y\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Fallback: Se o FFmpeg falhar (raro), tenta o librosa padrão ou retorna erro\n",
    "        # print(f\"Erro FFmpeg em {file_path}: {e}\")\n",
    "        try:\n",
    "            y, _ = librosa.load(file_path, sr=sr, mono=True)\n",
    "            return y\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 5\n",
    "OVERLAP_PERCENT = 0.5\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y = load_audio_ffmpeg(file_path, sr=sr)\n",
    "\n",
    "        # Verificação de segurança caso o ffmpeg falhe e retorne None\n",
    "        if y is None:\n",
    "            return []\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eb7239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define o número de núcleos a usar (deixa 1 ou 2 livres para o sistema/OS não travar)\n",
    "N_JOBS = max(1, multiprocessing.cpu_count() - 2)\n",
    "\n",
    "# Funções Auxiliares para o Paralelismo (devem ser definidas antes da chamada Parallel)\n",
    "def worker_count_windows(args):\n",
    "    \"\"\"Função worker para contar janelas de uma faixa em paralelo\"\"\"\n",
    "    track_id, row, audio_dir = args\n",
    "    genre_top = row['genre_top']\n",
    "    file_path = f\"{audio_dir}/{genre_top}/{track_id:06d}.mp3\"\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return None\n",
    "    \n",
    "    # Reutiliza a lógica de contagem (copiada para dentro para garantir escopo no worker)\n",
    "    try:\n",
    "        y = load_audio_ffmpeg(file_path, sr=SR)\n",
    "        \n",
    "        if y is None: \n",
    "            return None\n",
    "    \n",
    "        samples_per_window = WINDOW_SIZE_SEC * SR\n",
    "        if len(y) < samples_per_window: \n",
    "            return None\n",
    "        \n",
    "        hop_size = int(samples_per_window * (1.0 - OVERLAP_PERCENT))\n",
    "        n_windows = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0).shape[0]\n",
    "\n",
    "        return (track_id, row, n_windows)\n",
    "    \n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def worker_extract_features(args):\n",
    "    \"\"\"Função worker para extrair mel-specs de uma faixa em paralelo\"\"\"\n",
    "    track_id, row, n_janelas_esperadas, audio_dir = args\n",
    "    genre_top = row['genre_top']\n",
    "    file_path = f\"{audio_dir}/{genre_top}/{track_id:06d}.mp3\"\n",
    "    \n",
    "    window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "    \n",
    "    # Prepara os dados para retorno\n",
    "    track_data = []\n",
    "    for i, spec in enumerate(window_specs):\n",
    "        if i >= n_janelas_esperadas: break\n",
    "        # Retorna tupla: (Espectrograma, Label Codificado, Track ID)\n",
    "        track_data.append((spec, row['genre_encoded'], track_id))\n",
    "        \n",
    "    return track_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados na cache. Iniciando extração (são 2 passagens)...\")\n",
    "    print(f\"Extração paralela usando {N_JOBS} núcleos...\")\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "\n",
    "    # --- 2 - Contagem Paralela ---\n",
    "    # Prepara argumentos para o worker\n",
    "    tasks_p1 = [(tid, row, AUDIO_DIR_GENRES) for tid, row in track_metadata.iterrows()]\n",
    "    \n",
    "    # Executa em paralelo\n",
    "    results_p1 = Parallel(n_jobs=N_JOBS, verbose=5, batch_size='auto')(\n",
    "        delayed(worker_count_windows)(t) for t in tqdm(tasks_p1, desc=\"Passagem 1/2: Contando Janelas\")\n",
    "    )\n",
    "\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for res in results_p1:\n",
    "        if res is not None:\n",
    "            track_id, row, n = res\n",
    "            if n > 0:\n",
    "                total_janelas += n\n",
    "                all_track_ids_para_contagem.append((track_id, row, n))\n",
    "                \n",
    "    print(f\"Contagem completa! Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- 2 - Extração Paralela ---\n",
    "    tasks_p2 = [(t[0], t[1], t[2], AUDIO_DIR_GENRES) for t in all_track_ids_para_contagem]\n",
    "    \n",
    "    # Executa extração (Isso vai consumir RAM, mas com 32GB é tranquilo para ~7GB de dados)\n",
    "    results_p2_lists = Parallel(n_jobs=N_JOBS, batch_size='auto')(\n",
    "        delayed(worker_extract_features)(t) for t in tqdm(tasks_p2, desc=\"Passagem 2/2: Extraindo Features\")\n",
    "    )\n",
    "    \n",
    "    # --- 3 - Escrita no Memmap ---\n",
    "    # Agora escrevemos tudo no disco sequencialmente (muito rápido pois já está na RAM)\n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    print(f\"\\nEscrevendo dados no disco para {MEMMAP_TEMP_FILE} shape={final_shape}...\")\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita = 0\n",
    "    # Itera sobre os resultados das faixas\n",
    "    for track_data in tqdm(results_p2_lists, desc=\"Salvando no disco...\"):\n",
    "        for spec, label, tid in track_data:\n",
    "            X_np_memmap[idx_escrita] = spec\n",
    "            y_encoded_np_temp[idx_escrita] = label\n",
    "            groups_np_temp[idx_escrita] = tid\n",
    "            idx_escrita += 1\n",
    "    \n",
    "    # Finalização (Salvar e Carregar)\n",
    "    print(f\"\\nConsolidando arquivos...\")\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap) # Converte memmap para npy final\n",
    "    del X_np_memmap\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE): os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    \n",
    "    print(\"Carregando arquivos gerados...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, LSTM,\n",
    "                                     BatchNormalization, Dropout, Reshape,\n",
    "                                     Permute, Dense, Activation, Bidirectional)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CRNN: CNN para extração de features + LSTM para dependência temporal.\n",
    "    \"\"\"\n",
    "    inputs = InputLayer(shape=input_shape, name='input_audio')\n",
    "\n",
    "    # --- Estágio 1: CNN (Feature Extraction) ---\n",
    "    # O objetivo aqui é reduzir a dimensão de Frequência (128) \n",
    "    # mas manter a dimensão de Tempo (431) relativamente alta.\n",
    "    \n",
    "    # Bloco 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Pooling apenas na Frequência (2, 1) ou moderado no tempo (2, 2)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool1')(x) \n",
    "    \n",
    "    # Bloco 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool2')(x)\n",
    "    \n",
    "    # Bloco 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool3')(x)\n",
    "    \n",
    "    # Bloco 4 (Deep Features)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Aqui fazemos pool agressivo na frequência para ela sumir ou ficar pequena\n",
    "    # pool_size=(4, 1) reduz frequência em 4x, mantém tempo intacto\n",
    "    x = MaxPooling2D(pool_size=(4, 1), name='pool4')(x)\n",
    "\n",
    "    # --- Estágio 2: Preparação para RNN (Reshape) ---\n",
    "    # Shape atual (Batch, Freq, Time, Channels) -> (Batch, H, W, C)\n",
    "    # Precisamos transformar em (Batch, Time, Features) para a LSTM\n",
    "    \n",
    "    # 1. Permutar para colocar o Tempo na dimensão 1: (Batch, Time, Freq, Channels)\n",
    "    x = Permute((2, 1, 3), name='permute')(x)\n",
    "    \n",
    "    # 2. Reshape para fundir Frequência e Canais em um vetor de features por timestep\n",
    "    # Novo shape: (Batch, Time, Freq * Channels)\n",
    "    shape = x.shape\n",
    "    x = Reshape((-1, shape[2] * shape[3]), name='reshape_to_rnn')(x)\n",
    "    \n",
    "    # --- Estágio 3: RNN (Temporal Modelling) ---\n",
    "    # Bidirectional permite ver o passado e o futuro da música\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True), name='lstm1')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # Return sequences=False pega apenas o último estado (resumo da música inteira)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=False), name='lstm2')(x)\n",
    "    \n",
    "    # --- Estágio 4: Classificação ---\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='output')(x)\n",
    "    \n",
    "    return Model(inputs, outputs, name=\"CRNN_Music_Genre\")\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_crnn_model(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 32 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "def apply_spec_augment(spectrogram, time_mask_param=20, freq_mask_param=15, num_masks=1):\n",
    "    \"\"\"\n",
    "    Aplica mascaramento de tempo e frequência no espectrograma.\n",
    "    Entrada: (128, 130, 1) ou (128, 130)\n",
    "    \"\"\"\n",
    "    # Garante que é uma cópia para não alterar o original\n",
    "    aug_spec = spectrogram.copy()\n",
    "    \n",
    "    # Se tiver canal (H, W, C), remove para processar\n",
    "    if aug_spec.ndim == 3:\n",
    "        aug_spec = aug_spec[:, :, 0]\n",
    "        \n",
    "    n_mels, n_steps = aug_spec.shape\n",
    "    \n",
    "    # Mascaramento de Frequência\n",
    "    for _ in range(num_masks):\n",
    "        f = np.random.randint(0, freq_mask_param)\n",
    "        f0 = np.random.randint(0, n_mels - f)\n",
    "        aug_spec[f0:f0+f, :] = 0\n",
    "        \n",
    "    # Mascaramento de Tempo\n",
    "    for _ in range(num_masks):\n",
    "        t = np.random.randint(0, time_mask_param)\n",
    "        t0 = np.random.randint(0, n_steps - t)\n",
    "        aug_spec[:, t0:t0+t] = 0\n",
    "        \n",
    "    # Retorna dimensão do canal\n",
    "    return aug_spec[..., np.newaxis]\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size, augment=False):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            original_shape = X_batch.shape\n",
    "            X_b_flat = X_batch.reshape(original_shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(original_shape)\n",
    "            \n",
    "            # Aplica Augmentation apenas no Treino\n",
    "            if augment:\n",
    "                X_b_final = np.array([apply_spec_augment(x) for x in X_b_scaled])\n",
    "            else:\n",
    "                X_b_final = X_b_scaled\n",
    "            \n",
    "            yield X_b_final, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"\\n=== Iniciando Fold {fold+1}/{n_splits} ===\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_crnn_model(input_shape, N_CLASSES)\n",
    "    \n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=0.004)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino com SpecAugmentation\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE, augment=True)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
