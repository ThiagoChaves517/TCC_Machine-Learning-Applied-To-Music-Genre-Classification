{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils  # Do seu utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_10s_50overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_10s_50overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_10s_50overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 10\n",
    "OVERLAP_PERCENT = 0.5\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição (lógica do v2)\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados. Iniciando extração (2 passagens)...\")\n",
    "    \n",
    "    # --- PASSAGEM 1: Contar o número total de janelas ---\n",
    "    \n",
    "    def get_window_count(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT):\n",
    "        # Esta função é mais leve, apenas carrega o áudio e conta os frames\n",
    "        try:\n",
    "            y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "            samples_per_window = window_size_sec * sr\n",
    "            if len(y) < samples_per_window: return 0\n",
    "            hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "            y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "            return y_frames.shape[0] # Retorna o número de janelas\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        if not os.path.exists(file_path): continue\n",
    "            \n",
    "        n_janelas = get_window_count(file_path)\n",
    "        if n_janelas > 0:\n",
    "            total_janelas += n_janelas\n",
    "            all_track_ids_para_contagem.append((track_id, row, n_janelas))\n",
    "\n",
    "    print(f\"\\nContagem concluída. Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- PASSAGEM 2: Extrair e Salvar em Arrays (memmap) ---\n",
    "    \n",
    "    # Usa o SPEC_SHAPE definido na Célula 3 (ex: (128, 130))\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    \n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita_atual = 0\n",
    "    \n",
    "    for track_id, row, n_janelas in tqdm(all_track_ids_para_contagem):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "        \n",
    "        for i, spec in enumerate(window_specs):\n",
    "            if i >= n_janelas: break \n",
    "            \n",
    "            X_np_memmap[idx_escrita_atual] = spec\n",
    "            y_encoded_np_temp[idx_escrita_atual] = row['genre_encoded']\n",
    "            groups_np_temp[idx_escrita_atual] = track_id\n",
    "            idx_escrita_atual += 1\n",
    "    \n",
    "    # 1. Salva o X (lendo do memmap e salvando como .npy)\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap)\n",
    "    \n",
    "    # 2. Fecha e deleta o arquivo memmap temporário\n",
    "    del X_np_memmap\n",
    "    os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    # 3. Salva os outros arrays\n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    print(f\"Extração concluída. Arquivos salvos.\")\n",
    "    \n",
    "    # 4. Agora, carregamos as variáveis (do .npy recém-criado)\n",
    "    print(f\"Carregando arquivos recém-criados do cache...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r') # <-- Esta linha agora funcionará\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, \n",
    "                                     BatchNormalization, Dropout, Dense, Activation,\n",
    "                                     Reshape, Bidirectional, LSTM, Permute)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_crnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    CRNN: CNN para extração de features + LSTM para dependência temporal.\n",
    "    Input Shape esperado: (128, 431, 1) para ~10s de áudio.\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=input_shape, name='input_audio')\n",
    "\n",
    "    # --- Estágio 1: CNN (Feature Extraction) ---\n",
    "    # O objetivo aqui é reduzir a dimensão de Frequência (128) \n",
    "    # mas manter a dimensão de Tempo (431) relativamente alta.\n",
    "    \n",
    "    # Bloco 1\n",
    "    x = Conv2D(64, (3, 3), padding='same', name='conv1')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Pooling apenas na Frequência (2, 1) ou moderado no tempo (2, 2)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool1')(x) \n",
    "    \n",
    "    # Bloco 2\n",
    "    x = Conv2D(128, (3, 3), padding='same', name='conv2')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool2')(x)\n",
    "    \n",
    "    # Bloco 3\n",
    "    x = Conv2D(256, (3, 3), padding='same', name='conv3')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='pool3')(x)\n",
    "    \n",
    "    # Bloco 4 (Deep Features)\n",
    "    x = Conv2D(512, (3, 3), padding='same', name='conv4')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    # Aqui fazemos pool agressivo na frequência para ela sumir ou ficar pequena\n",
    "    # pool_size=(4, 1) reduz frequência em 4x, mantém tempo intacto\n",
    "    x = MaxPooling2D(pool_size=(4, 1), name='pool4')(x)\n",
    "\n",
    "    # --- Estágio 2: Preparação para RNN (Reshape) ---\n",
    "    # Shape atual (Batch, Freq, Time, Channels) -> (Batch, H, W, C)\n",
    "    # Precisamos transformar em (Batch, Time, Features) para a LSTM\n",
    "    \n",
    "    # 1. Permutar para colocar o Tempo na dimensão 1: (Batch, Time, Freq, Channels)\n",
    "    x = Permute((2, 1, 3), name='permute')(x)\n",
    "    \n",
    "    # 2. Reshape para fundir Frequência e Canais em um vetor de features por timestep\n",
    "    # Novo shape: (Batch, Time, Freq * Channels)\n",
    "    shape = x.shape\n",
    "    x = Reshape((-1, shape[2] * shape[3]), name='reshape_to_rnn')(x)\n",
    "    \n",
    "    # --- Estágio 3: RNN (Temporal Modelling) ---\n",
    "    # Bidirectional permite ver o passado e o futuro da música\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True), name='lstm1')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    # Return sequences=False pega apenas o último estado (resumo da música inteira)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=False), name='lstm2')(x)\n",
    "    \n",
    "    # --- Estágio 4: Classificação ---\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax', dtype='float32', name='output')(x)\n",
    "    \n",
    "    return Model(inputs, outputs, name=\"CRNN_Music_Genre\")\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_crnn_model(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 32 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "def apply_spec_augment(spectrogram, time_mask_param=20, freq_mask_param=15, num_masks=1):\n",
    "    \"\"\"\n",
    "    Aplica mascaramento de tempo e frequência no espectrograma.\n",
    "    Entrada: (128, 130, 1) ou (128, 130)\n",
    "    \"\"\"\n",
    "    # Garante que é uma cópia para não alterar o original\n",
    "    aug_spec = spectrogram.copy()\n",
    "    \n",
    "    # Se tiver canal (H, W, C), remove para processar\n",
    "    if aug_spec.ndim == 3:\n",
    "        aug_spec = aug_spec[:, :, 0]\n",
    "        \n",
    "    n_mels, n_steps = aug_spec.shape\n",
    "    \n",
    "    # Mascaramento de Frequência\n",
    "    for _ in range(num_masks):\n",
    "        f = np.random.randint(0, freq_mask_param)\n",
    "        f0 = np.random.randint(0, n_mels - f)\n",
    "        aug_spec[f0:f0+f, :] = 0\n",
    "        \n",
    "    # Mascaramento de Tempo\n",
    "    for _ in range(num_masks):\n",
    "        t = np.random.randint(0, time_mask_param)\n",
    "        t0 = np.random.randint(0, n_steps - t)\n",
    "        aug_spec[:, t0:t0+t] = 0\n",
    "        \n",
    "    # Retorna dimensão do canal\n",
    "    return aug_spec[..., np.newaxis]\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size, augment=False):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            original_shape = X_batch.shape\n",
    "            X_b_flat = X_batch.reshape(original_shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(original_shape)\n",
    "            \n",
    "            # Aplica Augmentation apenas no Treino\n",
    "            if augment:\n",
    "                X_b_final = np.array([apply_spec_augment(x) for x in X_b_scaled])\n",
    "            else:\n",
    "                X_b_final = X_b_scaled\n",
    "            \n",
    "            yield X_b_final, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"\\n=== Iniciando Fold {fold+1}/{n_splits} ===\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_crnn_model(input_shape, N_CLASSES)\n",
    "\n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=1e-4, weight_decay=1e-4)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino com SpecAugmentation\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE, augment=True)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
