{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17482972",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bec5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 04:56:27.959744: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-11 04:56:28.045291: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762851388.073751   13549 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762851388.082616   13549 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1762851388.162612   13549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762851388.162655   13549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762851388.162656   13549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1762851388.162658   13549 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-11-11 04:56:28.172162: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "### Import Libraries\n",
    "# Adicionamos as bibliotecas do TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization, Activation, \n",
    "    MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Bibliotecas Scikit-learn (CPU)\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix as sklearn_confusion_matrix\n",
    "\n",
    "# Bibliotecas de Extração e Plotagem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import utils # Reutiliza o utils.py do seu projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67c74f",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "778a1800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configurado memory growth para 1 GPU(s).\n",
      "Metadados carregados para 8000 faixas 'small'.\n",
      "Gêneros: ['Electronic' 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental'\n",
      " 'International' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_mel_spec_X.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_mel_spec_y.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_mel_spec_groups.npy'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Configura o TensorFlow para alocar memória dinamicamente\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"Configurado memory growth para {len(gpus)} GPU(s).\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# --- Parâmetros de Extração ---\n",
    "SR = 22050\n",
    "WINDOW_SIZE_SEC = 3\n",
    "OVERLAP_PERCENT = 0.25\n",
    "N_MELS = 96\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "TARGET_STEPS = 128 \n",
    "\n",
    "# --- Carregar Metadados ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "y_all_onehot_np = to_categorical(y_all_encoded_np, num_classes=len(label_encoder.classes_))\n",
    "\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "class_names = label_encoder.classes_\n",
    "NUM_CLASSES = len(class_names)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfb0001e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos de features (mel-spec) não encontrados. Iniciando extração...\n",
      "Passo 1/2: Contando janelas (Dry Run)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 489/8000 [00:53<13:27,  9.30it/s][src/libmpg123/layer3.c:INT123_do_layer3():1948] error: dequantization failed!\n",
      " 11%|█▏        | 901/8000 [01:38<12:55,  9.16it/s][src/libmpg123/layer3.c:INT123_do_layer3():1908] error: dequantization failed!\n",
      " 15%|█▍        | 1181/8000 [02:07<12:00,  9.46it/s][src/libmpg123/layer3.c:INT123_do_layer3():1908] error: dequantization failed!\n",
      " 28%|██▊       | 2265/8000 [04:01<10:36,  9.02it/s][src/libmpg123/layer3.c:INT123_do_layer3():1878] error: part2_3_length (3360) too large for available bit count (3240)\n",
      " 28%|██▊       | 2267/8000 [04:01<09:20, 10.23it/s][src/libmpg123/layer3.c:INT123_do_layer3():1878] error: part2_3_length (3328) too large for available bit count (3240)\n",
      " 55%|█████▌    | 4423/8000 [07:45<06:15,  9.53it/s]Note: Illegal Audio-MPEG-Header 0x00000000 at offset 33361.\n",
      "Note: Trying to resync...\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1389] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 22401.\n",
      "Note: Trying to resync...\n",
      "/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1389] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      "[src/libmpg123/layer3.c:INT123_do_layer3():1908] error: dequantization failed!\n",
      "Note: Illegal Audio-MPEG-Header 0x00000000 at offset 63168.\n",
      "Note: Trying to resync...\n",
      "/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Note: Skipped 1024 bytes in input.\n",
      "[src/libmpg123/parse.c:wetwork():1389] error: Giving up resync after 1024 bytes - your stream is not nice... (maybe increasing resync limit could help).\n",
      " 56%|█████▌    | 4469/8000 [07:50<06:35,  8.92it/s]/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "[src/libmpg123/parse.c:do_readahead():1123] warning: Cannot read next header, a one-frame stream? Duh...\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 56%|█████▌    | 4471/8000 [07:50<05:08, 11.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao processar ../fma_datasets/fma_small_genres/Electronic/099134.mp3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 4902/8000 [08:34<01:10, 44.21it/s]/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "[src/libmpg123/parse.c:do_readahead():1123] warning: Cannot read next header, a one-frame stream? Duh...\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao processar ../fma_datasets/fma_small_genres/Rock/108925.mp3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 6965/8000 [12:06<01:58,  8.72it/s]/tmp/ipykernel_13549/193458362.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
      "/home/zurua/miniconda3/envs/tensorflow-gpu/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "[src/libmpg123/parse.c:do_readahead():1123] warning: Cannot read next header, a one-frame stream? Duh...\n",
      " 87%|████████▋ | 6967/8000 [12:07<01:34, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro ao processar ../fma_datasets/fma_small_genres/Experimental/133297.mp3: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [13:53<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de janelas a serem extraídas: 99278\n",
      "Passo 2/2: Preenchendo arrays (Extração Real)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 490/8000 [00:50<12:42,  9.85it/s][src/libmpg123/layer3.c:INT123_do_layer3():1948] error: dequantization failed!\n",
      " 11%|█▏        | 901/8000 [01:30<13:12,  8.96it/s][src/libmpg123/layer3.c:INT123_do_layer3():1908] error: dequantization failed!\n",
      " 15%|█▍        | 1180/8000 [01:57<11:06, 10.24it/s][src/libmpg123/layer3.c:INT123_do_layer3():1908] error: dequantization failed!\n",
      " 28%|██▊       | 2265/8000 [03:47<10:04,  9.49it/s][src/libmpg123/layer3.c:INT123_do_layer3():1878] error: part2_3_length (3360) too large for available bit count (3240)\n",
      " 28%|██▊       | 2267/8000 [03:47<08:25, 11.35it/s][src/libmpg123/layer3.c:INT123_do_layer3():1878] error: part2_3_length (3328) too large for available bit count (3240)\n",
      "100%|██████████| 8000/8000 [13:25<00:00,  9.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extração concluída. Shape de X: (99278, 96, 128). Shape de y: (99278, 8)\n",
      "Total de amostras (janelas): 99278\n",
      "Shape de X: (99278, 96, 128)\n",
      "Shape de y (one-hot): (99278, 8)\n",
      "Total de grupos (faixas únicas): 7994\n"
     ]
    }
   ],
   "source": [
    "def extract_melspectrogram_windowed(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, \n",
    "                                  overlap_percent=OVERLAP_PERCENT, n_mels=N_MELS, \n",
    "                                  n_fft=N_FFT, hop_length=HOP_LENGTH, target_steps=TARGET_STEPS):\n",
    "    \"\"\"\n",
    "    Extrai espectrogramas log-mel para janelas de áudio.\n",
    "    Similar ao seu v2, mas calcula espectrogramas em vez de 518 estatísticas.\n",
    "    \"\"\"\n",
    "    \n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        # 1. Carrega o áudio de 30s\n",
    "        y, sr_loaded = librosa.load(file_path, mono=True, sr=sr)\n",
    "        \n",
    "        # 2. Cria janelas de áudio (ex: 3s)\n",
    "        samples_per_window = int(window_size_sec * sr)\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent)) \n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            # print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # y_frames é [n_windows, samples_per_window]\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        # 3. Calcula o espectrograma para CADA janela\n",
    "        for y_window in y_frames:\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=n_mels, \n",
    "                                               n_fft=n_fft, hop_length=hop_length)\n",
    "            \n",
    "            # Converte para Log-Mel (dB)\n",
    "            log_S = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # 4. Padroniza o tamanho do tempo (importante para a CNN)\n",
    "            if log_S.shape[1] < target_steps:\n",
    "                # Adiciona padding se for curto\n",
    "                log_S = np.pad(log_S, ((0, 0), (0, target_steps - log_S.shape[1])), mode='constant')\n",
    "            else:\n",
    "                # Trunca se for longo\n",
    "                log_S = log_S[:, :target_steps]\n",
    "            \n",
    "            all_window_specs.append(log_S)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return None \n",
    "        \n",
    "    return all_window_specs\n",
    "\n",
    "# --- Loop de Extração e Cache (Similar ao v2) ---\n",
    "\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de features (mel-spec) não encontrados. Iniciando extração...\")\n",
    "    \n",
    "    window_counts = []\n",
    "    track_ids_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    print(\"Passo 1/2: Contando janelas (Dry Run)...\")\n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            continue\n",
    "            \n",
    "        window_specs = extract_melspectrogram_windowed(file_path)\n",
    "        \n",
    "        if window_specs is None or len(window_specs) == 0:\n",
    "            window_counts.append(0)\n",
    "            continue\n",
    "        \n",
    "        num_windows_for_track = len(window_specs)\n",
    "        window_counts.append(num_windows_for_track)\n",
    "        \n",
    "        label_onehot = y_all_onehot_np[y_all_labels_pd.index == track_id][0]\n",
    "        \n",
    "        for _ in range(num_windows_for_track):\n",
    "            track_ids_list.append(track_id)\n",
    "            labels_list.append(label_onehot)\n",
    "\n",
    "    # --- Pré-alocação dos Arrays ---\n",
    "    total_windows = sum(window_counts)\n",
    "    X_np = np.empty((total_windows, N_MELS, TARGET_STEPS), dtype=np.float32)\n",
    "    y_onehot_np = np.array(labels_list, dtype=np.float32)\n",
    "    groups_np = np.array(track_ids_list, dtype=np.int32)\n",
    "    \n",
    "    print(f\"Total de janelas a serem extraídas: {total_windows}\")\n",
    "    print(\"Passo 2/2: Preenchendo arrays (Extração Real)...\")\n",
    "    \n",
    "    current_window_index = 0\n",
    "    track_index = 0\n",
    "    \n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        num_windows_for_this_track = window_counts[track_index]\n",
    "        track_index += 1 # Avança o contador de faixas\n",
    "        \n",
    "        if num_windows_for_this_track == 0:\n",
    "            continue # Pula faixas que falharam ou eram curtas no dry run\n",
    "        \n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        # Extrai as janelas novamente\n",
    "        window_specs = extract_melspectrogram_windowed(file_path)\n",
    "        \n",
    "        if window_specs is None or len(window_specs) == 0:\n",
    "            # Isso não deveria acontecer se o dry run funcionou, mas é uma segurança\n",
    "            continue \n",
    "            \n",
    "        # Preenche o array X_np\n",
    "        for spec in window_specs:\n",
    "            X_np[current_window_index] = spec\n",
    "            current_window_index += 1\n",
    "\n",
    "    print(f\"\\nExtração concluída. Shape de X: {X_np.shape}. Shape de y: {y_onehot_np.shape}\")\n",
    "    \n",
    "    # Salva os arquivos cacheados\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    np.save(FEATURE_FILE_X, X_np)\n",
    "    np.save(FEATURE_FILE_y, y_onehot_np)\n",
    "    np.save(FEATURE_FILE_groups, groups_np)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando features (mel-spec) cacheadas de {FEATURE_FILE_X}...\")\n",
    "    X_np = np.load(FEATURE_FILE_X)\n",
    "    y_onehot_np = np.load(FEATURE_FILE_y) # Carrega os labels já em one-hot\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Features e grupos carregados.\")\n",
    "\n",
    "# --- Checagem de Segurança ---\n",
    "if X_np.size == 0:\n",
    "    print(\"\\nERRO: O array 'X_np' está vazio.\")\n",
    "else:\n",
    "    y_encoded_np = np.argmax(y_onehot_np, axis=1) \n",
    "    print(f\"Total de amostras (janelas): {X_np.shape[0]}\")\n",
    "    print(f\"Shape de X: {X_np.shape}\")\n",
    "    print(f\"Shape de y (one-hot): {y_onehot_np.shape}\")\n",
    "    print(f\"Total de grupos (faixas únicas): {len(np.unique(groups_np))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7f3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762853039.339511   13549 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)    │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m1,032\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,672</span> (615.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m157,672\u001b[0m (615.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,032</span> (613.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m157,032\u001b[0m (613.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> (2.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m640\u001b[0m (2.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Cria um modelo CNN 2D simples para classificação de espectrogramas.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Camada de Entrada\n",
    "    inp = Input(shape=input_shape)\n",
    "    \n",
    "    # --- Bloco 1 ---\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # --- Bloco 2 ---\n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    \n",
    "    # --- Bloco 3 ---\n",
    "    x = Conv2D(128, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # --- Camada de Agregação ---\n",
    "    # GlobalAveragePooling2D é mais eficiente que Flatten\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    # --- Camadas Densas (Classificador) ---\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x) # Dropout para regularização\n",
    "    \n",
    "    # Camada de Saída\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=out)\n",
    "    \n",
    "    # Compila o modelo\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Define o shape de entrada (Altura, Largura, Canais)\n",
    "# (N_MELS, TARGET_STEPS, 1 canal -> mono)\n",
    "INPUT_SHAPE = (N_MELS, TARGET_STEPS, 1) \n",
    "\n",
    "# Testa a construção do modelo\n",
    "model_teste = build_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "model_teste.summary()\n",
    "del model_teste # Libera a memória"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73767c5",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bcb603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando CV 10-Fold para CNN 2D (GPU)...\n",
      "\n",
      "--- Processando Fold 1/10 ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Definir a Estratégia de CV (GroupKFold)\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# 2. Dicionários para guardar os resultados (Nível da Faixa)\n",
    "# (Igual ao seu v2)\n",
    "cv_scores_track = {}\n",
    "out_of_fold_preds_track = {}\n",
    "\n",
    "# Callbacks do Keras\n",
    "# Parar o treino se a perda na validação não melhorar por 3 épocas\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=3, verbose=1, restore_best_weights=True)\n",
    "\n",
    "print(f\"\\nIniciando CV {n_splits}-Fold para CNN 2D (GPU)...\")\n",
    "start_model_time = time.time()\n",
    "\n",
    "fold_scores_acc = []\n",
    "all_preds_for_model = []\n",
    "all_true_for_model = []\n",
    "\n",
    "# 3. Executar a Validação Cruzada\n",
    "# Usamos y_encoded_np (índices) para o split, mas y_onehot_np (one-hot) para o treino\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np, y_encoded_np, groups=groups_np)):\n",
    "    \n",
    "    print(f\"\\n--- Processando Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "    # --- 4.1. Preparação dos Dados do Fold ---\n",
    "    \n",
    "    # Índices de treino e teste (nível de janela)\n",
    "    X_train_np_fold = X_np[train_idx]\n",
    "    y_train_onehot_fold = y_onehot_np[train_idx]\n",
    "    \n",
    "    X_test_np_fold = X_np[test_idx]\n",
    "    y_true_window_np = y_encoded_np[test_idx] # Labels como índice (0-7) para o report\n",
    "    y_true_onehot_fold = y_onehot_np[test_idx] # Labels one-hot para o val_loss\n",
    "    \n",
    "    track_ids_test_fold = groups_np[test_idx]\n",
    "\n",
    "    # --- 4.2. Padronização (StandardScaler) - VITAL para DL ---\n",
    "    # O Scaler deve ser \"fitado\" APENAS nos dados de treino do fold.\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Reshape para 2D (amostras, features) para o scaler\n",
    "    X_train_flat = X_train_np_fold.reshape(X_train_np_fold.shape[0], -1)\n",
    "    X_test_flat = X_test_np_fold.reshape(X_test_np_fold.shape[0], -1)\n",
    "    \n",
    "    # Fit no treino e transforma ambos\n",
    "    X_train_scaled_flat = scaler.fit_transform(X_train_flat)\n",
    "    X_test_scaled_flat = scaler.transform(X_test_flat)\n",
    "    \n",
    "    # --- 4.3. Reshape para a CNN (Adiciona canal) ---\n",
    "    # (amostras, altura, largura, canais)\n",
    "    X_train_fold = X_train_scaled_flat.reshape(-1, N_MELS, TARGET_STEPS, 1)\n",
    "    X_test_fold = X_test_scaled_flat.reshape(-1, N_MELS, TARGET_STEPS, 1)\n",
    "\n",
    "    # --- 4.4. Treinamento do Modelo ---\n",
    "    \n",
    "    # Cria um novo modelo para cada fold (reseta os pesos)\n",
    "    model = build_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_fold, \n",
    "        y_train_onehot_fold,\n",
    "        batch_size=16, # Ajuste conforme a VRAM (32, 64, 128)\n",
    "        epochs=20,     # O EarlyStopping vai parar quando for o ideal\n",
    "        callbacks=[early_stopper],\n",
    "        validation_data=(X_test_fold, y_true_onehot_fold), # Usa o set de teste do fold como validação\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # --- 4.5. Predição (Nível Janela) ---\n",
    "    y_pred_probs = model.predict(X_test_fold)\n",
    "    y_pred_window_np = np.argmax(y_pred_probs, axis=1) # Converte de one-hot para índice\n",
    "\n",
    "    # --- 4.6. Agregação (Votação Majoritária - Igual ao v2) ---\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': track_ids_test_fold,\n",
    "        'y_true_window': y_true_window_np,\n",
    "        'y_pred_window': y_pred_window_np\n",
    "    })\n",
    "\n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true_window'].first()\n",
    "    # Usamos keepdims=True para compatibilidade com scipy > 1.11\n",
    "    y_pred_track = grouped['y_pred_window'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    # Precisamos usar numpy para a métrica (cuML não está envolvido aqui)\n",
    "    acc_fold_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc.append(acc_fold_track)\n",
    "    \n",
    "    all_preds_for_model.append(y_pred_track.values)\n",
    "    all_true_for_model.append(y_true_track.values)\n",
    "    \n",
    "    # Limpa a memória\n",
    "    del X_train_fold, y_train_onehot_fold, X_test_fold, y_true_onehot_fold, model\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "# --- 5. Resultados Finais (Nível Faixa) ---\n",
    "\n",
    "cv_scores_track[\"CNN 2D (GPU)\"] = {\n",
    "    'Acurácia (Nível Faixa)': np.array(fold_scores_acc)\n",
    "}\n",
    "\n",
    "y_true_final = np.concatenate(all_true_for_model)\n",
    "y_pred_final = np.concatenate(all_preds_for_model)\n",
    "\n",
    "out_of_fold_preds_track[\"CNN 2D (GPU)\"] = {\n",
    "    'y_true': y_true_final,\n",
    "    'y_pred': y_pred_final\n",
    "}\n",
    "\n",
    "end_model_time = time.time()\n",
    "print(f\"\\nTreinamento da CNN 2D concluído em {end_model_time - start_model_time:.2f} segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2933257",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Treinamento e Avaliação de CV (Nível Faixa) Concluídos ---\")\n",
    "\n",
    "# 4. Analisar Resultados (Relatório de Métricas Nível Faixa)\n",
    "for model_name, metrics in cv_scores_track.items():\n",
    "    print(f\"\\n========= Resultados {model_name} ({n_splits}-Fold CV) - Nível Faixa (Votação Majoritária) ==========\")\n",
    "    \n",
    "    for metric_name, scores_cpu in metrics.items():\n",
    "        print(f\"--- {metric_name} ---\")\n",
    "        print(f\"  Média        : {scores_cpu.mean():.4f}\")\n",
    "        print(f\"  Desv. Padrão : {scores_cpu.std():.4f}\")\n",
    "        print(f\"  Scores (por Fold): {np.round(scores_cpu, 3)}\")\n",
    "\n",
    "# 5. Análise (Matrizes de Confusão Nível Faixa)\n",
    "print(\"\\n\\n========= Matrizes de Confusão (Agregadas da CV) - Nível Faixa ==========\")\n",
    "\n",
    "for model_name, results in out_of_fold_preds_track.items():\n",
    "    print(f\"--- {model_name} ---\")\n",
    "    \n",
    "    y_true_agg = results['y_true']\n",
    "    y_pred_agg = results['y_pred']\n",
    "    \n",
    "    # Usamos o confusion_matrix do sklearn (CPU)\n",
    "    cm_cpu = sklearn_confusion_matrix(y_true_agg, y_pred_agg)\n",
    "    \n",
    "    plt.figure(figsize=(5, 4))\n",
    "    sns.heatmap(cm_cpu, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'Matriz de Confusão (Nível Faixa) - {model_name}')\n",
    "    plt.ylabel('Rótulo Verdadeiro')\n",
    "    plt.xlabel('Rótulo Previsto')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "    print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
