{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c018a5a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c06f21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from scipy import stats\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import utils  # Do seu utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299c925",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecbc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadados carregados para 8000 faixas 'small'.\n",
      "Gêneros: ['Electronic' 'Experimental' 'Folk' 'Hip-Hop' 'Instrumental'\n",
      " 'International' 'Pop' 'Rock']\n"
     ]
    }
   ],
   "source": [
    "# --- Configuração ---\n",
    "METADATA_DIR = '../fma_metadata'\n",
    "AUDIO_DIR_GENRES = '../fma_datasets/fma_small_genres'\n",
    "# Arquivos de cache para os espectrogramas\n",
    "FEATURE_FILE_X = '../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy'\n",
    "FEATURE_FILE_y = '../preprocessed_features/fma_small_spectrograms_y_3s_25overlap.npy'\n",
    "FEATURE_FILE_groups = '../preprocessed_features/fma_small_spectrograms_groups_3s_25overlap.npy'\n",
    "N_CLASSES = 8 # 8 gêneros no fma_small\n",
    "\n",
    "# --- Carregar Metadados (Igual ao v2) ---\n",
    "tracks = utils.load(f'{METADATA_DIR}/tracks.csv')\n",
    "\n",
    "small_mask = tracks[('set', 'subset')] == 'small'\n",
    "y_all_labels_pd = tracks.loc[small_mask, ('track', 'genre_top')]\n",
    "splits_pd = tracks.loc[small_mask, ('set', 'split')]\n",
    "\n",
    "# --- Codificar os Gêneros (Labels) ---\n",
    "label_encoder = LabelEncoder()\n",
    "y_all_encoded_np = label_encoder.fit_transform(y_all_labels_pd).astype(np.int32)\n",
    "class_names = label_encoder.classes_\n",
    "\n",
    "# --- Criar DataFrame de referência ---\n",
    "track_metadata = pd.DataFrame({\n",
    "    'genre_top': y_all_labels_pd,\n",
    "    'genre_encoded': y_all_encoded_np,\n",
    "    'split': splits_pd\n",
    "}, index=y_all_labels_pd.index)\n",
    "\n",
    "print(f\"Metadados carregados para {track_metadata.shape[0]} faixas 'small'.\")\n",
    "print(f\"Gêneros: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50463f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros de Janelamento e Espectrograma\n",
    "WINDOW_SIZE_SEC = 3\n",
    "OVERLAP_PERCENT = 0.25\n",
    "SR = 22050\n",
    "N_MELS = 128   # Altura da \"imagem\" do espectrograma\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512 # Resultará na \"largura\" da imagem\n",
    "\n",
    "# CALCULA A LARGURA FIXA (shape[1])\n",
    "SPEC_WIDTH = int(np.ceil((WINDOW_SIZE_SEC * SR) / HOP_LENGTH))\n",
    "SPEC_SHAPE = (N_MELS, SPEC_WIDTH)\n",
    "\n",
    "def gerar_melspectrogram_janelado(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT, target_shape=SPEC_SHAPE, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    \"\"\"\n",
    "    Extrai mel-espectrogramas de 3s com 25% de sobreposição.\n",
    "    MODIFICADO para garantir shape fixo (padding/truncate).\n",
    "    \"\"\"\n",
    "    all_window_specs = []\n",
    "    \n",
    "    try:\n",
    "        y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "        \n",
    "        samples_per_window = window_size_sec * sr\n",
    "        hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "        \n",
    "        if len(y) < samples_per_window:\n",
    "            #print(f\"Aviso: Áudio {file_path} mais curto que {window_size_sec}s. Pulando.\")\n",
    "            return []\n",
    "\n",
    "        # Cria as janelas (frames) com sobreposição (lógica do v2)\n",
    "        y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "        \n",
    "        for y_window in y_frames:\n",
    "            # Gera o Mel-Espectrograma para a janela\n",
    "            S = librosa.feature.melspectrogram(y=y_window, sr=sr, n_mels=target_shape[0], n_fft=n_fft, hop_length=hop_length)\n",
    "            # Converte para dB\n",
    "            S_db = librosa.power_to_db(S, ref=np.max)\n",
    "            \n",
    "            # Garante que a \"largura\" do espectrograma seja consistente\n",
    "            # Isso evita o erro de \"pickle\" do NumPy\n",
    "            S_db = librosa.util.fix_length(S_db, size=target_shape[1], axis=1)\n",
    "            \n",
    "            all_window_specs.append(S_db.astype(np.float32)) # Salva como float32\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return []\n",
    "        \n",
    "    return all_window_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "190d6ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando espectrogramas cacheados de ../preprocessed_features/fma_small_spectrograms_X_3s_25overlap.npy...\n",
      "Arquivos carregados.\n",
      "Shape de X (amostras, n_mels, frames): (99278, 128, 130)\n",
      "Shape de y (labels): (99278,)\n",
      "Shape de groups (track_ids): (99278,)\n"
     ]
    }
   ],
   "source": [
    "# Para garantir que as variáveis existam fora do escopo do 'if'\n",
    "X_np = None\n",
    "y_encoded_np = None\n",
    "groups_np = None\n",
    "\n",
    "# Verifica se os arquivos de cache existem\n",
    "if not (os.path.exists(FEATURE_FILE_X) and \n",
    "        os.path.exists(FEATURE_FILE_y) and \n",
    "        os.path.exists(FEATURE_FILE_groups)):\n",
    "    \n",
    "    print(f\"Arquivos de espectrograma não encontrados. Iniciando extração (2 passagens)...\")\n",
    "    \n",
    "    # --- PASSAGEM 1: Contar o número total de janelas ---\n",
    "    \n",
    "    def get_window_count(file_path, sr=SR, window_size_sec=WINDOW_SIZE_SEC, overlap_percent=OVERLAP_PERCENT):\n",
    "        # Esta função é mais leve, apenas carrega o áudio e conta os frames\n",
    "        try:\n",
    "            y, sr_loaded = librosa.load(file_path, mono=True, sr=sr, res_type='kaiser_fast')\n",
    "            samples_per_window = window_size_sec * sr\n",
    "            if len(y) < samples_per_window: return 0\n",
    "            hop_size = int(samples_per_window * (1.0 - overlap_percent))\n",
    "            y_frames = librosa.util.frame(y, frame_length=samples_per_window, hop_length=hop_size, axis=0)\n",
    "            return y_frames.shape[0] # Retorna o número de janelas\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    print(\"Passagem 1/2: Contando janelas...\")\n",
    "    total_janelas = 0\n",
    "    all_track_ids_para_contagem = [] # Usado para saber quais faixas processar na Passagem 2\n",
    "    \n",
    "    for track_id, row in tqdm(track_metadata.iterrows(), total=track_metadata.shape[0]):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        if not os.path.exists(file_path): continue\n",
    "            \n",
    "        n_janelas = get_window_count(file_path)\n",
    "        if n_janelas > 0:\n",
    "            total_janelas += n_janelas\n",
    "            all_track_ids_para_contagem.append((track_id, row, n_janelas))\n",
    "\n",
    "    print(f\"\\nContagem concluída. Total de janelas a serem extraídas: {total_janelas}\")\n",
    "    \n",
    "    # --- PASSAGEM 2: Extrair e Salvar em Arrays (memmap) ---\n",
    "    \n",
    "    # Usa o SPEC_SHAPE definido na Célula 3 (ex: (128, 130))\n",
    "    final_shape = (total_janelas, SPEC_SHAPE[0], SPEC_SHAPE[1])\n",
    "    \n",
    "    # Cria os arrays no disco (np.memmap para X)\n",
    "    os.makedirs(os.path.dirname(FEATURE_FILE_X), exist_ok=True)\n",
    "    \n",
    "    # Criamos um nome temporário para o arquivo memmap\n",
    "    MEMMAP_TEMP_FILE = FEATURE_FILE_X + '.temp'\n",
    "    if os.path.exists(MEMMAP_TEMP_FILE):\n",
    "        os.remove(MEMMAP_TEMP_FILE)\n",
    "        \n",
    "    X_np_memmap = np.memmap(MEMMAP_TEMP_FILE, dtype='float32', mode='w+', shape=final_shape)\n",
    "    y_encoded_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "    groups_np_temp = np.zeros(total_janelas, dtype=np.int32)\n",
    "\n",
    "    print(f\"Passagem 2/2: Extraindo espectrogramas para {MEMMAP_TEMP_FILE} (Shape: {final_shape})...\")\n",
    "    \n",
    "    idx_escrita_atual = 0\n",
    "    \n",
    "    for track_id, row, n_janelas in tqdm(all_track_ids_para_contagem):\n",
    "        genre_top = row['genre_top']\n",
    "        file_path = f\"{AUDIO_DIR_GENRES}/{genre_top}/{track_id:06d}.mp3\"\n",
    "        \n",
    "        window_specs = gerar_melspectrogram_janelado(file_path)\n",
    "        \n",
    "        for i, spec in enumerate(window_specs):\n",
    "            if i >= n_janelas: break \n",
    "            \n",
    "            X_np_memmap[idx_escrita_atual] = spec\n",
    "            y_encoded_np_temp[idx_escrita_atual] = row['genre_encoded']\n",
    "            groups_np_temp[idx_escrita_atual] = track_id\n",
    "            idx_escrita_atual += 1\n",
    "    \n",
    "    # 1. Salva o X (lendo do memmap e salvando como .npy)\n",
    "    print(f\"\\nConvertendo {MEMMAP_TEMP_FILE} para {FEATURE_FILE_X}...\")\n",
    "    np.save(FEATURE_FILE_X, X_np_memmap)\n",
    "    \n",
    "    # 2. Fecha e deleta o arquivo memmap temporário\n",
    "    del X_np_memmap\n",
    "    os.remove(MEMMAP_TEMP_FILE)\n",
    "    \n",
    "    # 3. Salva os outros arrays\n",
    "    np.save(FEATURE_FILE_y, y_encoded_np_temp)\n",
    "    np.save(FEATURE_FILE_groups, groups_np_temp)\n",
    "    print(f\"Extração concluída. Arquivos salvos.\")\n",
    "    \n",
    "    # 4. Agora, carregamos as variáveis (do .npy recém-criado)\n",
    "    print(f\"Carregando arquivos recém-criados do cache...\")\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r')\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "\n",
    "else:\n",
    "    print(f\"Carregando espectrogramas cacheados de {FEATURE_FILE_X}...\")\n",
    "    # Carrega do disco (usando mmap_mode='r')\n",
    "    X_np = np.load(FEATURE_FILE_X, mmap_mode='r') # <-- Esta linha agora funcionará\n",
    "    y_encoded_np = np.load(FEATURE_FILE_y)\n",
    "    groups_np = np.load(FEATURE_FILE_groups)\n",
    "    print(\"Arquivos carregados.\")\n",
    "\n",
    "# Estas linhas agora funcionarão\n",
    "print(f\"Shape de X (amostras, n_mels, frames): {X_np.shape}\")\n",
    "print(f\"Shape de y (labels): {y_encoded_np.shape}\")\n",
    "print(f\"Shape de groups (track_ids): {groups_np.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d72d02e",
   "metadata": {},
   "source": [
    "### Treino dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a4960a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 02:51:13.352609: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-23 02:51:14.285200: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-23 02:51:16.670112: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Growth habilitado para: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Desabilita otimizações XLA que podem consumir memória extra na compilação\n",
    "os.environ['TF_XLA_FLAGS'] = '--tf_xla_enable_xla_devices=false'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Configuração crítica para evitar travamento em GPUs com pouca VRAM (6GB)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPU Memory Growth habilitado para: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b212c38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape de X para CNN (amostras, altura, largura, canais): (99278, 128, 130, 1)\n",
      "Shape de y (one-hot): (99278, 8)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (InputLayer, Conv2D, MaxPooling2D, \n",
    "                                     BatchNormalization, Dropout, \n",
    "                                     GlobalAveragePooling2D, Dense, Activation)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "\n",
    "# Adiciona a dimensão do \"canal\" (1, pois é escala de cinza/monocromático)\n",
    "X_np_cnn = X_np[..., np.newaxis]\n",
    "\n",
    "# Converte labels para one-hot encoding\n",
    "y_one_hot = tf.keras.utils.to_categorical(y_encoded_np, num_classes=N_CLASSES)\n",
    "\n",
    "print(f\"Shape de X para CNN (amostras, altura, largura, canais): {X_np_cnn.shape}\")\n",
    "print(f\"Shape de y (one-hot): {y_one_hot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa73338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763880678.329989  300882 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3584 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,056</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m130\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m2,056\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,243,368</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,243,368\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,241,448</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,241,448\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> (7.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,920\u001b[0m (7.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def build_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Arquitetura inspirada na VGG, otimizada para Mel-Espectrogramas.\n",
    "    Usa GlobalAveragePooling para reduzir parâmetros na camada densa.\n",
    "    \"\"\"\n",
    "    weight_decay = 0.0005  # Regularização L2 para evitar overfitting\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(shape=input_shape))\n",
    "\n",
    "    # --- Bloco 1 (Recursos de Baixo Nível / Timbre) ---\n",
    "    # 32 Filtros\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    # --- Bloco 2 ---\n",
    "    # 64 Filtros\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 3 ---\n",
    "    # 128 Filtros\n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # --- Bloco 4 (Recursos de Alto Nível / Estrutura) ---\n",
    "    # 256 Filtros - Aprofundando, mas parando aqui para economizar VRAM\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.4))\n",
    "    \n",
    "    \n",
    "    # --- Classificador (Head) ---\n",
    "    # Global Average Pooling \n",
    "    # Transforma (H, W, 256) -> vetor de (256)\n",
    "    model.add(GlobalAveragePooling2D()) \n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(weight_decay)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax', dtype='float32'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Pega o shape de uma amostra (altura, largura, canais)\n",
    "input_shape = X_np_cnn.shape[1:] \n",
    "model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6000dea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed Precision ativado: mixed_float16\n",
      "--- Iniciando Fold 1/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 02:52:00.197806: I external/local_xla/xla/service/service.cc:163] XLA service 0x4af892c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-11-23 02:52:00.197869: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-11-23 02:52:00.361129: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-11-23 02:52:01.122722: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91600\n",
      "I0000 00:00:1763880731.930705  301032 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 25ms/step - accuracy: 0.3901 - loss: 1.8509 - val_accuracy: 0.4070 - val_loss: 1.7788 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 24ms/step - accuracy: 0.4638 - loss: 1.6535 - val_accuracy: 0.3835 - val_loss: 1.8561 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5014 - loss: 1.5622 - val_accuracy: 0.5105 - val_loss: 1.5142 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5220 - loss: 1.5090 - val_accuracy: 0.4896 - val_loss: 1.5795 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 22ms/step - accuracy: 0.5344 - loss: 1.4822 - val_accuracy: 0.4380 - val_loss: 1.6747 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5442 - loss: 1.4581 - val_accuracy: 0.5262 - val_loss: 1.5075 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5516 - loss: 1.4403 - val_accuracy: 0.4981 - val_loss: 1.5574 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5569 - loss: 1.4259 - val_accuracy: 0.5295 - val_loss: 1.4575 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5601 - loss: 1.4192 - val_accuracy: 0.5435 - val_loss: 1.4421 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 22ms/step - accuracy: 0.5620 - loss: 1.4143 - val_accuracy: 0.5490 - val_loss: 1.4161 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.5675 - loss: 1.4004 - val_accuracy: 0.5282 - val_loss: 1.4861 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.5700 - loss: 1.3980 - val_accuracy: 0.5437 - val_loss: 1.4471 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5702 - loss: 1.3957\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.5705 - loss: 1.3936 - val_accuracy: 0.5235 - val_loss: 1.4968 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.5944 - loss: 1.3217 - val_accuracy: 0.5755 - val_loss: 1.3407 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.5988 - loss: 1.2944 - val_accuracy: 0.5447 - val_loss: 1.5027 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6039 - loss: 1.2840 - val_accuracy: 0.5753 - val_loss: 1.3310 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6071 - loss: 1.2750 - val_accuracy: 0.5526 - val_loss: 1.4016 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6062 - loss: 1.2698 - val_accuracy: 0.5545 - val_loss: 1.4071 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6107 - loss: 1.2675\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6104 - loss: 1.2672 - val_accuracy: 0.5739 - val_loss: 1.3373 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 22ms/step - accuracy: 0.6268 - loss: 1.2111 - val_accuracy: 0.5853 - val_loss: 1.3361 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6315 - loss: 1.1976 - val_accuracy: 0.5617 - val_loss: 1.4031 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6380 - loss: 1.1803\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6366 - loss: 1.1838 - val_accuracy: 0.5688 - val_loss: 1.3828 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6472 - loss: 1.1481 - val_accuracy: 0.5777 - val_loss: 1.3270 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6510 - loss: 1.1349 - val_accuracy: 0.5891 - val_loss: 1.2841 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6535 - loss: 1.1269 - val_accuracy: 0.5845 - val_loss: 1.3056 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6562 - loss: 1.1178 - val_accuracy: 0.5770 - val_loss: 1.3087 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6586 - loss: 1.1082\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6558 - loss: 1.1138 - val_accuracy: 0.5725 - val_loss: 1.3816 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6642 - loss: 1.0920 - val_accuracy: 0.5887 - val_loss: 1.3045 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6661 - loss: 1.0847 - val_accuracy: 0.5830 - val_loss: 1.3154 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6682 - loss: 1.0735\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6682 - loss: 1.0781 - val_accuracy: 0.5829 - val_loss: 1.3113 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 22ms/step - accuracy: 0.6729 - loss: 1.0651 - val_accuracy: 0.5845 - val_loss: 1.2974 - learning_rate: 3.1250e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 22ms/step - accuracy: 0.6719 - loss: 1.0616 - val_accuracy: 0.5832 - val_loss: 1.3105 - learning_rate: 3.1250e-05\n",
      "Fold 1: Acc Janela=0.5891 | Acc Faixa=0.6350\n",
      "--- Iniciando Fold 2/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 23ms/step - accuracy: 0.3611 - loss: 1.8853 - val_accuracy: 0.2284 - val_loss: 2.2369 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 23ms/step - accuracy: 0.4526 - loss: 1.6697 - val_accuracy: 0.4704 - val_loss: 1.6314 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.4940 - loss: 1.5791 - val_accuracy: 0.4566 - val_loss: 1.6378 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5156 - loss: 1.5205 - val_accuracy: 0.4844 - val_loss: 1.6320 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5314 - loss: 1.4882 - val_accuracy: 0.5013 - val_loss: 1.5275 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5413 - loss: 1.4622 - val_accuracy: 0.5259 - val_loss: 1.4826 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5486 - loss: 1.4460 - val_accuracy: 0.4902 - val_loss: 1.5892 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5551 - loss: 1.4298 - val_accuracy: 0.5855 - val_loss: 1.3580 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5591 - loss: 1.4256 - val_accuracy: 0.5166 - val_loss: 1.5081 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5617 - loss: 1.4173 - val_accuracy: 0.4771 - val_loss: 1.6091 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5610 - loss: 1.4176\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5617 - loss: 1.4116 - val_accuracy: 0.4929 - val_loss: 1.5667 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5894 - loss: 1.3349 - val_accuracy: 0.5773 - val_loss: 1.3482 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5948 - loss: 1.3087 - val_accuracy: 0.5712 - val_loss: 1.4219 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5981 - loss: 1.2987 - val_accuracy: 0.5774 - val_loss: 1.3460 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5997 - loss: 1.2898 - val_accuracy: 0.5669 - val_loss: 1.3987 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6015 - loss: 1.2853 - val_accuracy: 0.5803 - val_loss: 1.3809 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6018 - loss: 1.2826\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6031 - loss: 1.2813 - val_accuracy: 0.5606 - val_loss: 1.4408 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6204 - loss: 1.2287 - val_accuracy: 0.5911 - val_loss: 1.3233 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6263 - loss: 1.2116 - val_accuracy: 0.5969 - val_loss: 1.3151 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6285 - loss: 1.1986 - val_accuracy: 0.5926 - val_loss: 1.3063 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6295 - loss: 1.1912 - val_accuracy: 0.5998 - val_loss: 1.2768 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6309 - loss: 1.1867 - val_accuracy: 0.5942 - val_loss: 1.3208 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6323 - loss: 1.1807 - val_accuracy: 0.5834 - val_loss: 1.3561 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6349 - loss: 1.1781\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6342 - loss: 1.1785 - val_accuracy: 0.5992 - val_loss: 1.2991 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6465 - loss: 1.1441 - val_accuracy: 0.6045 - val_loss: 1.3011 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6477 - loss: 1.1288 - val_accuracy: 0.6022 - val_loss: 1.3067 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6499 - loss: 1.1259\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6511 - loss: 1.1236 - val_accuracy: 0.6028 - val_loss: 1.3072 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6583 - loss: 1.1009 - val_accuracy: 0.6078 - val_loss: 1.2972 - learning_rate: 6.2500e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6596 - loss: 1.0957 - val_accuracy: 0.5970 - val_loss: 1.3443 - learning_rate: 6.2500e-05\n",
      "Fold 2: Acc Janela=0.5998 | Acc Faixa=0.6288\n",
      "--- Iniciando Fold 3/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 23ms/step - accuracy: 0.3678 - loss: 1.8712 - val_accuracy: 0.2208 - val_loss: 2.4241 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 23ms/step - accuracy: 0.4536 - loss: 1.6635 - val_accuracy: 0.4165 - val_loss: 1.7640 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.4936 - loss: 1.5696 - val_accuracy: 0.4610 - val_loss: 1.7587 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5152 - loss: 1.5184 - val_accuracy: 0.4492 - val_loss: 1.6696 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5289 - loss: 1.4816 - val_accuracy: 0.5389 - val_loss: 1.4362 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 22ms/step - accuracy: 0.5398 - loss: 1.4599 - val_accuracy: 0.5209 - val_loss: 1.4856 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5458 - loss: 1.4428 - val_accuracy: 0.5182 - val_loss: 1.5060 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5516 - loss: 1.4261\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5520 - loss: 1.4284 - val_accuracy: 0.5382 - val_loss: 1.4837 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5767 - loss: 1.3551 - val_accuracy: 0.5549 - val_loss: 1.4098 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 22ms/step - accuracy: 0.5843 - loss: 1.3291 - val_accuracy: 0.5650 - val_loss: 1.3657 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5890 - loss: 1.3116 - val_accuracy: 0.5730 - val_loss: 1.3615 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5925 - loss: 1.3013 - val_accuracy: 0.5744 - val_loss: 1.4471 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5953 - loss: 1.2985 - val_accuracy: 0.5862 - val_loss: 1.3279 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5980 - loss: 1.2882 - val_accuracy: 0.5523 - val_loss: 1.4639 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6014 - loss: 1.2830 - val_accuracy: 0.5750 - val_loss: 1.4394 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6029 - loss: 1.2795 - val_accuracy: 0.6012 - val_loss: 1.3245 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6029 - loss: 1.2806 - val_accuracy: 0.5758 - val_loss: 1.3467 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6050 - loss: 1.2742 - val_accuracy: 0.5932 - val_loss: 1.3365 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6081 - loss: 1.2786\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6073 - loss: 1.2757 - val_accuracy: 0.5902 - val_loss: 1.3436 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6272 - loss: 1.2156 - val_accuracy: 0.5957 - val_loss: 1.3232 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6304 - loss: 1.1977 - val_accuracy: 0.6126 - val_loss: 1.2690 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6353 - loss: 1.1850 - val_accuracy: 0.5961 - val_loss: 1.3212 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6358 - loss: 1.1793 - val_accuracy: 0.5877 - val_loss: 1.3682 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6382 - loss: 1.1692\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6381 - loss: 1.1695 - val_accuracy: 0.6044 - val_loss: 1.3167 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6538 - loss: 1.1272 - val_accuracy: 0.6155 - val_loss: 1.2745 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6544 - loss: 1.1194 - val_accuracy: 0.6155 - val_loss: 1.2662 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6578 - loss: 1.1094 - val_accuracy: 0.6182 - val_loss: 1.2752 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6582 - loss: 1.1062 - val_accuracy: 0.6216 - val_loss: 1.2475 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6600 - loss: 1.1006 - val_accuracy: 0.6122 - val_loss: 1.2844 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6599 - loss: 1.0937 - val_accuracy: 0.6149 - val_loss: 1.2656 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6629 - loss: 1.0885\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6625 - loss: 1.0914 - val_accuracy: 0.6027 - val_loss: 1.3044 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6708 - loss: 1.0684 - val_accuracy: 0.6236 - val_loss: 1.2507 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6728 - loss: 1.0571 - val_accuracy: 0.6189 - val_loss: 1.2460 - learning_rate: 6.2500e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6725 - loss: 1.0572 - val_accuracy: 0.6119 - val_loss: 1.2548 - learning_rate: 6.2500e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6745 - loss: 1.0542 - val_accuracy: 0.6159 - val_loss: 1.2617 - learning_rate: 6.2500e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6766 - loss: 1.0502 - val_accuracy: 0.6159 - val_loss: 1.2405 - learning_rate: 6.2500e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6755 - loss: 1.0494 - val_accuracy: 0.6150 - val_loss: 1.2652 - learning_rate: 6.2500e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6779 - loss: 1.0456 - val_accuracy: 0.6163 - val_loss: 1.2571 - learning_rate: 6.2500e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6797 - loss: 1.0431\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6788 - loss: 1.0414 - val_accuracy: 0.6169 - val_loss: 1.2536 - learning_rate: 6.2500e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6825 - loss: 1.0262 - val_accuracy: 0.6180 - val_loss: 1.2546 - learning_rate: 3.1250e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6832 - loss: 1.0239 - val_accuracy: 0.6174 - val_loss: 1.2650 - learning_rate: 3.1250e-05\n",
      "Epoch 42/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6847 - loss: 1.0199\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6841 - loss: 1.0218 - val_accuracy: 0.6162 - val_loss: 1.2571 - learning_rate: 3.1250e-05\n",
      "Epoch 43/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6866 - loss: 1.0160 - val_accuracy: 0.6184 - val_loss: 1.2562 - learning_rate: 1.5625e-05\n",
      "Epoch 44/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6876 - loss: 1.0126 - val_accuracy: 0.6170 - val_loss: 1.2624 - learning_rate: 1.5625e-05\n",
      "Fold 3: Acc Janela=0.6159 | Acc Faixa=0.6613\n",
      "--- Iniciando Fold 4/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 23ms/step - accuracy: 0.3949 - loss: 1.8457 - val_accuracy: 0.2910 - val_loss: 2.4008 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 23ms/step - accuracy: 0.4718 - loss: 1.6473 - val_accuracy: 0.3751 - val_loss: 1.9545 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 23ms/step - accuracy: 0.5038 - loss: 1.5619 - val_accuracy: 0.4781 - val_loss: 1.6154 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5232 - loss: 1.5112 - val_accuracy: 0.4881 - val_loss: 1.5899 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5339 - loss: 1.4812 - val_accuracy: 0.5423 - val_loss: 1.4151 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5443 - loss: 1.4543 - val_accuracy: 0.5333 - val_loss: 1.4681 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5505 - loss: 1.4363 - val_accuracy: 0.5265 - val_loss: 1.4630 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5529 - loss: 1.4272\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5538 - loss: 1.4257 - val_accuracy: 0.5329 - val_loss: 1.4583 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5789 - loss: 1.3508 - val_accuracy: 0.5632 - val_loss: 1.3772 - learning_rate: 5.0000e-04\n",
      "Epoch 10/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5854 - loss: 1.3244 - val_accuracy: 0.5595 - val_loss: 1.3724 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5908 - loss: 1.3046 - val_accuracy: 0.5616 - val_loss: 1.3676 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5944 - loss: 1.3011 - val_accuracy: 0.5547 - val_loss: 1.3860 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.5964 - loss: 1.2911 - val_accuracy: 0.5578 - val_loss: 1.4263 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6020 - loss: 1.2858\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6003 - loss: 1.2856 - val_accuracy: 0.5673 - val_loss: 1.4024 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6200 - loss: 1.2256 - val_accuracy: 0.5820 - val_loss: 1.3464 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6254 - loss: 1.2061 - val_accuracy: 0.5892 - val_loss: 1.3047 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6258 - loss: 1.1996 - val_accuracy: 0.5944 - val_loss: 1.2943 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6286 - loss: 1.1881 - val_accuracy: 0.5819 - val_loss: 1.3414 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6308 - loss: 1.1827 - val_accuracy: 0.5873 - val_loss: 1.3333 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6307 - loss: 1.1777 - val_accuracy: 0.5953 - val_loss: 1.2833 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6347 - loss: 1.1709 - val_accuracy: 0.5857 - val_loss: 1.3371 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6361 - loss: 1.1656 - val_accuracy: 0.5958 - val_loss: 1.3144 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6395 - loss: 1.1586\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6371 - loss: 1.1618 - val_accuracy: 0.5827 - val_loss: 1.3667 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6510 - loss: 1.1215 - val_accuracy: 0.5978 - val_loss: 1.3265 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6546 - loss: 1.1128 - val_accuracy: 0.5941 - val_loss: 1.2871 - learning_rate: 1.2500e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5581/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6583 - loss: 1.1012\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6581 - loss: 1.1024 - val_accuracy: 0.5975 - val_loss: 1.3200 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 22ms/step - accuracy: 0.6660 - loss: 1.0778 - val_accuracy: 0.6008 - val_loss: 1.3027 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5583\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6660 - loss: 1.0723 - val_accuracy: 0.6061 - val_loss: 1.3082 - learning_rate: 6.2500e-05\n",
      "Fold 4: Acc Janela=0.5953 | Acc Faixa=0.6325\n",
      "--- Iniciando Fold 5/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 24ms/step - accuracy: 0.3874 - loss: 1.8580 - val_accuracy: 0.4564 - val_loss: 1.6720 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 23ms/step - accuracy: 0.4686 - loss: 1.6516 - val_accuracy: 0.3945 - val_loss: 1.8968 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 23ms/step - accuracy: 0.5016 - loss: 1.5648 - val_accuracy: 0.5191 - val_loss: 1.5815 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5176 - loss: 1.5194 - val_accuracy: 0.4627 - val_loss: 1.6437 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.5310 - loss: 1.4848 - val_accuracy: 0.4827 - val_loss: 1.5853 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 22ms/step - accuracy: 0.5401 - loss: 1.4655 - val_accuracy: 0.5105 - val_loss: 1.4709 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5468 - loss: 1.4486 - val_accuracy: 0.5560 - val_loss: 1.4000 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5520 - loss: 1.4356 - val_accuracy: 0.5400 - val_loss: 1.4298 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5585 - loss: 1.4244 - val_accuracy: 0.5473 - val_loss: 1.4406 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5616 - loss: 1.4160\n",
      "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5616 - loss: 1.4166 - val_accuracy: 0.5149 - val_loss: 1.5043 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5853 - loss: 1.3424 - val_accuracy: 0.5881 - val_loss: 1.3046 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5890 - loss: 1.3202 - val_accuracy: 0.5603 - val_loss: 1.3589 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5950 - loss: 1.3057 - val_accuracy: 0.5719 - val_loss: 1.3178 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5965 - loss: 1.2995\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.5967 - loss: 1.2994 - val_accuracy: 0.5674 - val_loss: 1.3702 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6137 - loss: 1.2471 - val_accuracy: 0.5789 - val_loss: 1.3104 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6203 - loss: 1.2234 - val_accuracy: 0.5931 - val_loss: 1.2935 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6242 - loss: 1.2093 - val_accuracy: 0.6107 - val_loss: 1.2430 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6254 - loss: 1.2054 - val_accuracy: 0.6000 - val_loss: 1.2639 - learning_rate: 2.5000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6264 - loss: 1.1960 - val_accuracy: 0.5899 - val_loss: 1.2965 - learning_rate: 2.5000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6313 - loss: 1.1885\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6303 - loss: 1.1910 - val_accuracy: 0.5987 - val_loss: 1.2752 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6414 - loss: 1.1542 - val_accuracy: 0.5964 - val_loss: 1.2772 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6484 - loss: 1.1395 - val_accuracy: 0.6056 - val_loss: 1.2660 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6449 - loss: 1.1359\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6474 - loss: 1.1370 - val_accuracy: 0.5874 - val_loss: 1.2994 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6563 - loss: 1.1108 - val_accuracy: 0.6126 - val_loss: 1.2426 - learning_rate: 6.2500e-05\n",
      "Epoch 25/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6589 - loss: 1.1029 - val_accuracy: 0.6064 - val_loss: 1.2533 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6589 - loss: 1.0982 - val_accuracy: 0.6076 - val_loss: 1.2482 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6608 - loss: 1.0902\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6600 - loss: 1.0932 - val_accuracy: 0.6108 - val_loss: 1.2491 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6656 - loss: 1.0794 - val_accuracy: 0.6114 - val_loss: 1.2515 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6663 - loss: 1.0758 - val_accuracy: 0.6117 - val_loss: 1.2442 - learning_rate: 3.1250e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6683 - loss: 1.0755\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6681 - loss: 1.0740 - val_accuracy: 0.6092 - val_loss: 1.2609 - learning_rate: 3.1250e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 22ms/step - accuracy: 0.6715 - loss: 1.0638 - val_accuracy: 0.6122 - val_loss: 1.2512 - learning_rate: 1.5625e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 23ms/step - accuracy: 0.6709 - loss: 1.0631 - val_accuracy: 0.6079 - val_loss: 1.2610 - learning_rate: 1.5625e-05\n",
      "Fold 5: Acc Janela=0.6126 | Acc Faixa=0.6671\n",
      "--- Iniciando Fold 6/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 23ms/step - accuracy: 0.3960 - loss: 1.8482 - val_accuracy: 0.4078 - val_loss: 1.7870 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 23ms/step - accuracy: 0.4770 - loss: 1.6434 - val_accuracy: 0.4812 - val_loss: 1.5697 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 23ms/step - accuracy: 0.5084 - loss: 1.5514 - val_accuracy: 0.5220 - val_loss: 1.5068 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.5246 - loss: 1.5052 - val_accuracy: 0.4668 - val_loss: 1.7946 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.5374 - loss: 1.4702 - val_accuracy: 0.5085 - val_loss: 1.5177 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.5475 - loss: 1.4476 - val_accuracy: 0.5698 - val_loss: 1.3682 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 23ms/step - accuracy: 0.5531 - loss: 1.4286 - val_accuracy: 0.5066 - val_loss: 1.5321 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 25ms/step - accuracy: 0.5570 - loss: 1.4207 - val_accuracy: 0.5410 - val_loss: 1.4718 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5540 - loss: 1.4284\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 25ms/step - accuracy: 0.5610 - loss: 1.4137 - val_accuracy: 0.5421 - val_loss: 1.4678 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.5858 - loss: 1.3342 - val_accuracy: 0.5773 - val_loss: 1.3274 - learning_rate: 5.0000e-04\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 23ms/step - accuracy: 0.5923 - loss: 1.3074 - val_accuracy: 0.5602 - val_loss: 1.3722 - learning_rate: 5.0000e-04\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 23ms/step - accuracy: 0.5979 - loss: 1.2954 - val_accuracy: 0.5298 - val_loss: 1.4744 - learning_rate: 5.0000e-04\n",
      "Epoch 13/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5976 - loss: 1.2888\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 24ms/step - accuracy: 0.5985 - loss: 1.2885 - val_accuracy: 0.5768 - val_loss: 1.3526 - learning_rate: 5.0000e-04\n",
      "Epoch 14/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 25ms/step - accuracy: 0.6176 - loss: 1.2328 - val_accuracy: 0.6017 - val_loss: 1.2558 - learning_rate: 2.5000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6248 - loss: 1.2060 - val_accuracy: 0.5991 - val_loss: 1.2698 - learning_rate: 2.5000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6274 - loss: 1.1994 - val_accuracy: 0.6060 - val_loss: 1.2622 - learning_rate: 2.5000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6303 - loss: 1.1944\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6308 - loss: 1.1920 - val_accuracy: 0.5872 - val_loss: 1.3373 - learning_rate: 2.5000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6435 - loss: 1.1507 - val_accuracy: 0.6108 - val_loss: 1.2508 - learning_rate: 1.2500e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6477 - loss: 1.1359 - val_accuracy: 0.6025 - val_loss: 1.2659 - learning_rate: 1.2500e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6500 - loss: 1.1305 - val_accuracy: 0.6031 - val_loss: 1.2684 - learning_rate: 1.2500e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6507 - loss: 1.1204 - val_accuracy: 0.6068 - val_loss: 1.2418 - learning_rate: 1.2500e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6529 - loss: 1.1159 - val_accuracy: 0.6077 - val_loss: 1.2568 - learning_rate: 1.2500e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 25ms/step - accuracy: 0.6555 - loss: 1.1079 - val_accuracy: 0.6068 - val_loss: 1.2669 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6587 - loss: 1.0995\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6555 - loss: 1.1060 - val_accuracy: 0.5994 - val_loss: 1.3123 - learning_rate: 1.2500e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.6653 - loss: 1.0804 - val_accuracy: 0.6091 - val_loss: 1.2523 - learning_rate: 6.2500e-05\n",
      "Epoch 26/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6680 - loss: 1.0727 - val_accuracy: 0.6091 - val_loss: 1.2627 - learning_rate: 6.2500e-05\n",
      "Epoch 27/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6687 - loss: 1.0686\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.6683 - loss: 1.0676 - val_accuracy: 0.6045 - val_loss: 1.2610 - learning_rate: 6.2500e-05\n",
      "Epoch 28/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6738 - loss: 1.0533 - val_accuracy: 0.6095 - val_loss: 1.2637 - learning_rate: 3.1250e-05\n",
      "Epoch 29/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6759 - loss: 1.0481 - val_accuracy: 0.6083 - val_loss: 1.2643 - learning_rate: 3.1250e-05\n",
      "Fold 6: Acc Janela=0.6068 | Acc Faixa=0.6521\n",
      "--- Iniciando Fold 7/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 26ms/step - accuracy: 0.3662 - loss: 1.8762 - val_accuracy: 0.4344 - val_loss: 1.7434 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 25ms/step - accuracy: 0.4526 - loss: 1.6661 - val_accuracy: 0.4486 - val_loss: 1.6975 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.4941 - loss: 1.5689 - val_accuracy: 0.4829 - val_loss: 1.5875 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5195 - loss: 1.5144 - val_accuracy: 0.4224 - val_loss: 1.7719 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5330 - loss: 1.4768 - val_accuracy: 0.5596 - val_loss: 1.4500 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5427 - loss: 1.4528 - val_accuracy: 0.4488 - val_loss: 1.7436 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5507 - loss: 1.4386 - val_accuracy: 0.5559 - val_loss: 1.4107 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 24ms/step - accuracy: 0.5542 - loss: 1.4234 - val_accuracy: 0.5031 - val_loss: 1.5737 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5598 - loss: 1.4176 - val_accuracy: 0.5320 - val_loss: 1.4883 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.5608 - loss: 1.4059 - val_accuracy: 0.5752 - val_loss: 1.3781 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5655 - loss: 1.4001 - val_accuracy: 0.5322 - val_loss: 1.5032 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5667 - loss: 1.3984 - val_accuracy: 0.5373 - val_loss: 1.4624 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5709 - loss: 1.3847\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5695 - loss: 1.3909 - val_accuracy: 0.5406 - val_loss: 1.4720 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5926 - loss: 1.3178 - val_accuracy: 0.5820 - val_loss: 1.3635 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5972 - loss: 1.2980 - val_accuracy: 0.5528 - val_loss: 1.4258 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.5998 - loss: 1.2870 - val_accuracy: 0.5951 - val_loss: 1.3056 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6022 - loss: 1.2778 - val_accuracy: 0.5860 - val_loss: 1.3346 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6045 - loss: 1.2743 - val_accuracy: 0.5768 - val_loss: 1.4365 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6029 - loss: 1.2738\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6056 - loss: 1.2690 - val_accuracy: 0.5786 - val_loss: 1.3787 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6249 - loss: 1.2145 - val_accuracy: 0.5989 - val_loss: 1.3071 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6300 - loss: 1.1986 - val_accuracy: 0.5943 - val_loss: 1.3335 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6323 - loss: 1.1909\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6317 - loss: 1.1881 - val_accuracy: 0.5903 - val_loss: 1.3621 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6426 - loss: 1.1584 - val_accuracy: 0.5790 - val_loss: 1.3895 - learning_rate: 1.2500e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6474 - loss: 1.1422 - val_accuracy: 0.5937 - val_loss: 1.3702 - learning_rate: 1.2500e-04\n",
      "Fold 7: Acc Janela=0.5951 | Acc Faixa=0.6395\n",
      "--- Iniciando Fold 8/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 24ms/step - accuracy: 0.3870 - loss: 1.8543 - val_accuracy: 0.3524 - val_loss: 1.8647 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 24ms/step - accuracy: 0.4681 - loss: 1.6442 - val_accuracy: 0.3354 - val_loss: 1.9961 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5039 - loss: 1.5540 - val_accuracy: 0.4403 - val_loss: 1.7626 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5228 - loss: 1.5058 - val_accuracy: 0.5092 - val_loss: 1.4662 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5327 - loss: 1.4711 - val_accuracy: 0.4434 - val_loss: 1.7395 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5434 - loss: 1.4491 - val_accuracy: 0.5055 - val_loss: 1.5028 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5517 - loss: 1.4315 - val_accuracy: 0.5424 - val_loss: 1.4177 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5540 - loss: 1.4231 - val_accuracy: 0.5179 - val_loss: 1.4664 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5620 - loss: 1.4081 - val_accuracy: 0.4743 - val_loss: 1.5966 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5645 - loss: 1.4016 - val_accuracy: 0.5569 - val_loss: 1.3708 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5665 - loss: 1.3959 - val_accuracy: 0.5418 - val_loss: 1.4280 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5707 - loss: 1.3904 - val_accuracy: 0.5562 - val_loss: 1.4260 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5706 - loss: 1.3931\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5716 - loss: 1.3889 - val_accuracy: 0.4716 - val_loss: 1.6510 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5947 - loss: 1.3146 - val_accuracy: 0.5802 - val_loss: 1.3289 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6016 - loss: 1.2876 - val_accuracy: 0.5632 - val_loss: 1.3722 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6034 - loss: 1.2792 - val_accuracy: 0.5885 - val_loss: 1.3160 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.6058 - loss: 1.2713 - val_accuracy: 0.5314 - val_loss: 1.4470 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6096 - loss: 1.2614 - val_accuracy: 0.5658 - val_loss: 1.4062 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6117 - loss: 1.2546\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 26ms/step - accuracy: 0.6105 - loss: 1.2593 - val_accuracy: 0.5764 - val_loss: 1.3364 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6261 - loss: 1.2089 - val_accuracy: 0.5750 - val_loss: 1.3164 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6342 - loss: 1.1898 - val_accuracy: 0.5880 - val_loss: 1.3057 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6357 - loss: 1.1815 - val_accuracy: 0.5878 - val_loss: 1.2899 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6355 - loss: 1.1716 - val_accuracy: 0.5596 - val_loss: 1.3721 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6397 - loss: 1.1629 - val_accuracy: 0.5906 - val_loss: 1.2916 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6435 - loss: 1.1549\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6427 - loss: 1.1565 - val_accuracy: 0.5809 - val_loss: 1.3357 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6539 - loss: 1.1211 - val_accuracy: 0.5934 - val_loss: 1.2972 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6589 - loss: 1.1097 - val_accuracy: 0.5951 - val_loss: 1.2976 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6622 - loss: 1.1041\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6602 - loss: 1.1039 - val_accuracy: 0.5982 - val_loss: 1.3081 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6662 - loss: 1.0815 - val_accuracy: 0.5948 - val_loss: 1.2885 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6694 - loss: 1.0697 - val_accuracy: 0.5969 - val_loss: 1.2887 - learning_rate: 6.2500e-05\n",
      "Epoch 31/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6717 - loss: 1.0675 - val_accuracy: 0.5958 - val_loss: 1.2968 - learning_rate: 6.2500e-05\n",
      "Epoch 32/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6690 - loss: 1.0668\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6699 - loss: 1.0657 - val_accuracy: 0.5973 - val_loss: 1.2931 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 26ms/step - accuracy: 0.6750 - loss: 1.0529 - val_accuracy: 0.5948 - val_loss: 1.2952 - learning_rate: 3.1250e-05\n",
      "Epoch 34/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6748 - loss: 1.0464 - val_accuracy: 0.5940 - val_loss: 1.3100 - learning_rate: 3.1250e-05\n",
      "Epoch 35/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6781 - loss: 1.0416\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 26ms/step - accuracy: 0.6785 - loss: 1.0450 - val_accuracy: 0.5993 - val_loss: 1.2993 - learning_rate: 3.1250e-05\n",
      "Epoch 36/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6793 - loss: 1.0382 - val_accuracy: 0.5996 - val_loss: 1.2898 - learning_rate: 1.5625e-05\n",
      "Epoch 37/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 26ms/step - accuracy: 0.6809 - loss: 1.0347 - val_accuracy: 0.6011 - val_loss: 1.2745 - learning_rate: 1.5625e-05\n",
      "Epoch 38/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6799 - loss: 1.0339 - val_accuracy: 0.5979 - val_loss: 1.2982 - learning_rate: 1.5625e-05\n",
      "Epoch 39/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.6814 - loss: 1.0323 - val_accuracy: 0.5958 - val_loss: 1.2988 - learning_rate: 1.5625e-05\n",
      "Epoch 40/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6774 - loss: 1.0378\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 26ms/step - accuracy: 0.6800 - loss: 1.0324 - val_accuracy: 0.5981 - val_loss: 1.2964 - learning_rate: 1.5625e-05\n",
      "Epoch 41/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.6846 - loss: 1.0274 - val_accuracy: 0.5993 - val_loss: 1.2846 - learning_rate: 7.8125e-06\n",
      "Epoch 42/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.6817 - loss: 1.0278 - val_accuracy: 0.5997 - val_loss: 1.2853 - learning_rate: 7.8125e-06\n",
      "Epoch 43/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6859 - loss: 1.0191\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.6846 - loss: 1.0227 - val_accuracy: 0.5988 - val_loss: 1.2861 - learning_rate: 7.8125e-06\n",
      "Epoch 44/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.6836 - loss: 1.0250 - val_accuracy: 0.5987 - val_loss: 1.2904 - learning_rate: 3.9063e-06\n",
      "Epoch 45/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.6841 - loss: 1.0262 - val_accuracy: 0.6008 - val_loss: 1.2840 - learning_rate: 3.9063e-06\n",
      "Fold 8: Acc Janela=0.6011 | Acc Faixa=0.6483\n",
      "--- Iniciando Fold 9/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 24ms/step - accuracy: 0.3826 - loss: 1.8704 - val_accuracy: 0.3469 - val_loss: 1.8764 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 24ms/step - accuracy: 0.4749 - loss: 1.6403 - val_accuracy: 0.4902 - val_loss: 1.5795 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.5054 - loss: 1.5529 - val_accuracy: 0.5079 - val_loss: 1.5320 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 26ms/step - accuracy: 0.5207 - loss: 1.5092 - val_accuracy: 0.4642 - val_loss: 1.6041 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 26ms/step - accuracy: 0.5365 - loss: 1.4755 - val_accuracy: 0.4571 - val_loss: 1.7311 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 24ms/step - accuracy: 0.5418 - loss: 1.4548 - val_accuracy: 0.5213 - val_loss: 1.4682 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.5492 - loss: 1.4380 - val_accuracy: 0.5171 - val_loss: 1.4867 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.5552 - loss: 1.4254 - val_accuracy: 0.5524 - val_loss: 1.4497 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 24ms/step - accuracy: 0.5586 - loss: 1.4123 - val_accuracy: 0.5008 - val_loss: 1.6430 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 24ms/step - accuracy: 0.5644 - loss: 1.4046 - val_accuracy: 0.5643 - val_loss: 1.3993 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.5664 - loss: 1.3984 - val_accuracy: 0.4745 - val_loss: 1.7414 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5692 - loss: 1.3942 - val_accuracy: 0.5378 - val_loss: 1.4759 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5726 - loss: 1.3814\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 25ms/step - accuracy: 0.5697 - loss: 1.3894 - val_accuracy: 0.5544 - val_loss: 1.4382 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.5940 - loss: 1.3168 - val_accuracy: 0.5742 - val_loss: 1.3936 - learning_rate: 5.0000e-04\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6001 - loss: 1.2865 - val_accuracy: 0.5798 - val_loss: 1.3581 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6033 - loss: 1.2779 - val_accuracy: 0.5546 - val_loss: 1.3987 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6057 - loss: 1.2703 - val_accuracy: 0.5795 - val_loss: 1.3338 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6086 - loss: 1.2631 - val_accuracy: 0.5507 - val_loss: 1.4427 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6120 - loss: 1.2565 - val_accuracy: 0.5776 - val_loss: 1.3601 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6096 - loss: 1.2607\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6123 - loss: 1.2571 - val_accuracy: 0.5441 - val_loss: 1.4658 - learning_rate: 5.0000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6297 - loss: 1.1994 - val_accuracy: 0.5927 - val_loss: 1.3110 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6354 - loss: 1.1796 - val_accuracy: 0.5972 - val_loss: 1.3024 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6383 - loss: 1.1698 - val_accuracy: 0.5751 - val_loss: 1.3488 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6404 - loss: 1.1624 - val_accuracy: 0.5883 - val_loss: 1.3211 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6431 - loss: 1.1507\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6392 - loss: 1.1598 - val_accuracy: 0.5913 - val_loss: 1.3363 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 24ms/step - accuracy: 0.6535 - loss: 1.1177 - val_accuracy: 0.5961 - val_loss: 1.3086 - learning_rate: 1.2500e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6599 - loss: 1.1068 - val_accuracy: 0.5969 - val_loss: 1.3207 - learning_rate: 1.2500e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5583/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6572 - loss: 1.1046\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6593 - loss: 1.0994 - val_accuracy: 0.5899 - val_loss: 1.3658 - learning_rate: 1.2500e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6673 - loss: 1.0744 - val_accuracy: 0.5994 - val_loss: 1.3065 - learning_rate: 6.2500e-05\n",
      "Epoch 30/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 23ms/step - accuracy: 0.6695 - loss: 1.0693 - val_accuracy: 0.5998 - val_loss: 1.3088 - learning_rate: 6.2500e-05\n",
      "Fold 9: Acc Janela=0.5972 | Acc Faixa=0.6258\n",
      "--- Iniciando Fold 10/10 ---\n",
      "Ajustando o Scaler (partial_fit)...\n",
      "Scaler ajustado.\n",
      "Preparando validação...\n",
      "Treinando com Batch Size: 16...\n",
      "Epoch 1/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 26ms/step - accuracy: 0.3699 - loss: 1.8703 - val_accuracy: 0.3771 - val_loss: 1.8068 - learning_rate: 0.0010\n",
      "Epoch 2/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 25ms/step - accuracy: 0.4471 - loss: 1.6771 - val_accuracy: 0.4858 - val_loss: 1.5510 - learning_rate: 0.0010\n",
      "Epoch 3/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.4819 - loss: 1.5938 - val_accuracy: 0.4161 - val_loss: 1.7273 - learning_rate: 0.0010\n",
      "Epoch 4/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5081 - loss: 1.5378 - val_accuracy: 0.5028 - val_loss: 1.4996 - learning_rate: 0.0010\n",
      "Epoch 5/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.5205 - loss: 1.5021 - val_accuracy: 0.5262 - val_loss: 1.4687 - learning_rate: 0.0010\n",
      "Epoch 6/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5300 - loss: 1.4819 - val_accuracy: 0.5249 - val_loss: 1.4574 - learning_rate: 0.0010\n",
      "Epoch 7/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.5383 - loss: 1.4611 - val_accuracy: 0.5490 - val_loss: 1.4053 - learning_rate: 0.0010\n",
      "Epoch 8/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.5420 - loss: 1.4531 - val_accuracy: 0.5125 - val_loss: 1.5277 - learning_rate: 0.0010\n",
      "Epoch 9/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5479 - loss: 1.4422 - val_accuracy: 0.5033 - val_loss: 1.5826 - learning_rate: 0.0010\n",
      "Epoch 10/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5528 - loss: 1.4301 - val_accuracy: 0.5594 - val_loss: 1.3976 - learning_rate: 0.0010\n",
      "Epoch 11/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5568 - loss: 1.4253 - val_accuracy: 0.5548 - val_loss: 1.3897 - learning_rate: 0.0010\n",
      "Epoch 12/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 25ms/step - accuracy: 0.5594 - loss: 1.4170 - val_accuracy: 0.4246 - val_loss: 1.8626 - learning_rate: 0.0010\n",
      "Epoch 13/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5620 - loss: 1.4097 - val_accuracy: 0.5131 - val_loss: 1.5553 - learning_rate: 0.0010\n",
      "Epoch 14/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5682 - loss: 1.4068\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5653 - loss: 1.4095 - val_accuracy: 0.5508 - val_loss: 1.3964 - learning_rate: 0.0010\n",
      "Epoch 15/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.5889 - loss: 1.3334 - val_accuracy: 0.5926 - val_loss: 1.3127 - learning_rate: 5.0000e-04\n",
      "Epoch 16/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 24ms/step - accuracy: 0.5904 - loss: 1.3106 - val_accuracy: 0.5873 - val_loss: 1.2948 - learning_rate: 5.0000e-04\n",
      "Epoch 17/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 25ms/step - accuracy: 0.5957 - loss: 1.3006 - val_accuracy: 0.5897 - val_loss: 1.2966 - learning_rate: 5.0000e-04\n",
      "Epoch 18/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.5982 - loss: 1.2937 - val_accuracy: 0.5393 - val_loss: 1.4788 - learning_rate: 5.0000e-04\n",
      "Epoch 19/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6020 - loss: 1.2826\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6004 - loss: 1.2877 - val_accuracy: 0.5683 - val_loss: 1.3534 - learning_rate: 5.0000e-04\n",
      "Epoch 20/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6134 - loss: 1.2445 - val_accuracy: 0.5762 - val_loss: 1.3458 - learning_rate: 2.5000e-04\n",
      "Epoch 21/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6202 - loss: 1.2238 - val_accuracy: 0.5979 - val_loss: 1.2723 - learning_rate: 2.5000e-04\n",
      "Epoch 22/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6215 - loss: 1.2149 - val_accuracy: 0.5908 - val_loss: 1.2996 - learning_rate: 2.5000e-04\n",
      "Epoch 23/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 24ms/step - accuracy: 0.6217 - loss: 1.2097 - val_accuracy: 0.5991 - val_loss: 1.2576 - learning_rate: 2.5000e-04\n",
      "Epoch 24/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6246 - loss: 1.2035 - val_accuracy: 0.6022 - val_loss: 1.2654 - learning_rate: 2.5000e-04\n",
      "Epoch 25/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6255 - loss: 1.1985 - val_accuracy: 0.6083 - val_loss: 1.2288 - learning_rate: 2.5000e-04\n",
      "Epoch 26/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 23ms/step - accuracy: 0.6257 - loss: 1.1950 - val_accuracy: 0.5825 - val_loss: 1.3506 - learning_rate: 2.5000e-04\n",
      "Epoch 27/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 23ms/step - accuracy: 0.6262 - loss: 1.1902 - val_accuracy: 0.6056 - val_loss: 1.2572 - learning_rate: 2.5000e-04\n",
      "Epoch 28/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6280 - loss: 1.1860\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6270 - loss: 1.1876 - val_accuracy: 0.5958 - val_loss: 1.2937 - learning_rate: 2.5000e-04\n",
      "Epoch 29/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 25ms/step - accuracy: 0.6388 - loss: 1.1529 - val_accuracy: 0.6130 - val_loss: 1.2353 - learning_rate: 1.2500e-04\n",
      "Epoch 30/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 25ms/step - accuracy: 0.6422 - loss: 1.1447 - val_accuracy: 0.6126 - val_loss: 1.2333 - learning_rate: 1.2500e-04\n",
      "Epoch 31/60\n",
      "\u001b[1m5582/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.6420 - loss: 1.1401\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 24ms/step - accuracy: 0.6429 - loss: 1.1373 - val_accuracy: 0.6081 - val_loss: 1.2364 - learning_rate: 1.2500e-04\n",
      "Epoch 32/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6501 - loss: 1.1175 - val_accuracy: 0.6091 - val_loss: 1.2541 - learning_rate: 6.2500e-05\n",
      "Epoch 33/60\n",
      "\u001b[1m5584/5584\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 24ms/step - accuracy: 0.6513 - loss: 1.1120 - val_accuracy: 0.6040 - val_loss: 1.2659 - learning_rate: 6.2500e-05\n",
      "Fold 10: Acc Janela=0.6083 | Acc Faixa=0.6458\n",
      "\n",
      "--- CV Concluído ---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import mixed_precision\n",
    "import gc\n",
    "\n",
    "# Isso usa float16 para cálculos pesados e float32 para variáveis, economizando VRAM.\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "print(\"Mixed Precision ativado: mixed_float16\")\n",
    "\n",
    "n_splits = 10\n",
    "gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "# Armazenar resultados\n",
    "fold_scores_acc_window = []\n",
    "fold_scores_acc_track = []\n",
    "all_preds_track = []\n",
    "all_true_track = []\n",
    "\n",
    "BATCH_SIZE = 16 # Reduzido para garantir estabilidade na RTX 3060\n",
    "\n",
    "# Função do Gerador (Mesma lógica, apenas garantindo consistência)\n",
    "def data_generator(indices, batch_size):\n",
    "    num_samples = len(indices)\n",
    "    while True:\n",
    "        indices_shuffled = shuffle(indices)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_indices = indices_shuffled[offset:offset + batch_size]\n",
    "\n",
    "            # Carrega do disco (memmap)\n",
    "            X_batch = X_np_cnn[batch_indices]\n",
    "            y_batch = y_one_hot[batch_indices]\n",
    "            \n",
    "            # O Scaler deve ser aplicado na versão achatada e depois reshape (reshape para 2D -> transform -> reshape volta)\n",
    "            # (Assumindo que o scaler foi fitado no loop principal)\n",
    "            X_b_flat = X_batch.reshape(X_batch.shape[0], -1)\n",
    "            X_b_scaled = scaler.transform(X_b_flat).reshape(X_batch.shape)\n",
    "            \n",
    "            yield X_b_scaled, y_batch\n",
    "\n",
    "# Loop de Validação Cruzada (GroupKFold)\n",
    "for fold, (train_idx, test_idx) in enumerate(gkf.split(X_np_cnn, y_one_hot, groups=groups_np)):\n",
    "    print(f\"--- Iniciando Fold {fold+1}/{n_splits} ---\")\n",
    "    \n",
    "    # Limpeza de memória preventiva\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    # 1. Ajustar Scaler (StandardScaler)\n",
    "    print(\"Ajustando o Scaler (partial_fit)...\")\n",
    "    scaler = StandardScaler()\n",
    "    train_idx_shuffled = shuffle(train_idx)\n",
    "    chunk_size = 5000   # Ajusta o scaler em lotes de 5000 amostras, para não estourar a RAM\n",
    "\n",
    "    for i in range(0, len(train_idx_shuffled), chunk_size):\n",
    "        idx = train_idx_shuffled[i:i+chunk_size]\n",
    "        X_chunk = X_np_cnn[idx].reshape(len(idx), -1)\n",
    "        scaler.partial_fit(X_chunk)\n",
    "        del X_chunk\n",
    "\n",
    "    print(\"Scaler ajustado.\")\n",
    "\n",
    "    # 2. Preparar Validação\n",
    "    print(\"Preparando validação...\")\n",
    "    X_test = X_np_cnn[test_idx]\n",
    "    y_test = y_one_hot[test_idx]\n",
    "    \n",
    "    # Escalar teste\n",
    "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "    X_test_scaled = scaler.transform(X_test_flat).reshape(X_test.shape)\n",
    "\n",
    "    # Liberar memória das cópias não usadas\n",
    "    del X_test, X_test_flat\n",
    "    gc.collect()\n",
    "\n",
    "    # Dados auxiliares para votação\n",
    "    groups_test_fold = groups_np[test_idx]\n",
    "    y_true_labels_fold = y_encoded_np[test_idx]\n",
    "    \n",
    "    # 3. Callbacks e Compilação \n",
    "    # Recriamos o modelo do zero a cada fold para não vazar pesos\n",
    "    model_cnn = build_cnn_model(input_shape, N_CLASSES)\n",
    "\n",
    "    # Usando AdamW para melhor generalização\n",
    "    optimizer = AdamW(learning_rate=0.001, weight_decay=0.004)\n",
    "    \n",
    "    model_cnn.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss='categorical_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # ReduceLROnPlateau: Reduz LR se val_loss não melhorar por 3 épocas\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True)\n",
    "\n",
    "    # 4. Treino\n",
    "    train_gen = data_generator(train_idx, BATCH_SIZE)\n",
    "    steps_per_epoch = len(train_idx) // BATCH_SIZE\n",
    "    \n",
    "    print(f\"Treinando com Batch Size: {BATCH_SIZE}...\")\n",
    "    history = model_cnn.fit(\n",
    "        train_gen,\n",
    "        epochs=60,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        callbacks=[early_stopping, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 5. Avaliação (Janela)\n",
    "    loss, acc = model_cnn.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "    fold_scores_acc_window.append(acc)\n",
    "\n",
    "    # 6. Avaliação (Faixa - Votação Majoritária)\n",
    "    # Predição em batches para economizar VRAM na inferência\n",
    "    y_pred_probs = model_cnn.predict(X_test_scaled, batch_size=32, verbose=0)\n",
    "    y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    df_fold = pd.DataFrame({\n",
    "        'track_id': groups_test_fold,\n",
    "        'y_true': y_true_labels_fold,\n",
    "        'y_pred': y_pred_labels\n",
    "    })\n",
    "    \n",
    "    grouped = df_fold.groupby('track_id')\n",
    "    y_true_track = grouped['y_true'].first()\n",
    "    y_pred_track = grouped['y_pred'].apply(lambda x: stats.mode(x, keepdims=True)[0][0])\n",
    "    \n",
    "    acc_track = np.mean(y_true_track == y_pred_track)\n",
    "    fold_scores_acc_track.append(acc_track)\n",
    "    \n",
    "    print(f\"Fold {fold+1}: Acc Janela={acc:.4f} | Acc Faixa={acc_track:.4f}\")\n",
    "    \n",
    "    # Armazenar predições globais\n",
    "    all_preds_track.append(y_pred_track.values)\n",
    "    all_true_track.append(y_true_track.values)\n",
    "    \n",
    "    # Limpeza final do fold\n",
    "    del model_cnn, scaler, X_test_scaled, y_test, y_pred_probs, df_fold\n",
    "    tf.keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "print(\"\\n--- CV Concluído ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61b3120",
   "metadata": {},
   "source": [
    "### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44aa0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\n",
      "Acurácia Média (10-Fold CV): 0.6436 +/- 0.0131\n",
      "\n",
      "--- Relatório de Classificação (Nível Faixa) ---\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.62      0.72      0.67       999\n",
      " Experimental       0.60      0.51      0.55       999\n",
      "         Folk       0.62      0.71      0.66      1000\n",
      "      Hip-Hop       0.78      0.81      0.79       997\n",
      " Instrumental       0.58      0.66      0.61      1000\n",
      "International       0.75      0.77      0.76      1000\n",
      "          Pop       0.49      0.25      0.33      1000\n",
      "         Rock       0.65      0.72      0.68       999\n",
      "\n",
      "     accuracy                           0.64      7994\n",
      "    macro avg       0.63      0.64      0.63      7994\n",
      " weighted avg       0.63      0.64      0.63      7994\n",
      "\n",
      "\n",
      "--- Matriz de Confusão (Nível Faixa) ---\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Resultados da Acurácia por Faixa\n",
    "mean_acc_track = np.mean(fold_scores_acc_track)\n",
    "std_acc_track = np.std(fold_scores_acc_track)\n",
    "print(f\"\\n========= Resultados Finais (Nível Faixa - Votação Majoritária) ==========\")\n",
    "print(f\"Acurácia Média (10-Fold CV): {mean_acc_track:.4f} +/- {std_acc_track:.4f}\")\n",
    "\n",
    "# Matriz de Confusão e Relatório de Classificação Agregados (Nível Faixa)\n",
    "y_true_agg = np.concatenate(all_true_track)\n",
    "y_pred_agg = np.concatenate(all_preds_track)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n--- Relatório de Classificação (Nível Faixa) ---\")\n",
    "print(classification_report(y_true_agg, y_pred_agg, target_names=class_names))\n",
    "\n",
    "print(\"\\n--- Matriz de Confusão (Nível Faixa) ---\")\n",
    "cm = confusion_matrix(y_true_agg, y_pred_agg)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Matriz de Confusão (Nível Faixa) - CNN 2D')\n",
    "plt.ylabel('Rótulo Verdadeiro')\n",
    "plt.xlabel('Rótulo Previsto')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tcc_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
